{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kavan\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.13.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\kavan\\appdata\\roaming\\python\\python38\\site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (49.2.1)\n",
      "Requirement already satisfied: pathtools in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.12.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0; sys_platform != \"linux\" in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\kavan\\appdata\\roaming\\python\\python38\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\kavan\\appdata\\roaming\\python\\python38\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.6)\n",
      "Requirement already satisfied: urllib3>=1.26.11; python_version >= \"3.6\" in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentry-sdk>=1.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: certifi in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentry-sdk>=1.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kavan\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'sklearn.utils._bunch.Bunch'>\n",
      "keys: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "shape: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "print('type:', type(data))\n",
    "print('keys:', data.keys())\n",
    "print('shape:', data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "classes: ['malignant' 'benign']\n",
      "features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print('ground truth:', data.target)\n",
    "print('classes:', data.target_names)\n",
    "print('features:', data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a train and test set. Pass in feature data and targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset for comparable weights in features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the wandb sweep\n",
    "sweep_config = {\n",
    "    'method': 'random', #grid, random\n",
    "    'metric': {\n",
    "      'name': 'accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.1, 0.05, 0.01, 0.005, 0.004, 0.003, 0.002, 0.001, 0.0005, 0.0004, 0.0003, 0.0002, 0.0001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [10, 20, 50, 100, 200, 500]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64, 128, 256]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'nadam', 'sgd', 'rmsprop']\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2rsf7rdm\n",
      "Sweep URL: https://wandb.ai/kavp/tensorflow-test/sweeps/2rsf7rdm\n"
     ]
    }
   ],
   "source": [
    "# Initialise sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project='tensorflow-test', entity='kavp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mega function to define and train model and log results (used by the sweep)\n",
    "def sweep_func():\n",
    "    # Default hyperparameter values\n",
    "    config_defaults = {\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 128,\n",
    "        'optimizer': 'adam',\n",
    "        'eager_mode': False,\n",
    "    }\n",
    "\n",
    "    # Initialise run\n",
    "    wandb.init(config=config_defaults)\n",
    "\n",
    "    # Variable to hold the sweep values\n",
    "    config = wandb.config\n",
    "    \n",
    "    if config['eager_mode'] == True:\n",
    "        tf.compat.v1.enable_eager_execution()\n",
    "    elif config['eager_mode'] == False:\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "    else:\n",
    "        raise ValueError('eager_mode property of wandb config could not be determined.') \n",
    "\n",
    "    # Define our own sequential model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Layers\n",
    "        tf.keras.layers.Input(shape=(D,)),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=config['optimizer'],\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        run_eagerly=config['eager_mode'],\n",
    "    )\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        r = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=config['epochs'], batch_size=config['batch_size'])\n",
    "        wandb.tensorflow.log(tf.compat.v1.summary.merge_all())\n",
    "        # wandb.log({'loss': r.history['loss'], 'val_loss': r.history['val_loss'], 'acc': r.history['accuracy'], 'val_acc': r.history['val_accuracy']})\n",
    "\n",
    "        # wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['loss'])]\n",
    "        # table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"loss\"])\n",
    "        # wandb.log({\"loss_against_epochs\" : wandb.plot.line(table, \"epoch\", \"loss\", title=\"Training loss\")})\n",
    "\n",
    "        # wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['val_loss'])]\n",
    "        # table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"val_loss\"])\n",
    "        # wandb.log({\"val_loss_against_epochs\" : wandb.plot.line(table, \"epoch\", \"val_loss\", title=\"Validation loss\")})\n",
    "\n",
    "        # wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['accuracy'])]\n",
    "        # table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"accuracy\"])\n",
    "        # wandb.log({\"accuracy_against_epochs\" : wandb.plot.line(table, \"epoch\", \"accuracy\", title=\"Training accuracy\")})\n",
    "\n",
    "        # wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['val_accuracy'])]\n",
    "        # table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"val_accuracy\"])\n",
    "        # wandb.log({\"val_accuracy_against_epochs\" : wandb.plot.line(table, \"epoch\", \"val_accuracy\", title=\"Validation accuracy\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, sweep_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3c659eed48feaa95130d67f14112e7f62129a763be0b6a77d5fa4efaa63988c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
