{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (1.24.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kavan\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.13.7)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.12.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0; sys_platform != \"linux\" in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (3.19.6)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (49.2.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\kavan\\appdata\\roaming\\python\\python38\\site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentry-sdk>=1.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: urllib3>=1.26.11; python_version >= \"3.6\" in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sentry-sdk>=1.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: six in c:\\users\\kavan\\appdata\\roaming\\python\\python38\\site-packages (from promise<3,>=2.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\kavan\\appdata\\roaming\\python\\python38\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\kavan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\kavan\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'sklearn.utils._bunch.Bunch'>\n",
      "keys: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "shape: (569, 30)\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "print('type:', type(data))\n",
    "print('keys:', data.keys())\n",
    "print('shape:', data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "classes: ['malignant' 'benign']\n",
      "features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print('ground truth:', data.target)\n",
    "print('classes:', data.target_names)\n",
    "print('features:', data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a train and test set. Pass in feature data and targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset for comparable weights in features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230107_002803-1fz7pipf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/1fz7pipf\" target=\"_blank\">rose-sun-13</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='tensorflow-test', entity='kavp')\n",
    "\n",
    "# WandB parameters\n",
    "wandb.config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 128,\n",
    "    'eager_mode': False,\n",
    "}\n",
    "if wandb.config['eager_mode'] == True:\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "elif wandb.config['eager_mode'] == False:\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "else:\n",
    "    raise ValueError('eager_mode property of wandb config could not be determined.') \n",
    "\n",
    "\n",
    "# Define our own sequential model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Layers\n",
    "    tf.keras.layers.Input(shape=(D,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=wandb.config['eager_mode'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381 samples, validate on 188 samples\n",
      "Epoch 1/100\n",
      "381/381 [==============================] - 0s 574us/sample - loss: 1.7826 - accuracy: 0.0709 - val_loss: 1.6698 - val_accuracy: 0.1170\n",
      "Epoch 2/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 1.7491 - accuracy: 0.0735 - val_loss: 1.6384 - val_accuracy: 0.1223\n",
      "Epoch 3/100\n",
      "381/381 [==============================] - 0s 14us/sample - loss: 1.7153 - accuracy: 0.0735 - val_loss: 1.6075 - val_accuracy: 0.1170\n",
      "Epoch 4/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 1.6836 - accuracy: 0.0814 - val_loss: 1.5767 - val_accuracy: 0.1223\n",
      "Epoch 5/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.6499 - accuracy: 0.0945 - val_loss: 1.5464 - val_accuracy: 0.1223\n",
      "Epoch 6/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 1.6182 - accuracy: 0.1024 - val_loss: 1.5164 - val_accuracy: 0.1170\n",
      "Epoch 7/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.5865 - accuracy: 0.1050 - val_loss: 1.4866 - val_accuracy: 0.1223\n",
      "Epoch 8/100\n",
      "381/381 [==============================] - 0s 14us/sample - loss: 1.5547 - accuracy: 0.1076 - val_loss: 1.4573 - val_accuracy: 0.1277\n",
      "Epoch 9/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.5235 - accuracy: 0.1102 - val_loss: 1.4284 - val_accuracy: 0.1277\n",
      "Epoch 10/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 1.4938 - accuracy: 0.1155 - val_loss: 1.3997 - val_accuracy: 0.1277\n",
      "Epoch 11/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 1.4629 - accuracy: 0.1260 - val_loss: 1.3715 - val_accuracy: 0.1277\n",
      "Epoch 12/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.4325 - accuracy: 0.1365 - val_loss: 1.3439 - val_accuracy: 0.1330\n",
      "Epoch 13/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.4043 - accuracy: 0.1444 - val_loss: 1.3166 - val_accuracy: 0.1330\n",
      "Epoch 14/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.3753 - accuracy: 0.1522 - val_loss: 1.2897 - val_accuracy: 0.1383\n",
      "Epoch 15/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 1.3480 - accuracy: 0.1627 - val_loss: 1.2630 - val_accuracy: 0.1596\n",
      "Epoch 16/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 1.3192 - accuracy: 0.1680 - val_loss: 1.2369 - val_accuracy: 0.1755\n",
      "Epoch 17/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 1.2922 - accuracy: 0.1759 - val_loss: 1.2113 - val_accuracy: 0.2021\n",
      "Epoch 18/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.2654 - accuracy: 0.1864 - val_loss: 1.1861 - val_accuracy: 0.2128\n",
      "Epoch 19/100\n",
      "381/381 [==============================] - 0s 10us/sample - loss: 1.2393 - accuracy: 0.1969 - val_loss: 1.1613 - val_accuracy: 0.2128\n",
      "Epoch 20/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.2129 - accuracy: 0.2126 - val_loss: 1.1371 - val_accuracy: 0.2447\n",
      "Epoch 21/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.1881 - accuracy: 0.2336 - val_loss: 1.1132 - val_accuracy: 0.2500\n",
      "Epoch 22/100\n",
      "381/381 [==============================] - 0s 8us/sample - loss: 1.1626 - accuracy: 0.2520 - val_loss: 1.0900 - val_accuracy: 0.2766\n",
      "Epoch 23/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 1.1382 - accuracy: 0.2677 - val_loss: 1.0672 - val_accuracy: 0.2872\n",
      "Epoch 24/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.1150 - accuracy: 0.2835 - val_loss: 1.0448 - val_accuracy: 0.3138\n",
      "Epoch 25/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 1.0924 - accuracy: 0.2913 - val_loss: 1.0227 - val_accuracy: 0.3245\n",
      "Epoch 26/100\n",
      "381/381 [==============================] - 0s 8us/sample - loss: 1.0694 - accuracy: 0.3018 - val_loss: 1.0012 - val_accuracy: 0.3351\n",
      "Epoch 27/100\n",
      "381/381 [==============================] - 0s 8us/sample - loss: 1.0470 - accuracy: 0.3255 - val_loss: 0.9801 - val_accuracy: 0.3404\n",
      "Epoch 28/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 1.0250 - accuracy: 0.3386 - val_loss: 0.9596 - val_accuracy: 0.3617\n",
      "Epoch 29/100\n",
      "381/381 [==============================] - 0s 10us/sample - loss: 1.0036 - accuracy: 0.3596 - val_loss: 0.9397 - val_accuracy: 0.3670\n",
      "Epoch 30/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.9830 - accuracy: 0.3701 - val_loss: 0.9201 - val_accuracy: 0.3777\n",
      "Epoch 31/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.9628 - accuracy: 0.3832 - val_loss: 0.9010 - val_accuracy: 0.4149\n",
      "Epoch 32/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.9433 - accuracy: 0.4042 - val_loss: 0.8824 - val_accuracy: 0.4255\n",
      "Epoch 33/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.9236 - accuracy: 0.4357 - val_loss: 0.8643 - val_accuracy: 0.4468\n",
      "Epoch 34/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.9044 - accuracy: 0.4541 - val_loss: 0.8468 - val_accuracy: 0.4574\n",
      "Epoch 35/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.8871 - accuracy: 0.4646 - val_loss: 0.8295 - val_accuracy: 0.4681\n",
      "Epoch 36/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.8688 - accuracy: 0.4751 - val_loss: 0.8127 - val_accuracy: 0.4947\n",
      "Epoch 37/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.8514 - accuracy: 0.4829 - val_loss: 0.7964 - val_accuracy: 0.5053\n",
      "Epoch 38/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.8352 - accuracy: 0.4882 - val_loss: 0.7804 - val_accuracy: 0.5213\n",
      "Epoch 39/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.8182 - accuracy: 0.4908 - val_loss: 0.7650 - val_accuracy: 0.5372\n",
      "Epoch 40/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.8022 - accuracy: 0.4987 - val_loss: 0.7500 - val_accuracy: 0.5532\n",
      "Epoch 41/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.7871 - accuracy: 0.5092 - val_loss: 0.7353 - val_accuracy: 0.5745\n",
      "Epoch 42/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.7723 - accuracy: 0.5328 - val_loss: 0.7210 - val_accuracy: 0.5851\n",
      "Epoch 43/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.7573 - accuracy: 0.5407 - val_loss: 0.7072 - val_accuracy: 0.6011\n",
      "Epoch 44/100\n",
      "381/381 [==============================] - 0s 8us/sample - loss: 0.7433 - accuracy: 0.5486 - val_loss: 0.6937 - val_accuracy: 0.6064\n",
      "Epoch 45/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.7294 - accuracy: 0.5617 - val_loss: 0.6807 - val_accuracy: 0.6223\n",
      "Epoch 46/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.7158 - accuracy: 0.5774 - val_loss: 0.6680 - val_accuracy: 0.6277\n",
      "Epoch 47/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.7027 - accuracy: 0.6010 - val_loss: 0.6558 - val_accuracy: 0.6489\n",
      "Epoch 48/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.6904 - accuracy: 0.6089 - val_loss: 0.6438 - val_accuracy: 0.6489\n",
      "Epoch 49/100\n",
      "381/381 [==============================] - 0s 15us/sample - loss: 0.6780 - accuracy: 0.6168 - val_loss: 0.6323 - val_accuracy: 0.6489\n",
      "Epoch 50/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.6665 - accuracy: 0.6247 - val_loss: 0.6209 - val_accuracy: 0.6702\n",
      "Epoch 51/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.6546 - accuracy: 0.6352 - val_loss: 0.6101 - val_accuracy: 0.6809\n",
      "Epoch 52/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.6436 - accuracy: 0.6483 - val_loss: 0.5995 - val_accuracy: 0.7021\n",
      "Epoch 53/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.6327 - accuracy: 0.6614 - val_loss: 0.5892 - val_accuracy: 0.7234\n",
      "Epoch 54/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.6222 - accuracy: 0.6772 - val_loss: 0.5793 - val_accuracy: 0.7287\n",
      "Epoch 55/100\n",
      "381/381 [==============================] - 0s 10us/sample - loss: 0.6121 - accuracy: 0.6877 - val_loss: 0.5697 - val_accuracy: 0.7340\n",
      "Epoch 56/100\n",
      "381/381 [==============================] - 0s 8us/sample - loss: 0.6023 - accuracy: 0.6955 - val_loss: 0.5603 - val_accuracy: 0.7394\n",
      "Epoch 57/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.5929 - accuracy: 0.7034 - val_loss: 0.5512 - val_accuracy: 0.7553\n",
      "Epoch 58/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.5834 - accuracy: 0.7087 - val_loss: 0.5424 - val_accuracy: 0.7660\n",
      "Epoch 59/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.5747 - accuracy: 0.7192 - val_loss: 0.5339 - val_accuracy: 0.7713\n",
      "Epoch 60/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.5661 - accuracy: 0.7218 - val_loss: 0.5255 - val_accuracy: 0.7872\n",
      "Epoch 61/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.5576 - accuracy: 0.7297 - val_loss: 0.5175 - val_accuracy: 0.7979\n",
      "Epoch 62/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.5494 - accuracy: 0.7428 - val_loss: 0.5097 - val_accuracy: 0.8085\n",
      "Epoch 63/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.5415 - accuracy: 0.7507 - val_loss: 0.5022 - val_accuracy: 0.8138\n",
      "Epoch 64/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.5339 - accuracy: 0.7559 - val_loss: 0.4949 - val_accuracy: 0.8191\n",
      "Epoch 65/100\n",
      "381/381 [==============================] - 0s 10us/sample - loss: 0.5266 - accuracy: 0.7612 - val_loss: 0.4878 - val_accuracy: 0.8191\n",
      "Epoch 66/100\n",
      "381/381 [==============================] - 0s 8us/sample - loss: 0.5192 - accuracy: 0.7664 - val_loss: 0.4809 - val_accuracy: 0.8245\n",
      "Epoch 67/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.5124 - accuracy: 0.7795 - val_loss: 0.4742 - val_accuracy: 0.8298\n",
      "Epoch 68/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.5056 - accuracy: 0.7900 - val_loss: 0.4677 - val_accuracy: 0.8511\n",
      "Epoch 69/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4990 - accuracy: 0.7927 - val_loss: 0.4614 - val_accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4928 - accuracy: 0.7979 - val_loss: 0.4553 - val_accuracy: 0.8564\n",
      "Epoch 71/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.4866 - accuracy: 0.8058 - val_loss: 0.4494 - val_accuracy: 0.8617\n",
      "Epoch 72/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4806 - accuracy: 0.8136 - val_loss: 0.4436 - val_accuracy: 0.8670\n",
      "Epoch 73/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.4747 - accuracy: 0.8163 - val_loss: 0.4380 - val_accuracy: 0.8723\n",
      "Epoch 74/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4691 - accuracy: 0.8215 - val_loss: 0.4325 - val_accuracy: 0.8777\n",
      "Epoch 75/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.4637 - accuracy: 0.8215 - val_loss: 0.4271 - val_accuracy: 0.8777\n",
      "Epoch 76/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4581 - accuracy: 0.8215 - val_loss: 0.4220 - val_accuracy: 0.8830\n",
      "Epoch 77/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.4529 - accuracy: 0.8294 - val_loss: 0.4170 - val_accuracy: 0.8936\n",
      "Epoch 78/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4480 - accuracy: 0.8320 - val_loss: 0.4121 - val_accuracy: 0.8989\n",
      "Epoch 79/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.4430 - accuracy: 0.8373 - val_loss: 0.4073 - val_accuracy: 0.8989\n",
      "Epoch 80/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4381 - accuracy: 0.8399 - val_loss: 0.4026 - val_accuracy: 0.8989\n",
      "Epoch 81/100\n",
      "381/381 [==============================] - 0s 15us/sample - loss: 0.4335 - accuracy: 0.8451 - val_loss: 0.3981 - val_accuracy: 0.8989\n",
      "Epoch 82/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.4290 - accuracy: 0.8478 - val_loss: 0.3937 - val_accuracy: 0.8989\n",
      "Epoch 83/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.4245 - accuracy: 0.8530 - val_loss: 0.3893 - val_accuracy: 0.8989\n",
      "Epoch 84/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.4201 - accuracy: 0.8609 - val_loss: 0.3851 - val_accuracy: 0.9043\n",
      "Epoch 85/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4159 - accuracy: 0.8609 - val_loss: 0.3810 - val_accuracy: 0.9043\n",
      "Epoch 86/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.4117 - accuracy: 0.8609 - val_loss: 0.3770 - val_accuracy: 0.9043\n",
      "Epoch 87/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.4077 - accuracy: 0.8635 - val_loss: 0.3731 - val_accuracy: 0.9043\n",
      "Epoch 88/100\n",
      "381/381 [==============================] - 0s 13us/sample - loss: 0.4038 - accuracy: 0.8661 - val_loss: 0.3692 - val_accuracy: 0.9043\n",
      "Epoch 89/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.3998 - accuracy: 0.8661 - val_loss: 0.3655 - val_accuracy: 0.9043\n",
      "Epoch 90/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.3961 - accuracy: 0.8661 - val_loss: 0.3618 - val_accuracy: 0.9043\n",
      "Epoch 91/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.3923 - accuracy: 0.8688 - val_loss: 0.3582 - val_accuracy: 0.9043\n",
      "Epoch 92/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.3887 - accuracy: 0.8661 - val_loss: 0.3547 - val_accuracy: 0.9096\n",
      "Epoch 93/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.3852 - accuracy: 0.8714 - val_loss: 0.3513 - val_accuracy: 0.9096\n",
      "Epoch 94/100\n",
      "381/381 [==============================] - 0s 12us/sample - loss: 0.3816 - accuracy: 0.8714 - val_loss: 0.3480 - val_accuracy: 0.9149\n",
      "Epoch 95/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.3783 - accuracy: 0.8740 - val_loss: 0.3447 - val_accuracy: 0.9149\n",
      "Epoch 96/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.3749 - accuracy: 0.8766 - val_loss: 0.3414 - val_accuracy: 0.9149\n",
      "Epoch 97/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.3718 - accuracy: 0.8766 - val_loss: 0.3383 - val_accuracy: 0.9149\n",
      "Epoch 98/100\n",
      "381/381 [==============================] - 0s 11us/sample - loss: 0.3685 - accuracy: 0.8793 - val_loss: 0.3352 - val_accuracy: 0.9202\n",
      "Epoch 99/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.3653 - accuracy: 0.8793 - val_loss: 0.3322 - val_accuracy: 0.9202\n",
      "Epoch 100/100\n",
      "381/381 [==============================] - 0s 9us/sample - loss: 0.3623 - accuracy: 0.8793 - val_loss: 0.3292 - val_accuracy: 0.9202\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    r = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=wandb.config['epochs'], batch_size=wandb.config['batch_size'], )\n",
    "    wandb.tensorflow.log(tf.compat.v1.summary.merge_all())\n",
    "    wandb.log({'loss': r.history['loss'], 'val_loss': r.history['val_loss'], 'acc': r.history['accuracy'], 'val_acc': r.history['val_accuracy']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_data = [[x,y] for (x,y) in zip(np.arange(0, wandb.config['epochs'], 1), r.history['loss'])]\n",
    "table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"loss\"])\n",
    "wandb.log({\"loss_against_epochs\" : wandb.plot.line(table, \"epoch\", \"loss\", title=\"Training loss\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_data = [[x,y] for (x,y) in zip(np.arange(0, wandb.config['epochs'], 1), r.history['val_loss'])]\n",
    "table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"val_loss\"])\n",
    "wandb.log({\"val_loss_against_epochs\" : wandb.plot.line(table, \"epoch\", \"val_loss\", title=\"Validation loss\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_data = [[x,y] for (x,y) in zip(np.arange(0, wandb.config['epochs'], 1), r.history['accuracy'])]\n",
    "table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"accuracy\"])\n",
    "wandb.log({\"accuracy_against_epochs\" : wandb.plot.line(table, \"epoch\", \"accuracy\", title=\"Training accuracy\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_data = [[x,y] for (x,y) in zip(np.arange(0, wandb.config['epochs'], 1), r.history['val_accuracy'])]\n",
    "table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"val_accuracy\"])\n",
    "wandb.log({\"val_accuracy_against_epochs\" : wandb.plot.line(table, \"epoch\", \"val_accuracy\", title=\"Validation accuracy\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rose-sun-13</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/1fz7pipf\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/1fz7pipf</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230107_002803-1fz7pipf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3c659eed48feaa95130d67f14112e7f62129a763be0b6a77d5fa4efaa63988c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
