{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nonlinear long-distance dataset\n",
    "T = 20\n",
    "D = 1\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "def get_label(x, i1, i2, i3):\n",
    "    if x[i1] < 0 and x[i2] < 0 and x[i3] < 0:\n",
    "        return 1\n",
    "    elif x[i1] < 0 and x[i2] > 0 and x[i3] > 0:\n",
    "        return 1\n",
    "    elif x[i1] > 0 and x[i2] < 0 and x[i3] > 0:\n",
    "        return 1\n",
    "    elif x[i1] > 0 and x[i2] > 0 and x[i3] < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "for t in range(5000):\n",
    "    x = np.random.randn(T)\n",
    "    X.append(x)\n",
    "    y = get_label(x, 0, 1, 2)\n",
    "    Y.append(y)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "N = len(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the wandb sweep\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "      'name': 'val_accuracy',\n",
    "      'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [80, 100, 200, 400]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [8, 16, 32, 64]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'nadam', 'sgd', 'rmsprop']\n",
    "        },\n",
    "        'activation_func': {\n",
    "            'values': [None, 'tanh', 'relu', 'sigmoid']\n",
    "        },\n",
    "        'model': {\n",
    "            'values': ['SimpleRNN', 'LSTM', 'GRU']\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: tsmolat6\n",
      "Sweep URL: https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\n"
     ]
    }
   ],
   "source": [
    "# Initialise sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project='tensorflow-test', entity='kavp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mega function to define and train model and log results (used by the sweep)\n",
    "def sweep_func():\n",
    "    # Default hyperparameter values\n",
    "    config_defaults = {\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 200,\n",
    "        'batch_size': 16,\n",
    "        'optimizer': 'adam',\n",
    "        'eager_mode': False,\n",
    "        'activation_func': None,\n",
    "        'model': 'LSTM',\n",
    "    }\n",
    "\n",
    "    # Initialise run\n",
    "    wandb.init(config=config_defaults)\n",
    "\n",
    "    # Variable to hold the sweep values\n",
    "    config = wandb.config\n",
    "    \n",
    "    if config['eager_mode'] == True:\n",
    "        tf.compat.v1.enable_eager_execution()\n",
    "    elif config['eager_mode'] == False:\n",
    "        tf.compat.v1.disable_eager_execution()\n",
    "    else:\n",
    "        raise ValueError('eager_mode property of wandb config could not be determined.') \n",
    "\n",
    "    # Create model\n",
    "    inputs = np.expand_dims(X, -1)\n",
    "    inp = tf.keras.layers.Input(shape=(T, D))\n",
    "    if config['model'] == 'SimpleRNN':\n",
    "        x = tf.keras.layers.SimpleRNN(5)(inp)\n",
    "    elif config['model'] == 'LSTM':\n",
    "        x = tf.keras.layers.LSTM(5)(inp)\n",
    "    elif config['model'] == 'GRU':\n",
    "        x = tf.keras.layers.GRU(5)(inp)\n",
    "    else:\n",
    "        raise ValueError('model property of wandb config could not be determined.')\n",
    "    x = tf.keras.layers.Dense(1, activation=config['activation_func'])(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inp, x)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=config['optimizer'],\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "        run_eagerly=config['eager_mode'],\n",
    "    )\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        r = model.fit(inputs, Y, validation_split=0.5, epochs=config['epochs'], batch_size=config['batch_size'])\n",
    "        wandb.tensorflow.log(tf.compat.v1.summary.merge_all())\n",
    "        wandb.log({'loss': r.history['loss'][-1], 'val_loss': r.history['val_loss'][-1], 'accuracy': r.history['accuracy'][-1], 'val_accuracy': r.history['val_accuracy'][-1]})\n",
    "\n",
    "        wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['loss'])]\n",
    "        table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"loss\"])\n",
    "        wandb.log({\"loss_against_epochs\" : wandb.plot.line(table, \"epoch\", \"loss\", title=\"Training loss\")})\n",
    "\n",
    "        wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['val_loss'])]\n",
    "        table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"val_loss\"])\n",
    "        wandb.log({\"val_loss_against_epochs\" : wandb.plot.line(table, \"epoch\", \"val_loss\", title=\"Validation loss\")})\n",
    "\n",
    "        wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['accuracy'])]\n",
    "        table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"accuracy\"])\n",
    "        wandb.log({\"accuracy_against_epochs\" : wandb.plot.line(table, \"epoch\", \"accuracy\", title=\"Training accuracy\")})\n",
    "\n",
    "        wandb_data = [[x,y] for (x,y) in zip(np.arange(0, config['epochs'], 1), r.history['val_accuracy'])]\n",
    "        table = wandb.Table(data=wandb_data, columns = [\"epoch\", \"val_accuracy\"])\n",
    "        wandb.log({\"val_accuracy_against_epochs\" : wandb.plot.line(table, \"epoch\", \"val_accuracy\", title=\"Validation accuracy\")})\n",
    "\n",
    "        wandb.log_artifact(model)\n",
    "\n",
    "        # Save model\n",
    "        model.save(os.path.join(wandb.run.dir, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ziqfk2my with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_220212-ziqfk2my</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/ziqfk2my\" target=\"_blank\">amber-sweep-1</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 1s 388us/sample - loss: 0.7369 - accuracy: 0.5024 - val_loss: 0.7037 - val_accuracy: 0.4916\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6982 - accuracy: 0.5000 - val_loss: 0.6978 - val_accuracy: 0.4896\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6949 - accuracy: 0.5244 - val_loss: 0.6960 - val_accuracy: 0.4920\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 1s 330us/sample - loss: 0.6956 - accuracy: 0.5084 - val_loss: 0.6957 - val_accuracy: 0.4876\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6953 - accuracy: 0.5136 - val_loss: 0.6951 - val_accuracy: 0.4908\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.6949 - accuracy: 0.4996 - val_loss: 0.6985 - val_accuracy: 0.4868\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6947 - accuracy: 0.5112 - val_loss: 0.6959 - val_accuracy: 0.5096\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6948 - accuracy: 0.4976 - val_loss: 0.6945 - val_accuracy: 0.5076\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6951 - accuracy: 0.4976 - val_loss: 0.6946 - val_accuracy: 0.4900\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.6947 - accuracy: 0.4996 - val_loss: 0.6947 - val_accuracy: 0.4856\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 1s 336us/sample - loss: 0.6942 - accuracy: 0.5076 - val_loss: 0.6942 - val_accuracy: 0.5080\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 1s 331us/sample - loss: 0.6952 - accuracy: 0.4964 - val_loss: 0.6943 - val_accuracy: 0.4892\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6948 - accuracy: 0.4936 - val_loss: 0.6942 - val_accuracy: 0.5076\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 1s 333us/sample - loss: 0.6947 - accuracy: 0.4980 - val_loss: 0.6942 - val_accuracy: 0.5020\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6943 - accuracy: 0.5088 - val_loss: 0.6941 - val_accuracy: 0.4908\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.6944 - accuracy: 0.5100 - val_loss: 0.6947 - val_accuracy: 0.5084\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 1s 326us/sample - loss: 0.6936 - accuracy: 0.5200 - val_loss: 0.6984 - val_accuracy: 0.5088\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6944 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.4936\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6939 - val_accuracy: 0.4944\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6948 - accuracy: 0.4940 - val_loss: 0.6948 - val_accuracy: 0.4872\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6941 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.4932\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6936 - accuracy: 0.5096 - val_loss: 0.6958 - val_accuracy: 0.5088\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5068 - val_loss: 0.6952 - val_accuracy: 0.4884\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5088 - val_loss: 0.6940 - val_accuracy: 0.5168\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6945 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.5064\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6944 - accuracy: 0.5088 - val_loss: 0.6940 - val_accuracy: 0.5148\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5064 - val_loss: 0.6939 - val_accuracy: 0.5172\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5072 - val_loss: 0.6968 - val_accuracy: 0.4920\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6947 - accuracy: 0.4960 - val_loss: 0.6939 - val_accuracy: 0.4900\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.6945 - accuracy: 0.4980 - val_loss: 0.6939 - val_accuracy: 0.5084\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6946 - accuracy: 0.4928 - val_loss: 0.6941 - val_accuracy: 0.4832\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6945 - accuracy: 0.4916 - val_loss: 0.6973 - val_accuracy: 0.4948\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6953 - val_accuracy: 0.4860\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6947 - accuracy: 0.4896 - val_loss: 0.6959 - val_accuracy: 0.4912\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6947 - accuracy: 0.4988 - val_loss: 0.6969 - val_accuracy: 0.4932\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6947 - accuracy: 0.4984 - val_loss: 0.6938 - val_accuracy: 0.5116\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6945 - accuracy: 0.5028 - val_loss: 0.6943 - val_accuracy: 0.5056\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6944 - accuracy: 0.5032 - val_loss: 0.6940 - val_accuracy: 0.4844\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6942 - accuracy: 0.5112 - val_loss: 0.6942 - val_accuracy: 0.4812\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6944 - accuracy: 0.4880 - val_loss: 0.6944 - val_accuracy: 0.4892\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6945 - accuracy: 0.4992 - val_loss: 0.6940 - val_accuracy: 0.4832\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6941 - accuracy: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6944 - accuracy: 0.5068 - val_loss: 0.6942 - val_accuracy: 0.4848\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6945 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.4800\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6944 - accuracy: 0.4944 - val_loss: 0.6938 - val_accuracy: 0.4816\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6943 - val_accuracy: 0.4876\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6946 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.5036\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6941 - accuracy: 0.5032 - val_loss: 0.6953 - val_accuracy: 0.4864\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6941 - accuracy: 0.5024 - val_loss: 0.6979 - val_accuracy: 0.4908\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6937 - accuracy: 0.4980 - val_loss: 0.6979 - val_accuracy: 0.5088\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.5092 - val_loss: 0.6948 - val_accuracy: 0.4840\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6938 - accuracy: 0.5112 - val_loss: 0.6947 - val_accuracy: 0.4896\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6944 - accuracy: 0.4952 - val_loss: 0.6938 - val_accuracy: 0.4872\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6976 - val_accuracy: 0.5088\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6937 - accuracy: 0.5080 - val_loss: 0.6953 - val_accuracy: 0.4872\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6939 - accuracy: 0.4944 - val_loss: 0.6953 - val_accuracy: 0.5092\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6946 - accuracy: 0.4884 - val_loss: 0.6937 - val_accuracy: 0.4868\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4964 - val_loss: 0.6948 - val_accuracy: 0.5108\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6948 - accuracy: 0.4984 - val_loss: 0.6944 - val_accuracy: 0.4868\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6942 - accuracy: 0.4964 - val_loss: 0.6947 - val_accuracy: 0.4868\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6943 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6941 - accuracy: 0.5076 - val_loss: 0.6937 - val_accuracy: 0.4872\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5140 - val_loss: 0.6952 - val_accuracy: 0.4864\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6935 - accuracy: 0.5132 - val_loss: 0.6953 - val_accuracy: 0.4872\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6935 - accuracy: 0.5076 - val_loss: 0.6975 - val_accuracy: 0.4904\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6941 - accuracy: 0.5012 - val_loss: 0.6956 - val_accuracy: 0.4864\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6935 - accuracy: 0.5152 - val_loss: 0.6940 - val_accuracy: 0.4872\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6942 - val_accuracy: 0.5124\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5020 - val_loss: 0.6936 - val_accuracy: 0.5148\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5096 - val_loss: 0.6940 - val_accuracy: 0.5108\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6942 - accuracy: 0.4936 - val_loss: 0.6945 - val_accuracy: 0.4880\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 1s 331us/sample - loss: 0.6939 - accuracy: 0.4984 - val_loss: 0.6956 - val_accuracy: 0.4892\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 1s 333us/sample - loss: 0.6940 - accuracy: 0.5016 - val_loss: 0.6947 - val_accuracy: 0.5092\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.6943 - accuracy: 0.4900 - val_loss: 0.6940 - val_accuracy: 0.5108\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 1s 327us/sample - loss: 0.6939 - accuracy: 0.5120 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 1s 332us/sample - loss: 0.6942 - accuracy: 0.4912 - val_loss: 0.6943 - val_accuracy: 0.4848\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 1s 328us/sample - loss: 0.6941 - accuracy: 0.5116 - val_loss: 0.6936 - val_accuracy: 0.5184\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 1s 334us/sample - loss: 0.6942 - accuracy: 0.4920 - val_loss: 0.6953 - val_accuracy: 0.4884\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 1s 336us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 1s 340us/sample - loss: 0.6943 - accuracy: 0.4912 - val_loss: 0.6936 - val_accuracy: 0.5100\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 1s 329us/sample - loss: 0.6939 - accuracy: 0.5004 - val_loss: 0.6947 - val_accuracy: 0.4828\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6944 - accuracy: 0.4888 - val_loss: 0.6941 - val_accuracy: 0.5124\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 1s 331us/sample - loss: 0.6942 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.4856\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 1s 334us/sample - loss: 0.6940 - accuracy: 0.5008 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6935 - accuracy: 0.5204 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6942 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.5120\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 1s 328us/sample - loss: 0.6942 - accuracy: 0.5044 - val_loss: 0.6944 - val_accuracy: 0.4888\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6942 - accuracy: 0.5012 - val_loss: 0.6949 - val_accuracy: 0.4892\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6944 - accuracy: 0.4932 - val_loss: 0.6936 - val_accuracy: 0.4948\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5112 - val_loss: 0.6957 - val_accuracy: 0.5088\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 1s 325us/sample - loss: 0.6941 - accuracy: 0.5004 - val_loss: 0.6949 - val_accuracy: 0.4856\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6936 - accuracy: 0.5136 - val_loss: 0.6964 - val_accuracy: 0.5088\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6942 - accuracy: 0.4936 - val_loss: 0.6953 - val_accuracy: 0.4892\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6957 - val_accuracy: 0.4960\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.5028 - val_loss: 0.6936 - val_accuracy: 0.5124\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.5004 - val_loss: 0.6935 - val_accuracy: 0.5036\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6942 - accuracy: 0.4904 - val_loss: 0.6936 - val_accuracy: 0.5004\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6940 - accuracy: 0.4976 - val_loss: 0.6942 - val_accuracy: 0.4824\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6934 - accuracy: 0.5112 - val_loss: 0.6935 - val_accuracy: 0.5156\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6942 - accuracy: 0.4928 - val_loss: 0.6958 - val_accuracy: 0.4936\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6939 - accuracy: 0.5076 - val_loss: 0.6936 - val_accuracy: 0.5092\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6937 - accuracy: 0.5068 - val_loss: 0.6940 - val_accuracy: 0.5128\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5028 - val_loss: 0.6952 - val_accuracy: 0.4860\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6942 - val_accuracy: 0.4868\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6941 - accuracy: 0.4964 - val_loss: 0.6941 - val_accuracy: 0.4892\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6936 - accuracy: 0.5152 - val_loss: 0.6960 - val_accuracy: 0.4932\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5052 - val_loss: 0.6938 - val_accuracy: 0.4840\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6943 - val_accuracy: 0.4840\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6941 - accuracy: 0.4952 - val_loss: 0.6935 - val_accuracy: 0.5116\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5192 - val_loss: 0.6951 - val_accuracy: 0.4872\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4956 - val_loss: 0.6935 - val_accuracy: 0.5148\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6934 - accuracy: 0.5064 - val_loss: 0.6943 - val_accuracy: 0.4860\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6934 - accuracy: 0.5144 - val_loss: 0.6936 - val_accuracy: 0.4948\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5016 - val_loss: 0.6936 - val_accuracy: 0.4976\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4984 - val_loss: 0.6936 - val_accuracy: 0.4924\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6942 - accuracy: 0.4968 - val_loss: 0.6940 - val_accuracy: 0.4872\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6927 - accuracy: 0.5172 - val_loss: 0.6942 - val_accuracy: 0.4884\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4984 - val_loss: 0.6939 - val_accuracy: 0.4892\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6939 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.5132\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.5048\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6939 - val_accuracy: 0.5136\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6923 - accuracy: 0.5264 - val_loss: 0.6970 - val_accuracy: 0.4908\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5164 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6941 - accuracy: 0.4980 - val_loss: 0.6935 - val_accuracy: 0.5156\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5092 - val_loss: 0.6950 - val_accuracy: 0.5096\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6927 - accuracy: 0.5140 - val_loss: 0.6948 - val_accuracy: 0.4888\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6940 - accuracy: 0.4972 - val_loss: 0.6940 - val_accuracy: 0.5128\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6926 - accuracy: 0.5164 - val_loss: 0.7016 - val_accuracy: 0.4912\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6945 - accuracy: 0.4984 - val_loss: 0.6940 - val_accuracy: 0.4864\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6940 - accuracy: 0.5056 - val_loss: 0.6936 - val_accuracy: 0.5104\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6940 - accuracy: 0.5144 - val_loss: 0.6938 - val_accuracy: 0.4848\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 1s 308us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6945 - val_accuracy: 0.4896\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 1s 312us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6940 - val_accuracy: 0.4868\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.4984 - val_loss: 0.6935 - val_accuracy: 0.5124\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6943 - accuracy: 0.4916 - val_loss: 0.6942 - val_accuracy: 0.4856\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 1s 310us/sample - loss: 0.6937 - accuracy: 0.5068 - val_loss: 0.6947 - val_accuracy: 0.4852\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.4992 - val_loss: 0.6939 - val_accuracy: 0.4912\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6940 - accuracy: 0.5044 - val_loss: 0.6940 - val_accuracy: 0.4876\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6956 - val_accuracy: 0.4924\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6936 - accuracy: 0.5160 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6939 - accuracy: 0.5028 - val_loss: 0.6935 - val_accuracy: 0.5124\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.4960 - val_loss: 0.6936 - val_accuracy: 0.4852\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6943 - accuracy: 0.5056 - val_loss: 0.6941 - val_accuracy: 0.4868\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6938 - val_accuracy: 0.5132\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4976 - val_loss: 0.6936 - val_accuracy: 0.5092\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.5104\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.5064 - val_loss: 0.6951 - val_accuracy: 0.5084\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6929 - accuracy: 0.5136 - val_loss: 0.6937 - val_accuracy: 0.4848\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5032 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.4852\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6939 - accuracy: 0.4964 - val_loss: 0.6937 - val_accuracy: 0.4884\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5132 - val_loss: 0.6937 - val_accuracy: 0.5108\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6941 - accuracy: 0.5136 - val_loss: 0.6938 - val_accuracy: 0.4892\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6934 - accuracy: 0.5124 - val_loss: 0.6935 - val_accuracy: 0.5148\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6980 - val_accuracy: 0.4908\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6942 - accuracy: 0.4956 - val_loss: 0.6941 - val_accuracy: 0.4852\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6942 - val_accuracy: 0.4900\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5124 - val_loss: 0.6962 - val_accuracy: 0.4924\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.4976 - val_loss: 0.6939 - val_accuracy: 0.5136\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.4992 - val_loss: 0.6946 - val_accuracy: 0.4880\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6935 - val_accuracy: 0.4944\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.5140 - val_loss: 0.6951 - val_accuracy: 0.4864\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4996 - val_loss: 0.6936 - val_accuracy: 0.4944\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6929 - accuracy: 0.5180 - val_loss: 0.6950 - val_accuracy: 0.4880\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.5032 - val_loss: 0.6936 - val_accuracy: 0.4948\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6936 - accuracy: 0.5044 - val_loss: 0.6949 - val_accuracy: 0.4880\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6937 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.5144\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6940 - val_accuracy: 0.4880\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6938 - val_accuracy: 0.5084\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6937 - accuracy: 0.5008 - val_loss: 0.6935 - val_accuracy: 0.5016\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6945 - val_accuracy: 0.4884\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6930 - accuracy: 0.5132 - val_loss: 0.6956 - val_accuracy: 0.5092\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6922 - accuracy: 0.5200 - val_loss: 0.6961 - val_accuracy: 0.4916\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.5112 - val_loss: 0.6936 - val_accuracy: 0.5100\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.4872 - val_loss: 0.6946 - val_accuracy: 0.4884\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4916 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6950 - val_accuracy: 0.5088\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6941 - accuracy: 0.5056 - val_loss: 0.6936 - val_accuracy: 0.4928\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6949 - val_accuracy: 0.5088\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6938 - accuracy: 0.5116 - val_loss: 0.6943 - val_accuracy: 0.4860\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6934 - val_accuracy: 0.5112\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.5132 - val_loss: 0.6938 - val_accuracy: 0.4896\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.5048 - val_loss: 0.6935 - val_accuracy: 0.5080\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.4964 - val_loss: 0.6942 - val_accuracy: 0.5124\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5160 - val_loss: 0.6954 - val_accuracy: 0.4924\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6939 - accuracy: 0.5080 - val_loss: 0.6934 - val_accuracy: 0.5164\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5044 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6935 - accuracy: 0.5040 - val_loss: 0.6941 - val_accuracy: 0.5128\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5116 - val_loss: 0.6938 - val_accuracy: 0.5080\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6941 - accuracy: 0.5012 - val_loss: 0.6940 - val_accuracy: 0.4852\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6954 - val_accuracy: 0.4928\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6941 - accuracy: 0.4968 - val_loss: 0.6943 - val_accuracy: 0.4872\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6941 - accuracy: 0.5088 - val_loss: 0.6935 - val_accuracy: 0.4992\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.4896\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6964 - val_accuracy: 0.5092\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6936 - val_accuracy: 0.4976\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6930 - accuracy: 0.5136 - val_loss: 0.6938 - val_accuracy: 0.4896\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6932 - accuracy: 0.5148 - val_loss: 0.6944 - val_accuracy: 0.4860\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6942 - accuracy: 0.4920 - val_loss: 0.6943 - val_accuracy: 0.4876\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6935 - accuracy: 0.5108 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6941 - accuracy: 0.5080 - val_loss: 0.6935 - val_accuracy: 0.5024\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6935 - accuracy: 0.5204 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6938 - accuracy: 0.5172 - val_loss: 0.6958 - val_accuracy: 0.4936\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5112 - val_loss: 0.6934 - val_accuracy: 0.5136\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6962 - val_accuracy: 0.4904\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6937 - accuracy: 0.5064 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 1s 314us/sample - loss: 0.6941 - accuracy: 0.4952 - val_loss: 0.6936 - val_accuracy: 0.4980\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 1s 312us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6944 - val_accuracy: 0.4880\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6935 - val_accuracy: 0.5152\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5084\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6932 - accuracy: 0.5068 - val_loss: 0.6937 - val_accuracy: 0.4880\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6939 - accuracy: 0.4908 - val_loss: 0.6936 - val_accuracy: 0.4980\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6955 - val_accuracy: 0.4912\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6936 - accuracy: 0.4984 - val_loss: 0.6945 - val_accuracy: 0.4888\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6935 - accuracy: 0.5096 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5004 - val_loss: 0.6935 - val_accuracy: 0.5024\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6934 - accuracy: 0.5136 - val_loss: 0.6956 - val_accuracy: 0.4940\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 1s 328us/sample - loss: 0.6938 - accuracy: 0.5076 - val_loss: 0.6959 - val_accuracy: 0.4932\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6936 - accuracy: 0.4932 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6935 - accuracy: 0.5180 - val_loss: 0.6943 - val_accuracy: 0.5136\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6942 - val_accuracy: 0.4844\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5020 - val_loss: 0.6937 - val_accuracy: 0.4844\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.4980\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6949 - val_accuracy: 0.4860\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6937 - val_accuracy: 0.4840\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5068 - val_loss: 0.6938 - val_accuracy: 0.5108\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6939 - accuracy: 0.4988 - val_loss: 0.6936 - val_accuracy: 0.5108\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6941 - val_accuracy: 0.4900\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6939 - accuracy: 0.5064 - val_loss: 0.6939 - val_accuracy: 0.4872\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.5008 - val_loss: 0.6936 - val_accuracy: 0.5100\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.5116\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6933 - accuracy: 0.5112 - val_loss: 0.6935 - val_accuracy: 0.5056\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.4856\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6935 - val_accuracy: 0.5136\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5060 - val_loss: 0.6941 - val_accuracy: 0.5104\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6936 - val_accuracy: 0.4984\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5064 - val_loss: 0.6937 - val_accuracy: 0.4824\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6931 - accuracy: 0.5176 - val_loss: 0.6962 - val_accuracy: 0.5092\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.6950 - val_accuracy: 0.5084\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6941 - accuracy: 0.4884 - val_loss: 0.6944 - val_accuracy: 0.4888\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.5112\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5068 - val_loss: 0.6935 - val_accuracy: 0.5124\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5020 - val_loss: 0.6939 - val_accuracy: 0.5104\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6961 - val_accuracy: 0.4928\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 1s 326us/sample - loss: 0.6931 - accuracy: 0.5092 - val_loss: 0.6935 - val_accuracy: 0.5120\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 1s 324us/sample - loss: 0.6935 - accuracy: 0.5152 - val_loss: 0.6980 - val_accuracy: 0.4908\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 1s 329us/sample - loss: 0.6942 - accuracy: 0.4988 - val_loss: 0.6943 - val_accuracy: 0.4884\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6932 - accuracy: 0.5164 - val_loss: 0.6958 - val_accuracy: 0.5088\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5124 - val_loss: 0.6941 - val_accuracy: 0.5100\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 1s 333us/sample - loss: 0.6933 - accuracy: 0.5156 - val_loss: 0.6943 - val_accuracy: 0.4860\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.4944 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.5012 - val_loss: 0.6939 - val_accuracy: 0.4904\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 1s 333us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6943 - val_accuracy: 0.4816\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6940 - val_accuracy: 0.4892\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6936 - accuracy: 0.4980 - val_loss: 0.6935 - val_accuracy: 0.5144\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6921 - accuracy: 0.5212 - val_loss: 0.6994 - val_accuracy: 0.5088\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6942 - accuracy: 0.5116 - val_loss: 0.6937 - val_accuracy: 0.4932\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.4996\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6937 - val_accuracy: 0.4820\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6949 - val_accuracy: 0.4880\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5008 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.4984 - val_loss: 0.6936 - val_accuracy: 0.4988\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6941 - val_accuracy: 0.4856\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.5108\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5164 - val_loss: 0.6950 - val_accuracy: 0.4880\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6941 - val_accuracy: 0.5108\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6936 - val_accuracy: 0.5004\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6935 - accuracy: 0.5112 - val_loss: 0.6944 - val_accuracy: 0.4888\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 1s 334us/sample - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6937 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.5112\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6950 - val_accuracy: 0.4872\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.5072\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 1s 325us/sample - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6949 - val_accuracy: 0.4868\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6944 - val_accuracy: 0.4912\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6936 - accuracy: 0.5096 - val_loss: 0.6935 - val_accuracy: 0.5120\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6940 - val_accuracy: 0.5104\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6940 - val_accuracy: 0.5108\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6940 - accuracy: 0.5008 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6940 - accuracy: 0.4960 - val_loss: 0.6935 - val_accuracy: 0.5120\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5028 - val_loss: 0.6939 - val_accuracy: 0.4880\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5080 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6947 - val_accuracy: 0.4880\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6932 - accuracy: 0.5196 - val_loss: 0.6941 - val_accuracy: 0.4860\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6941 - accuracy: 0.4892 - val_loss: 0.6935 - val_accuracy: 0.5112\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6933 - accuracy: 0.5152 - val_loss: 0.6941 - val_accuracy: 0.5104\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6929 - accuracy: 0.5156 - val_loss: 0.6979 - val_accuracy: 0.4904\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6946 - val_accuracy: 0.4856\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.5112 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6933 - accuracy: 0.5216 - val_loss: 0.6967 - val_accuracy: 0.4904\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6934 - accuracy: 0.5040 - val_loss: 0.6935 - val_accuracy: 0.5112\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.5064 - val_loss: 0.6937 - val_accuracy: 0.5124\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6929 - accuracy: 0.5144 - val_loss: 0.6992 - val_accuracy: 0.4908\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6942 - accuracy: 0.5064 - val_loss: 0.6935 - val_accuracy: 0.5084\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5144 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6935 - val_accuracy: 0.5092\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 1s 313us/sample - loss: 0.6940 - accuracy: 0.5068 - val_loss: 0.6938 - val_accuracy: 0.4884\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 1s 314us/sample - loss: 0.6936 - accuracy: 0.4996 - val_loss: 0.6955 - val_accuracy: 0.4912\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6936 - val_accuracy: 0.5008\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6936 - accuracy: 0.5060 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.4976 - val_loss: 0.6936 - val_accuracy: 0.5028\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6951 - val_accuracy: 0.4892\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5092 - val_loss: 0.6957 - val_accuracy: 0.4924\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6939 - accuracy: 0.5020 - val_loss: 0.6950 - val_accuracy: 0.4876\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6936 - val_accuracy: 0.5040\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.5052\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.5044\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6936 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.5100\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5088 - val_loss: 0.6952 - val_accuracy: 0.4892\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6938 - accuracy: 0.5032 - val_loss: 0.6937 - val_accuracy: 0.4940\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6936 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.4924\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6928 - accuracy: 0.5048 - val_loss: 0.6969 - val_accuracy: 0.5088\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6936 - accuracy: 0.5180 - val_loss: 0.6935 - val_accuracy: 0.5048\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6938 - val_accuracy: 0.4888\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5216 - val_loss: 0.6941 - val_accuracy: 0.4892\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6941 - val_accuracy: 0.5096\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6938 - accuracy: 0.4976 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6941 - accuracy: 0.4984 - val_loss: 0.6944 - val_accuracy: 0.4852\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6933 - accuracy: 0.5112 - val_loss: 0.6936 - val_accuracy: 0.5080\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6939 - accuracy: 0.5012 - val_loss: 0.6941 - val_accuracy: 0.4872\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6938 - accuracy: 0.4964 - val_loss: 0.6936 - val_accuracy: 0.5080\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6936 - accuracy: 0.5188 - val_loss: 0.6937 - val_accuracy: 0.5012\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5128 - val_loss: 0.6959 - val_accuracy: 0.5092\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6939 - accuracy: 0.5024 - val_loss: 0.6937 - val_accuracy: 0.5120\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 1s 329us/sample - loss: 0.6932 - accuracy: 0.5156 - val_loss: 0.6939 - val_accuracy: 0.4848\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5144 - val_loss: 0.6935 - val_accuracy: 0.5084\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6941 - val_accuracy: 0.5096\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6931 - accuracy: 0.5184 - val_loss: 0.6947 - val_accuracy: 0.4880\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6935 - val_accuracy: 0.5116\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6931 - accuracy: 0.5164 - val_loss: 0.6945 - val_accuracy: 0.5116\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6931 - accuracy: 0.5180 - val_loss: 0.6955 - val_accuracy: 0.4924\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6935 - accuracy: 0.5096 - val_loss: 0.6956 - val_accuracy: 0.4912\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6930 - accuracy: 0.5196 - val_loss: 0.6961 - val_accuracy: 0.4916\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6928 - accuracy: 0.5080 - val_loss: 0.6954 - val_accuracy: 0.5084\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6939 - accuracy: 0.5016 - val_loss: 0.6940 - val_accuracy: 0.5092\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.5052 - val_loss: 0.6947 - val_accuracy: 0.4860\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6935 - accuracy: 0.4964 - val_loss: 0.6947 - val_accuracy: 0.5124\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6944 - val_accuracy: 0.5112\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6925 - accuracy: 0.5260 - val_loss: 0.6937 - val_accuracy: 0.5044\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6936 - accuracy: 0.5024 - val_loss: 0.6952 - val_accuracy: 0.4876\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6933 - accuracy: 0.5156 - val_loss: 0.6936 - val_accuracy: 0.5072\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6936 - accuracy: 0.5136 - val_loss: 0.6939 - val_accuracy: 0.5132\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6937 - accuracy: 0.5064 - val_loss: 0.6948 - val_accuracy: 0.4844\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6935 - accuracy: 0.5132 - val_loss: 0.6936 - val_accuracy: 0.5100\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6932 - accuracy: 0.5092 - val_loss: 0.6959 - val_accuracy: 0.4908\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6953 - val_accuracy: 0.4876\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6935 - accuracy: 0.5168 - val_loss: 0.6936 - val_accuracy: 0.5084\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6938 - val_accuracy: 0.5116\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6936 - val_accuracy: 0.5072\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6941 - val_accuracy: 0.4868\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6935 - accuracy: 0.5084 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6934 - accuracy: 0.5104 - val_loss: 0.6936 - val_accuracy: 0.5060\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.5068\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6935 - accuracy: 0.5160 - val_loss: 0.6946 - val_accuracy: 0.4852\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6933 - accuracy: 0.5188 - val_loss: 0.6940 - val_accuracy: 0.4868\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5120 - val_loss: 0.6936 - val_accuracy: 0.5064\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6937 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.5092\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 1s 328us/sample - loss: 0.6937 - accuracy: 0.4952 - val_loss: 0.6942 - val_accuracy: 0.4844\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6936 - accuracy: 0.5016 - val_loss: 0.6946 - val_accuracy: 0.4812\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6960 - val_accuracy: 0.5104\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6938 - accuracy: 0.5124 - val_loss: 0.6949 - val_accuracy: 0.4888\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6936 - val_accuracy: 0.5072\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.6936 - val_accuracy: 0.5064\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6935 - accuracy: 0.5184 - val_loss: 0.6936 - val_accuracy: 0.5080\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6933 - accuracy: 0.5048 - val_loss: 0.6970 - val_accuracy: 0.4896\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6940 - accuracy: 0.4952 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6932 - accuracy: 0.5180 - val_loss: 0.6936 - val_accuracy: 0.5056\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.5056\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6936 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.4860\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.5056\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6934 - accuracy: 0.5136 - val_loss: 0.6942 - val_accuracy: 0.4892\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6937 - accuracy: 0.5072 - val_loss: 0.6946 - val_accuracy: 0.4844\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6934 - accuracy: 0.5096 - val_loss: 0.6937 - val_accuracy: 0.5032\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 1s 323us/sample - loss: 0.6939 - accuracy: 0.4972 - val_loss: 0.6936 - val_accuracy: 0.5064\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 1s 320us/sample - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6946 - val_accuracy: 0.4816\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.5044\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 1s 321us/sample - loss: 0.6935 - accuracy: 0.5032 - val_loss: 0.6942 - val_accuracy: 0.4864\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 1s 317us/sample - loss: 0.6930 - accuracy: 0.5124 - val_loss: 0.6962 - val_accuracy: 0.5104\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6938 - accuracy: 0.5128 - val_loss: 0.6937 - val_accuracy: 0.5112\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6958 - val_accuracy: 0.4908\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6955 - val_accuracy: 0.4876\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6936 - accuracy: 0.5068 - val_loss: 0.6939 - val_accuracy: 0.5044\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6939 - accuracy: 0.4976 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5072 - val_loss: 0.6938 - val_accuracy: 0.5092\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 1s 326us/sample - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6954 - val_accuracy: 0.4892\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5044\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6930 - accuracy: 0.5188 - val_loss: 0.6941 - val_accuracy: 0.5128\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6935 - accuracy: 0.5132 - val_loss: 0.6948 - val_accuracy: 0.4872\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 1s 318us/sample - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.4856\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 1s 316us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6934 - accuracy: 0.4968 - val_loss: 0.6938 - val_accuracy: 0.5108\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 1s 319us/sample - loss: 0.6933 - accuracy: 0.5116 - val_loss: 0.6940 - val_accuracy: 0.4960\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 1s 322us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6942 - val_accuracy: 0.4852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5028</td></tr><tr><td>loss</td><td>0.6933</td></tr><tr><td>val_accuracy</td><td>0.4852</td></tr><tr><td>val_loss</td><td>0.69415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">amber-sweep-1</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/ziqfk2my\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/ziqfk2my</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_220212-ziqfk2my\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zjxh0exl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: SimpleRNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_220821-zjxh0exl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/zjxh0exl\" target=\"_blank\">toasty-sweep-2</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 4.1565 - accuracy: 0.5032 - val_loss: 4.0615 - val_accuracy: 0.5036\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 3.9255 - accuracy: 0.5044 - val_loss: 3.9463 - val_accuracy: 0.5040\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 3.7598 - accuracy: 0.5008 - val_loss: 3.7166 - val_accuracy: 0.5020\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 3.6174 - accuracy: 0.5000 - val_loss: 3.6446 - val_accuracy: 0.4996\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 3.5121 - accuracy: 0.5016 - val_loss: 3.5253 - val_accuracy: 0.4956\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 3.3890 - accuracy: 0.5008 - val_loss: 3.4501 - val_accuracy: 0.4948\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 3.3247 - accuracy: 0.5004 - val_loss: 3.3629 - val_accuracy: 0.4944\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 3.2508 - accuracy: 0.5004 - val_loss: 3.2799 - val_accuracy: 0.4984\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 3.1812 - accuracy: 0.4968 - val_loss: 3.1920 - val_accuracy: 0.4992\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 3.1283 - accuracy: 0.4968 - val_loss: 3.1242 - val_accuracy: 0.4988\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 3.0479 - accuracy: 0.4980 - val_loss: 3.0150 - val_accuracy: 0.4984\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 32us/sample - loss: 2.9342 - accuracy: 0.4992 - val_loss: 2.8849 - val_accuracy: 0.4952\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 2.8222 - accuracy: 0.5016 - val_loss: 2.7514 - val_accuracy: 0.4948\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 2.6308 - accuracy: 0.5016 - val_loss: 2.5276 - val_accuracy: 0.4956\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 2.2303 - accuracy: 0.5036 - val_loss: 2.1184 - val_accuracy: 0.4992\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 1.7824 - accuracy: 0.4984 - val_loss: 1.6925 - val_accuracy: 0.4980\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 1.4506 - accuracy: 0.4976 - val_loss: 1.3315 - val_accuracy: 0.4988\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 1.1821 - accuracy: 0.5000 - val_loss: 1.1340 - val_accuracy: 0.4984\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 1.0416 - accuracy: 0.4932 - val_loss: 1.0106 - val_accuracy: 0.5020\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.9207 - accuracy: 0.4940 - val_loss: 0.8871 - val_accuracy: 0.5008\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.8458 - accuracy: 0.4924 - val_loss: 0.8232 - val_accuracy: 0.5012\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.8149 - accuracy: 0.4916 - val_loss: 0.8083 - val_accuracy: 0.5012\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7942 - accuracy: 0.4920 - val_loss: 0.7980 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7857 - accuracy: 0.4912 - val_loss: 0.7902 - val_accuracy: 0.4984\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7789 - accuracy: 0.4904 - val_loss: 0.7837 - val_accuracy: 0.4992\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7728 - accuracy: 0.4916 - val_loss: 0.7779 - val_accuracy: 0.5012\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7674 - accuracy: 0.4936 - val_loss: 0.7727 - val_accuracy: 0.5016\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7628 - accuracy: 0.4944 - val_loss: 0.7681 - val_accuracy: 0.5024\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7587 - accuracy: 0.4980 - val_loss: 0.7642 - val_accuracy: 0.5008\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7551 - accuracy: 0.4968 - val_loss: 0.7606 - val_accuracy: 0.5020\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7516 - accuracy: 0.4952 - val_loss: 0.7573 - val_accuracy: 0.5024\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7485 - accuracy: 0.4976 - val_loss: 0.7544 - val_accuracy: 0.5008\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7455 - accuracy: 0.4956 - val_loss: 0.7514 - val_accuracy: 0.4992\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7428 - accuracy: 0.4972 - val_loss: 0.7486 - val_accuracy: 0.4968\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7402 - accuracy: 0.4976 - val_loss: 0.7463 - val_accuracy: 0.4972\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7380 - accuracy: 0.4996 - val_loss: 0.7442 - val_accuracy: 0.4948\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7360 - accuracy: 0.5008 - val_loss: 0.7422 - val_accuracy: 0.4944\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.7342 - accuracy: 0.5004 - val_loss: 0.7405 - val_accuracy: 0.4976\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7324 - accuracy: 0.4984 - val_loss: 0.7388 - val_accuracy: 0.4992\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7309 - accuracy: 0.4988 - val_loss: 0.7375 - val_accuracy: 0.4980\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7295 - accuracy: 0.4976 - val_loss: 0.7361 - val_accuracy: 0.4952\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7281 - accuracy: 0.4976 - val_loss: 0.7348 - val_accuracy: 0.4952\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7269 - accuracy: 0.5004 - val_loss: 0.7336 - val_accuracy: 0.4952\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7258 - accuracy: 0.4996 - val_loss: 0.7326 - val_accuracy: 0.4964\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7247 - accuracy: 0.4992 - val_loss: 0.7315 - val_accuracy: 0.4980\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7237 - accuracy: 0.4996 - val_loss: 0.7306 - val_accuracy: 0.4980\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7228 - accuracy: 0.5004 - val_loss: 0.7297 - val_accuracy: 0.4972\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7219 - accuracy: 0.5016 - val_loss: 0.7289 - val_accuracy: 0.4952\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7211 - accuracy: 0.5040 - val_loss: 0.7282 - val_accuracy: 0.4956\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7204 - accuracy: 0.5016 - val_loss: 0.7275 - val_accuracy: 0.4964\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7197 - accuracy: 0.5020 - val_loss: 0.7269 - val_accuracy: 0.4964\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7191 - accuracy: 0.5024 - val_loss: 0.7262 - val_accuracy: 0.4964\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7185 - accuracy: 0.5036 - val_loss: 0.7257 - val_accuracy: 0.4976\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7180 - accuracy: 0.5044 - val_loss: 0.7252 - val_accuracy: 0.4952\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7176 - accuracy: 0.5056 - val_loss: 0.7249 - val_accuracy: 0.4944\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7171 - accuracy: 0.5100 - val_loss: 0.7244 - val_accuracy: 0.4964\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7167 - accuracy: 0.5096 - val_loss: 0.7240 - val_accuracy: 0.4964\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7163 - accuracy: 0.5096 - val_loss: 0.7237 - val_accuracy: 0.4976\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7159 - accuracy: 0.5128 - val_loss: 0.7233 - val_accuracy: 0.4944\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7155 - accuracy: 0.5136 - val_loss: 0.7230 - val_accuracy: 0.4936\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7153 - accuracy: 0.5152 - val_loss: 0.7227 - val_accuracy: 0.4932\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7149 - accuracy: 0.5156 - val_loss: 0.7224 - val_accuracy: 0.4940\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.7145 - accuracy: 0.5144 - val_loss: 0.7220 - val_accuracy: 0.4940\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7143 - accuracy: 0.5172 - val_loss: 0.7217 - val_accuracy: 0.4948\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7139 - accuracy: 0.5168 - val_loss: 0.7213 - val_accuracy: 0.4932\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7137 - accuracy: 0.5164 - val_loss: 0.7211 - val_accuracy: 0.4920\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7134 - accuracy: 0.5176 - val_loss: 0.7209 - val_accuracy: 0.4924\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7131 - accuracy: 0.5144 - val_loss: 0.7206 - val_accuracy: 0.4912\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7128 - accuracy: 0.5140 - val_loss: 0.7204 - val_accuracy: 0.4940\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7126 - accuracy: 0.5132 - val_loss: 0.7201 - val_accuracy: 0.4924\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7124 - accuracy: 0.5116 - val_loss: 0.7199 - val_accuracy: 0.4936\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7122 - accuracy: 0.5132 - val_loss: 0.7197 - val_accuracy: 0.4928\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7120 - accuracy: 0.5136 - val_loss: 0.7195 - val_accuracy: 0.4944\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7117 - accuracy: 0.5128 - val_loss: 0.7192 - val_accuracy: 0.4936\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7115 - accuracy: 0.5120 - val_loss: 0.7190 - val_accuracy: 0.4940\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7113 - accuracy: 0.5124 - val_loss: 0.7188 - val_accuracy: 0.4936\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7110 - accuracy: 0.5124 - val_loss: 0.7185 - val_accuracy: 0.4932\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7108 - accuracy: 0.5096 - val_loss: 0.7182 - val_accuracy: 0.4936\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7106 - accuracy: 0.5104 - val_loss: 0.7179 - val_accuracy: 0.4932\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7105 - accuracy: 0.5088 - val_loss: 0.7178 - val_accuracy: 0.4928\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7102 - accuracy: 0.5080 - val_loss: 0.7176 - val_accuracy: 0.4928\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7101 - accuracy: 0.5076 - val_loss: 0.7174 - val_accuracy: 0.4920\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7098 - accuracy: 0.5096 - val_loss: 0.7172 - val_accuracy: 0.4900\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7096 - accuracy: 0.5100 - val_loss: 0.7170 - val_accuracy: 0.4904\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7095 - accuracy: 0.5072 - val_loss: 0.7167 - val_accuracy: 0.4908\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7092 - accuracy: 0.5088 - val_loss: 0.7166 - val_accuracy: 0.4908\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.7092 - accuracy: 0.5096 - val_loss: 0.7165 - val_accuracy: 0.4920\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7089 - accuracy: 0.5076 - val_loss: 0.7162 - val_accuracy: 0.4916\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7087 - accuracy: 0.5108 - val_loss: 0.7160 - val_accuracy: 0.4900\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7085 - accuracy: 0.5132 - val_loss: 0.7159 - val_accuracy: 0.4892\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7083 - accuracy: 0.5120 - val_loss: 0.7157 - val_accuracy: 0.4888\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7081 - accuracy: 0.5124 - val_loss: 0.7155 - val_accuracy: 0.4872\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7079 - accuracy: 0.5116 - val_loss: 0.7152 - val_accuracy: 0.4880\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7077 - accuracy: 0.5124 - val_loss: 0.7150 - val_accuracy: 0.4880\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7075 - accuracy: 0.5136 - val_loss: 0.7147 - val_accuracy: 0.4884\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7073 - accuracy: 0.5144 - val_loss: 0.7145 - val_accuracy: 0.4880\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7071 - accuracy: 0.5116 - val_loss: 0.7142 - val_accuracy: 0.4876\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7069 - accuracy: 0.5136 - val_loss: 0.7140 - val_accuracy: 0.4836\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7068 - accuracy: 0.5120 - val_loss: 0.7138 - val_accuracy: 0.4872\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7065 - accuracy: 0.5120 - val_loss: 0.7135 - val_accuracy: 0.4868\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7064 - accuracy: 0.5124 - val_loss: 0.7133 - val_accuracy: 0.4872\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7062 - accuracy: 0.5108 - val_loss: 0.7131 - val_accuracy: 0.4880\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7060 - accuracy: 0.5144 - val_loss: 0.7129 - val_accuracy: 0.4872\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7058 - accuracy: 0.5152 - val_loss: 0.7127 - val_accuracy: 0.4848\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7057 - accuracy: 0.5164 - val_loss: 0.7125 - val_accuracy: 0.4848\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7055 - accuracy: 0.5164 - val_loss: 0.7124 - val_accuracy: 0.4868\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7053 - accuracy: 0.5160 - val_loss: 0.7121 - val_accuracy: 0.4872\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7051 - accuracy: 0.5156 - val_loss: 0.7119 - val_accuracy: 0.4884\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7050 - accuracy: 0.5168 - val_loss: 0.7117 - val_accuracy: 0.4880\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.7049 - accuracy: 0.5140 - val_loss: 0.7115 - val_accuracy: 0.4904\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7046 - accuracy: 0.5156 - val_loss: 0.7112 - val_accuracy: 0.4900\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7044 - accuracy: 0.5148 - val_loss: 0.7111 - val_accuracy: 0.4852\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7043 - accuracy: 0.5156 - val_loss: 0.7109 - val_accuracy: 0.4864\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7040 - accuracy: 0.5136 - val_loss: 0.7105 - val_accuracy: 0.4888\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7039 - accuracy: 0.5160 - val_loss: 0.7103 - val_accuracy: 0.4872\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7037 - accuracy: 0.5156 - val_loss: 0.7101 - val_accuracy: 0.4884\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7035 - accuracy: 0.5140 - val_loss: 0.7099 - val_accuracy: 0.4868\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7034 - accuracy: 0.5132 - val_loss: 0.7097 - val_accuracy: 0.4900\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7032 - accuracy: 0.5104 - val_loss: 0.7095 - val_accuracy: 0.4876\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7030 - accuracy: 0.5132 - val_loss: 0.7094 - val_accuracy: 0.4872\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7029 - accuracy: 0.5120 - val_loss: 0.7092 - val_accuracy: 0.4884\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7027 - accuracy: 0.5140 - val_loss: 0.7092 - val_accuracy: 0.4852\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7024 - accuracy: 0.5152 - val_loss: 0.7091 - val_accuracy: 0.4856\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7024 - accuracy: 0.5156 - val_loss: 0.7089 - val_accuracy: 0.4876\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7022 - accuracy: 0.5176 - val_loss: 0.7088 - val_accuracy: 0.4852\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7021 - accuracy: 0.5180 - val_loss: 0.7085 - val_accuracy: 0.4844\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7019 - accuracy: 0.5160 - val_loss: 0.7083 - val_accuracy: 0.4860\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7018 - accuracy: 0.5164 - val_loss: 0.7081 - val_accuracy: 0.4836\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7016 - accuracy: 0.5168 - val_loss: 0.7081 - val_accuracy: 0.4848\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7015 - accuracy: 0.5184 - val_loss: 0.7081 - val_accuracy: 0.4836\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.7012 - accuracy: 0.5188 - val_loss: 0.7076 - val_accuracy: 0.4868\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7012 - accuracy: 0.5160 - val_loss: 0.7073 - val_accuracy: 0.4856\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7010 - accuracy: 0.5132 - val_loss: 0.7073 - val_accuracy: 0.4868\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7008 - accuracy: 0.5148 - val_loss: 0.7070 - val_accuracy: 0.4880\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7007 - accuracy: 0.5160 - val_loss: 0.7066 - val_accuracy: 0.4896\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7006 - accuracy: 0.5172 - val_loss: 0.7065 - val_accuracy: 0.4852\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.7006 - accuracy: 0.5148 - val_loss: 0.7063 - val_accuracy: 0.4888\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.7003 - accuracy: 0.5180 - val_loss: 0.7063 - val_accuracy: 0.4852\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.7001 - accuracy: 0.5204 - val_loss: 0.7063 - val_accuracy: 0.4892\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6999 - accuracy: 0.5148 - val_loss: 0.7059 - val_accuracy: 0.4848\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6998 - accuracy: 0.5192 - val_loss: 0.7058 - val_accuracy: 0.4868\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6997 - accuracy: 0.5184 - val_loss: 0.7056 - val_accuracy: 0.4868\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6996 - accuracy: 0.5148 - val_loss: 0.7056 - val_accuracy: 0.4836\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6995 - accuracy: 0.5180 - val_loss: 0.7055 - val_accuracy: 0.4840\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6993 - accuracy: 0.5172 - val_loss: 0.7052 - val_accuracy: 0.4840\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6992 - accuracy: 0.5188 - val_loss: 0.7052 - val_accuracy: 0.4868\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6990 - accuracy: 0.5176 - val_loss: 0.7050 - val_accuracy: 0.4860\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6990 - accuracy: 0.5216 - val_loss: 0.7048 - val_accuracy: 0.4860\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6986 - accuracy: 0.5192 - val_loss: 0.7047 - val_accuracy: 0.4840\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6987 - accuracy: 0.5172 - val_loss: 0.7046 - val_accuracy: 0.4844\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6987 - accuracy: 0.5172 - val_loss: 0.7045 - val_accuracy: 0.4872\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 32us/sample - loss: 0.6985 - accuracy: 0.5192 - val_loss: 0.7045 - val_accuracy: 0.4844\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6983 - accuracy: 0.5168 - val_loss: 0.7041 - val_accuracy: 0.4828\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6981 - accuracy: 0.5204 - val_loss: 0.7041 - val_accuracy: 0.4872\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6980 - accuracy: 0.5176 - val_loss: 0.7036 - val_accuracy: 0.4824\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 29us/sample - loss: 0.6980 - accuracy: 0.5156 - val_loss: 0.7037 - val_accuracy: 0.4832\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6980 - accuracy: 0.5180 - val_loss: 0.7036 - val_accuracy: 0.4872\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6978 - accuracy: 0.5144 - val_loss: 0.7033 - val_accuracy: 0.4872\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6978 - accuracy: 0.5168 - val_loss: 0.7031 - val_accuracy: 0.4884\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6974 - accuracy: 0.5164 - val_loss: 0.7031 - val_accuracy: 0.4848\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6973 - accuracy: 0.5156 - val_loss: 0.7031 - val_accuracy: 0.4828\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6972 - accuracy: 0.5156 - val_loss: 0.7028 - val_accuracy: 0.4848\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6971 - accuracy: 0.5216 - val_loss: 0.7029 - val_accuracy: 0.4828\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6970 - accuracy: 0.5188 - val_loss: 0.7024 - val_accuracy: 0.4840\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6969 - accuracy: 0.5176 - val_loss: 0.7025 - val_accuracy: 0.4860\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6970 - accuracy: 0.5156 - val_loss: 0.7026 - val_accuracy: 0.4916\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6968 - accuracy: 0.5176 - val_loss: 0.7024 - val_accuracy: 0.4864\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6966 - accuracy: 0.5192 - val_loss: 0.7021 - val_accuracy: 0.4824\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6966 - accuracy: 0.5208 - val_loss: 0.7019 - val_accuracy: 0.4848\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6964 - accuracy: 0.5136 - val_loss: 0.7016 - val_accuracy: 0.4816\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6963 - accuracy: 0.5132 - val_loss: 0.7018 - val_accuracy: 0.4856\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6961 - accuracy: 0.5188 - val_loss: 0.7018 - val_accuracy: 0.4876\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6961 - accuracy: 0.5176 - val_loss: 0.7019 - val_accuracy: 0.4860\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6959 - accuracy: 0.5188 - val_loss: 0.7016 - val_accuracy: 0.4868\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6959 - accuracy: 0.5160 - val_loss: 0.7013 - val_accuracy: 0.4856\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.6958 - accuracy: 0.5180 - val_loss: 0.7013 - val_accuracy: 0.4880\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6956 - accuracy: 0.5200 - val_loss: 0.7014 - val_accuracy: 0.4872\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6957 - accuracy: 0.5148 - val_loss: 0.7011 - val_accuracy: 0.4888\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6956 - accuracy: 0.5148 - val_loss: 0.7006 - val_accuracy: 0.4864\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6955 - accuracy: 0.5164 - val_loss: 0.7008 - val_accuracy: 0.4920\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6955 - accuracy: 0.5136 - val_loss: 0.7008 - val_accuracy: 0.4864\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6953 - accuracy: 0.5164 - val_loss: 0.7007 - val_accuracy: 0.4844\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6952 - accuracy: 0.5156 - val_loss: 0.7004 - val_accuracy: 0.4888\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6953 - accuracy: 0.5168 - val_loss: 0.7006 - val_accuracy: 0.4840\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6950 - accuracy: 0.5224 - val_loss: 0.7007 - val_accuracy: 0.4876\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6950 - accuracy: 0.5196 - val_loss: 0.7004 - val_accuracy: 0.4836\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6949 - accuracy: 0.5188 - val_loss: 0.7004 - val_accuracy: 0.4872\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6948 - accuracy: 0.5216 - val_loss: 0.7003 - val_accuracy: 0.4860\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 28us/sample - loss: 0.6947 - accuracy: 0.5176 - val_loss: 0.6999 - val_accuracy: 0.4884\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6947 - accuracy: 0.5196 - val_loss: 0.6997 - val_accuracy: 0.4924\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6946 - accuracy: 0.5156 - val_loss: 0.6998 - val_accuracy: 0.4876\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6946 - accuracy: 0.5144 - val_loss: 0.6994 - val_accuracy: 0.4868\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6948 - accuracy: 0.5164 - val_loss: 0.6996 - val_accuracy: 0.4848\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 26us/sample - loss: 0.6945 - accuracy: 0.5136 - val_loss: 0.6996 - val_accuracy: 0.4896\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6945 - accuracy: 0.5180 - val_loss: 0.6997 - val_accuracy: 0.4876\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6942 - accuracy: 0.5244 - val_loss: 0.6997 - val_accuracy: 0.4908\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6941 - accuracy: 0.5200 - val_loss: 0.6996 - val_accuracy: 0.4824\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 31us/sample - loss: 0.6943 - accuracy: 0.5216 - val_loss: 0.6995 - val_accuracy: 0.4848\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6940 - accuracy: 0.5172 - val_loss: 0.6991 - val_accuracy: 0.4896\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 27us/sample - loss: 0.6940 - accuracy: 0.5148 - val_loss: 0.6993 - val_accuracy: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5148</td></tr><tr><td>loss</td><td>0.694</td></tr><tr><td>val_accuracy</td><td>0.4868</td></tr><tr><td>val_loss</td><td>0.69931</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">toasty-sweep-2</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/zjxh0exl\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/zjxh0exl</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_220821-zjxh0exl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: crp5tafr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_220920-crp5tafr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/crp5tafr\" target=\"_blank\">snowy-sweep-3</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 0s 182us/sample - loss: 2.7702 - accuracy: 0.5016 - val_loss: 1.3927 - val_accuracy: 0.5088\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 1.0368 - accuracy: 0.5016 - val_loss: 0.8758 - val_accuracy: 0.5088\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.8427 - accuracy: 0.5016 - val_loss: 0.8070 - val_accuracy: 0.5088\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.7884 - accuracy: 0.5016 - val_loss: 0.7617 - val_accuracy: 0.5084\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.7472 - accuracy: 0.5012 - val_loss: 0.7278 - val_accuracy: 0.5088\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.7182 - accuracy: 0.5000 - val_loss: 0.7075 - val_accuracy: 0.5116\n",
      "Epoch 7/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.7028 - accuracy: 0.5068 - val_loss: 0.6986 - val_accuracy: 0.5148\n",
      "Epoch 8/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6965 - accuracy: 0.5044 - val_loss: 0.6960 - val_accuracy: 0.5096\n",
      "Epoch 9/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6948 - accuracy: 0.5036 - val_loss: 0.6957 - val_accuracy: 0.5024\n",
      "Epoch 10/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6945 - accuracy: 0.5096 - val_loss: 0.6955 - val_accuracy: 0.5016\n",
      "Epoch 11/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6945 - accuracy: 0.5036 - val_loss: 0.6956 - val_accuracy: 0.4928\n",
      "Epoch 12/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6945 - accuracy: 0.5164 - val_loss: 0.6952 - val_accuracy: 0.4980\n",
      "Epoch 13/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6942 - accuracy: 0.5124 - val_loss: 0.6950 - val_accuracy: 0.5068\n",
      "Epoch 14/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6941 - accuracy: 0.5112 - val_loss: 0.6949 - val_accuracy: 0.5008\n",
      "Epoch 15/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6940 - accuracy: 0.5140 - val_loss: 0.6947 - val_accuracy: 0.5084\n",
      "Epoch 16/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6945 - val_accuracy: 0.5056\n",
      "Epoch 17/100\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6939 - accuracy: 0.5152 - val_loss: 0.6944 - val_accuracy: 0.5064\n",
      "Epoch 18/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5128 - val_loss: 0.6943 - val_accuracy: 0.5072\n",
      "Epoch 19/100\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6939 - accuracy: 0.5136 - val_loss: 0.6943 - val_accuracy: 0.5056\n",
      "Epoch 20/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5148 - val_loss: 0.6942 - val_accuracy: 0.5048\n",
      "Epoch 21/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6936 - accuracy: 0.5100 - val_loss: 0.6946 - val_accuracy: 0.4900\n",
      "Epoch 22/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6939 - accuracy: 0.5116 - val_loss: 0.6942 - val_accuracy: 0.4940\n",
      "Epoch 23/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5096 - val_loss: 0.6943 - val_accuracy: 0.4896\n",
      "Epoch 24/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6936 - accuracy: 0.5136 - val_loss: 0.6942 - val_accuracy: 0.4892\n",
      "Epoch 25/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5180 - val_loss: 0.6938 - val_accuracy: 0.5064\n",
      "Epoch 26/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5140 - val_loss: 0.6938 - val_accuracy: 0.5084\n",
      "Epoch 27/100\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6936 - accuracy: 0.5108 - val_loss: 0.6937 - val_accuracy: 0.5088\n",
      "Epoch 28/100\n",
      "2500/2500 [==============================] - 0s 98us/sample - loss: 0.6934 - accuracy: 0.5156 - val_loss: 0.6938 - val_accuracy: 0.4992\n",
      "Epoch 29/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6934 - accuracy: 0.5168 - val_loss: 0.6938 - val_accuracy: 0.5044\n",
      "Epoch 30/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5164 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
      "Epoch 31/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6936 - accuracy: 0.5236 - val_loss: 0.6940 - val_accuracy: 0.4832\n",
      "Epoch 32/100\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6936 - accuracy: 0.5072 - val_loss: 0.6938 - val_accuracy: 0.5004\n",
      "Epoch 33/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5140 - val_loss: 0.6944 - val_accuracy: 0.4916\n",
      "Epoch 34/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5096 - val_loss: 0.6938 - val_accuracy: 0.4944\n",
      "Epoch 35/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6934 - accuracy: 0.5208 - val_loss: 0.6935 - val_accuracy: 0.5092\n",
      "Epoch 36/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.5088 - val_loss: 0.6935 - val_accuracy: 0.5112\n",
      "Epoch 37/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6937 - accuracy: 0.4976 - val_loss: 0.6935 - val_accuracy: 0.5056\n",
      "Epoch 38/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6935 - val_accuracy: 0.4968\n",
      "Epoch 39/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
      "Epoch 40/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5096 - val_loss: 0.6934 - val_accuracy: 0.5104\n",
      "Epoch 41/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 42/100\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6938 - accuracy: 0.5016 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 43/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.6939 - val_accuracy: 0.4872\n",
      "Epoch 44/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6943 - val_accuracy: 0.4932\n",
      "Epoch 45/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6939 - accuracy: 0.4968 - val_loss: 0.6944 - val_accuracy: 0.4932\n",
      "Epoch 46/100\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.4860\n",
      "Epoch 47/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6938 - val_accuracy: 0.4836\n",
      "Epoch 48/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5052 - val_loss: 0.6939 - val_accuracy: 0.4868\n",
      "Epoch 49/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.4956\n",
      "Epoch 50/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5072 - val_loss: 0.6936 - val_accuracy: 0.4980\n",
      "Epoch 51/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5088 - val_loss: 0.6935 - val_accuracy: 0.5016\n",
      "Epoch 52/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6937 - accuracy: 0.5116 - val_loss: 0.6936 - val_accuracy: 0.4996\n",
      "Epoch 53/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6936 - accuracy: 0.5180 - val_loss: 0.6934 - val_accuracy: 0.5064\n",
      "Epoch 54/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5084 - val_loss: 0.6935 - val_accuracy: 0.5036\n",
      "Epoch 55/100\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6934 - val_accuracy: 0.5084\n",
      "Epoch 56/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5192 - val_loss: 0.6950 - val_accuracy: 0.4920\n",
      "Epoch 57/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6938 - accuracy: 0.4904 - val_loss: 0.6936 - val_accuracy: 0.4908\n",
      "Epoch 58/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6936 - accuracy: 0.5108 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 59/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6943 - accuracy: 0.5032 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 60/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6943 - val_accuracy: 0.4864\n",
      "Epoch 61/100\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6932 - accuracy: 0.5152 - val_loss: 0.6941 - val_accuracy: 0.5084\n",
      "Epoch 62/100\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.5088\n",
      "Epoch 63/100\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6945 - accuracy: 0.4968 - val_loss: 0.6934 - val_accuracy: 0.5048\n",
      "Epoch 64/100\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6937 - accuracy: 0.4988 - val_loss: 0.6934 - val_accuracy: 0.5172\n",
      "Epoch 65/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6933 - val_accuracy: 0.5100\n",
      "Epoch 66/100\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.5128 - val_loss: 0.6934 - val_accuracy: 0.5180\n",
      "Epoch 67/100\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6935 - val_accuracy: 0.5020\n",
      "Epoch 68/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6940 - accuracy: 0.4964 - val_loss: 0.6934 - val_accuracy: 0.5184\n",
      "Epoch 69/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6937 - accuracy: 0.4936 - val_loss: 0.6936 - val_accuracy: 0.4896\n",
      "Epoch 70/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.5080 - val_loss: 0.6934 - val_accuracy: 0.5180\n",
      "Epoch 71/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6936 - accuracy: 0.5056 - val_loss: 0.6940 - val_accuracy: 0.4860\n",
      "Epoch 72/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6939 - accuracy: 0.5068 - val_loss: 0.6944 - val_accuracy: 0.4868\n",
      "Epoch 73/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6939 - val_accuracy: 0.4828\n",
      "Epoch 74/100\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6942 - accuracy: 0.5116 - val_loss: 0.6938 - val_accuracy: 0.4864\n",
      "Epoch 75/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6936 - val_accuracy: 0.5176\n",
      "Epoch 76/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6939 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
      "Epoch 77/100\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6943 - accuracy: 0.4900 - val_loss: 0.6939 - val_accuracy: 0.4828\n",
      "Epoch 78/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6938 - accuracy: 0.4996 - val_loss: 0.6934 - val_accuracy: 0.5104\n",
      "Epoch 79/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6943 - accuracy: 0.4864 - val_loss: 0.6934 - val_accuracy: 0.4996\n",
      "Epoch 80/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6947 - val_accuracy: 0.4880\n",
      "Epoch 81/100\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5108 - val_loss: 0.6936 - val_accuracy: 0.4996\n",
      "Epoch 82/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6943 - accuracy: 0.5068 - val_loss: 0.6936 - val_accuracy: 0.5168\n",
      "Epoch 83/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6937 - accuracy: 0.4968 - val_loss: 0.6937 - val_accuracy: 0.4864\n",
      "Epoch 84/100\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.4968 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 85/100\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6939 - accuracy: 0.5072 - val_loss: 0.6941 - val_accuracy: 0.4856\n",
      "Epoch 86/100\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6938 - accuracy: 0.5060 - val_loss: 0.6939 - val_accuracy: 0.4852\n",
      "Epoch 87/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6939 - accuracy: 0.5032 - val_loss: 0.6943 - val_accuracy: 0.5132\n",
      "Epoch 88/100\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6940 - accuracy: 0.5096 - val_loss: 0.6946 - val_accuracy: 0.4924\n",
      "Epoch 89/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6940 - accuracy: 0.4992 - val_loss: 0.6939 - val_accuracy: 0.4844\n",
      "Epoch 90/100\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.5192\n",
      "Epoch 91/100\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6939 - accuracy: 0.5016 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
      "Epoch 92/100\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6938 - accuracy: 0.5012 - val_loss: 0.6933 - val_accuracy: 0.5112\n",
      "Epoch 93/100\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6941 - accuracy: 0.5108 - val_loss: 0.6962 - val_accuracy: 0.4908\n",
      "Epoch 94/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6940 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.5140\n",
      "Epoch 95/100\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6946 - accuracy: 0.4980 - val_loss: 0.6938 - val_accuracy: 0.4808\n",
      "Epoch 96/100\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.4828\n",
      "Epoch 97/100\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6971 - val_accuracy: 0.4912\n",
      "Epoch 98/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6948 - val_accuracy: 0.4888\n",
      "Epoch 99/100\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6944 - accuracy: 0.5124 - val_loss: 0.6946 - val_accuracy: 0.4872\n",
      "Epoch 100/100\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6937 - accuracy: 0.4916 - val_loss: 0.6935 - val_accuracy: 0.5104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.4916</td></tr><tr><td>loss</td><td>0.69366</td></tr><tr><td>val_accuracy</td><td>0.5104</td></tr><tr><td>val_loss</td><td>0.69355</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-3</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/crp5tafr\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/crp5tafr</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_220920-crp5tafr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qtsryu0s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_221033-qtsryu0s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/qtsryu0s\" target=\"_blank\">classic-sweep-4</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 0s 157us/sample - loss: 1.8345 - accuracy: 0.5016 - val_loss: 0.9696 - val_accuracy: 0.5088\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.8388 - accuracy: 0.5016 - val_loss: 0.7483 - val_accuracy: 0.5088\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.7253 - accuracy: 0.4916 - val_loss: 0.7046 - val_accuracy: 0.5112\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.7054 - accuracy: 0.4852 - val_loss: 0.6997 - val_accuracy: 0.4972\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.7003 - accuracy: 0.4784 - val_loss: 0.6973 - val_accuracy: 0.4952\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6976 - accuracy: 0.4800 - val_loss: 0.6966 - val_accuracy: 0.4880\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6968 - accuracy: 0.4800 - val_loss: 0.6962 - val_accuracy: 0.4816\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6957 - accuracy: 0.4908 - val_loss: 0.6959 - val_accuracy: 0.4896\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6954 - accuracy: 0.4964 - val_loss: 0.6960 - val_accuracy: 0.4932\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6948 - accuracy: 0.4952 - val_loss: 0.6957 - val_accuracy: 0.4868\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6944 - accuracy: 0.5064 - val_loss: 0.6965 - val_accuracy: 0.4796\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6949 - accuracy: 0.4924 - val_loss: 0.6956 - val_accuracy: 0.4784\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6939 - accuracy: 0.5084 - val_loss: 0.6958 - val_accuracy: 0.5192\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6948 - accuracy: 0.4868 - val_loss: 0.6950 - val_accuracy: 0.4872\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6941 - accuracy: 0.5032 - val_loss: 0.6951 - val_accuracy: 0.4856\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6942 - accuracy: 0.5012 - val_loss: 0.6951 - val_accuracy: 0.4824\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6943 - accuracy: 0.5032 - val_loss: 0.6959 - val_accuracy: 0.4792\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6951 - accuracy: 0.5048 - val_loss: 0.6952 - val_accuracy: 0.5144\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6945 - accuracy: 0.5048 - val_loss: 0.6948 - val_accuracy: 0.4936\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6941 - accuracy: 0.4892 - val_loss: 0.6947 - val_accuracy: 0.4892\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6958 - val_accuracy: 0.4824\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6937 - accuracy: 0.5096 - val_loss: 0.6946 - val_accuracy: 0.5076\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6941 - accuracy: 0.4948 - val_loss: 0.6945 - val_accuracy: 0.5052\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6936 - accuracy: 0.4984 - val_loss: 0.6944 - val_accuracy: 0.4912\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6935 - accuracy: 0.5040 - val_loss: 0.6943 - val_accuracy: 0.4972\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6942 - val_accuracy: 0.4972\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6938 - accuracy: 0.4900 - val_loss: 0.6941 - val_accuracy: 0.4980\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6935 - accuracy: 0.4896 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.5128 - val_loss: 0.6947 - val_accuracy: 0.4900\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6932 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.5088\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.5004 - val_loss: 0.6951 - val_accuracy: 0.4904\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6947 - accuracy: 0.4988 - val_loss: 0.6942 - val_accuracy: 0.4888\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6938 - val_accuracy: 0.5044\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.4944 - val_loss: 0.6941 - val_accuracy: 0.4896\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6952 - val_accuracy: 0.4888\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.5024\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6943 - val_accuracy: 0.5100\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6949 - val_accuracy: 0.4924\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6931 - accuracy: 0.5148 - val_loss: 0.6942 - val_accuracy: 0.4916\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6931 - accuracy: 0.5044 - val_loss: 0.6935 - val_accuracy: 0.5080\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6936 - val_accuracy: 0.5124\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.4956 - val_loss: 0.6937 - val_accuracy: 0.5112\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6931 - accuracy: 0.4972 - val_loss: 0.6936 - val_accuracy: 0.5108\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6929 - accuracy: 0.5064 - val_loss: 0.6944 - val_accuracy: 0.4872\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6941 - val_accuracy: 0.4904\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6938 - accuracy: 0.4992 - val_loss: 0.6949 - val_accuracy: 0.4904\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6986 - val_accuracy: 0.4904\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.5100 - val_loss: 0.6939 - val_accuracy: 0.5080\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6927 - accuracy: 0.5072 - val_loss: 0.6937 - val_accuracy: 0.5156\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6945 - accuracy: 0.4956 - val_loss: 0.6937 - val_accuracy: 0.5124\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5184 - val_loss: 0.6936 - val_accuracy: 0.5008\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6937 - val_accuracy: 0.4936\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6939 - val_accuracy: 0.4940\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6927 - accuracy: 0.5124 - val_loss: 0.6944 - val_accuracy: 0.4868\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6938 - val_accuracy: 0.4980\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6935 - val_accuracy: 0.5116\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6933 - accuracy: 0.5120 - val_loss: 0.6936 - val_accuracy: 0.5028\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.5072\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6933 - val_accuracy: 0.5136\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.5164\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6933 - accuracy: 0.5036 - val_loss: 0.6936 - val_accuracy: 0.5068\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6935 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.4924\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6930 - accuracy: 0.5008 - val_loss: 0.6939 - val_accuracy: 0.4920\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6927 - accuracy: 0.5236 - val_loss: 0.6944 - val_accuracy: 0.5076\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6934 - val_accuracy: 0.5096\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.5108\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6928 - accuracy: 0.5208 - val_loss: 0.6945 - val_accuracy: 0.4868\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5076 - val_loss: 0.6938 - val_accuracy: 0.4992\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6933 - accuracy: 0.5124 - val_loss: 0.6938 - val_accuracy: 0.5008\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6928 - accuracy: 0.5072 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.4940\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6945 - accuracy: 0.4940 - val_loss: 0.6934 - val_accuracy: 0.5112\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6928 - accuracy: 0.5108 - val_loss: 0.6935 - val_accuracy: 0.5136\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.4928\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6934 - val_accuracy: 0.5088\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6929 - accuracy: 0.5068 - val_loss: 0.6935 - val_accuracy: 0.5072\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6930 - accuracy: 0.5044 - val_loss: 0.6935 - val_accuracy: 0.5132\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6929 - accuracy: 0.5164 - val_loss: 0.6933 - val_accuracy: 0.5140\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.5080\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6928 - accuracy: 0.5076 - val_loss: 0.6941 - val_accuracy: 0.4920\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6929 - accuracy: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.4968\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5112 - val_loss: 0.6940 - val_accuracy: 0.4952\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6931 - accuracy: 0.5036 - val_loss: 0.6934 - val_accuracy: 0.5104\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6927 - accuracy: 0.5112 - val_loss: 0.6937 - val_accuracy: 0.5112\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6952 - val_accuracy: 0.4884\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6948 - val_accuracy: 0.4868\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6920 - accuracy: 0.5124 - val_loss: 0.6942 - val_accuracy: 0.5076\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6934 - val_accuracy: 0.5096\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5052\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6926 - accuracy: 0.5108 - val_loss: 0.6934 - val_accuracy: 0.5148\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6927 - accuracy: 0.5208 - val_loss: 0.6933 - val_accuracy: 0.5104\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5112 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6940 - accuracy: 0.4956 - val_loss: 0.6936 - val_accuracy: 0.4988\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5176\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6925 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5056\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6933 - val_accuracy: 0.5064\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6926 - accuracy: 0.5184 - val_loss: 0.6933 - val_accuracy: 0.5104\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6934 - val_accuracy: 0.5160\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5088 - val_loss: 0.6932 - val_accuracy: 0.5140\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6927 - accuracy: 0.5072 - val_loss: 0.6937 - val_accuracy: 0.5036\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6922 - accuracy: 0.5300 - val_loss: 0.6942 - val_accuracy: 0.4864\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6927 - accuracy: 0.5100 - val_loss: 0.6930 - val_accuracy: 0.5064\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5076 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6919 - accuracy: 0.5232 - val_loss: 0.6937 - val_accuracy: 0.4964\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6920 - accuracy: 0.5068 - val_loss: 0.6934 - val_accuracy: 0.5112\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6924 - accuracy: 0.5204 - val_loss: 0.6937 - val_accuracy: 0.5128\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5240 - val_loss: 0.6956 - val_accuracy: 0.4896\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6923 - accuracy: 0.5180 - val_loss: 0.6933 - val_accuracy: 0.5120\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6934 - val_accuracy: 0.5100\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6921 - accuracy: 0.5092 - val_loss: 0.6933 - val_accuracy: 0.5108\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5160\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6931 - val_accuracy: 0.5092\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6923 - accuracy: 0.5228 - val_loss: 0.6933 - val_accuracy: 0.5096\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6935 - val_accuracy: 0.5072\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6934 - val_accuracy: 0.5108\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6943 - val_accuracy: 0.4900\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6914 - accuracy: 0.5268 - val_loss: 0.6946 - val_accuracy: 0.4892\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6916 - accuracy: 0.5276 - val_loss: 0.6935 - val_accuracy: 0.5132\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5244\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6947 - val_accuracy: 0.4908\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6922 - accuracy: 0.5120 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6907 - accuracy: 0.5340 - val_loss: 0.6927 - val_accuracy: 0.5080\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6927 - val_accuracy: 0.5072\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6913 - accuracy: 0.5236 - val_loss: 0.6931 - val_accuracy: 0.5048\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6922 - accuracy: 0.5184 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6903 - accuracy: 0.5268 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6904 - accuracy: 0.5184 - val_loss: 0.6927 - val_accuracy: 0.5144\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6905 - accuracy: 0.5248 - val_loss: 0.6923 - val_accuracy: 0.5096\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6903 - accuracy: 0.5276 - val_loss: 0.6927 - val_accuracy: 0.5124\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6902 - accuracy: 0.5288 - val_loss: 0.6926 - val_accuracy: 0.5144\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6933 - val_accuracy: 0.5188\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6894 - accuracy: 0.5384 - val_loss: 0.6927 - val_accuracy: 0.5160\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6896 - accuracy: 0.5232 - val_loss: 0.6930 - val_accuracy: 0.5272\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6901 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5296\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6890 - accuracy: 0.5320 - val_loss: 0.6918 - val_accuracy: 0.5164\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6886 - accuracy: 0.5228 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6884 - accuracy: 0.5360 - val_loss: 0.6923 - val_accuracy: 0.5244\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6885 - accuracy: 0.5372 - val_loss: 0.6929 - val_accuracy: 0.5152\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6874 - accuracy: 0.5376 - val_loss: 0.6914 - val_accuracy: 0.5224\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6878 - accuracy: 0.5444 - val_loss: 0.6911 - val_accuracy: 0.5256\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6875 - accuracy: 0.5352 - val_loss: 0.6951 - val_accuracy: 0.5036\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6879 - accuracy: 0.5268 - val_loss: 0.6927 - val_accuracy: 0.5136\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6866 - accuracy: 0.5316 - val_loss: 0.6918 - val_accuracy: 0.5272\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6860 - accuracy: 0.5460 - val_loss: 0.6908 - val_accuracy: 0.5272\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6864 - accuracy: 0.5312 - val_loss: 0.6928 - val_accuracy: 0.5164\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6856 - accuracy: 0.5376 - val_loss: 0.6905 - val_accuracy: 0.5312\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6855 - accuracy: 0.5436 - val_loss: 0.6936 - val_accuracy: 0.5188\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6851 - accuracy: 0.5332 - val_loss: 0.6903 - val_accuracy: 0.5276\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6851 - accuracy: 0.5380 - val_loss: 0.6908 - val_accuracy: 0.5348\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6850 - accuracy: 0.5304 - val_loss: 0.6916 - val_accuracy: 0.5292\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6846 - accuracy: 0.5292 - val_loss: 0.6895 - val_accuracy: 0.5356\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6844 - accuracy: 0.5380 - val_loss: 0.6890 - val_accuracy: 0.5332\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6840 - accuracy: 0.5388 - val_loss: 0.6898 - val_accuracy: 0.5296\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6835 - accuracy: 0.5420 - val_loss: 0.6895 - val_accuracy: 0.5408\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6845 - accuracy: 0.5408 - val_loss: 0.6889 - val_accuracy: 0.5396\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6841 - accuracy: 0.5352 - val_loss: 0.6889 - val_accuracy: 0.5296\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6829 - accuracy: 0.5492 - val_loss: 0.6898 - val_accuracy: 0.5352\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6830 - accuracy: 0.5424 - val_loss: 0.6912 - val_accuracy: 0.5356\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6833 - accuracy: 0.5376 - val_loss: 0.6947 - val_accuracy: 0.5344\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6822 - accuracy: 0.5340 - val_loss: 0.6895 - val_accuracy: 0.5356\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6819 - accuracy: 0.5296 - val_loss: 0.6889 - val_accuracy: 0.5392\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6822 - accuracy: 0.5360 - val_loss: 0.6887 - val_accuracy: 0.5288\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6825 - accuracy: 0.5420 - val_loss: 0.6880 - val_accuracy: 0.5384\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6814 - accuracy: 0.5376 - val_loss: 0.6945 - val_accuracy: 0.5368\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6824 - accuracy: 0.5412 - val_loss: 0.6957 - val_accuracy: 0.5412\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6828 - accuracy: 0.5392 - val_loss: 0.6873 - val_accuracy: 0.5304\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6817 - accuracy: 0.5428 - val_loss: 0.6935 - val_accuracy: 0.5344\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6815 - accuracy: 0.5484 - val_loss: 0.6914 - val_accuracy: 0.5364\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6803 - accuracy: 0.5496 - val_loss: 0.6879 - val_accuracy: 0.5316\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6821 - accuracy: 0.5352 - val_loss: 0.6877 - val_accuracy: 0.5312\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6801 - accuracy: 0.5504 - val_loss: 0.6872 - val_accuracy: 0.5412\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6796 - accuracy: 0.5432 - val_loss: 0.6870 - val_accuracy: 0.5364\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6795 - accuracy: 0.5432 - val_loss: 0.6868 - val_accuracy: 0.5372\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6794 - accuracy: 0.5412 - val_loss: 0.6861 - val_accuracy: 0.5312\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6787 - accuracy: 0.5488 - val_loss: 0.7000 - val_accuracy: 0.5440\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6793 - accuracy: 0.5392 - val_loss: 0.6981 - val_accuracy: 0.5356\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6800 - accuracy: 0.5480 - val_loss: 0.6877 - val_accuracy: 0.5364\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6783 - accuracy: 0.5484 - val_loss: 0.6871 - val_accuracy: 0.5316\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6791 - accuracy: 0.5264 - val_loss: 0.6861 - val_accuracy: 0.5368\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6775 - accuracy: 0.5508 - val_loss: 0.6926 - val_accuracy: 0.5460\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6776 - accuracy: 0.5524 - val_loss: 0.6922 - val_accuracy: 0.5424\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6766 - accuracy: 0.5492 - val_loss: 0.6962 - val_accuracy: 0.5508\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6770 - accuracy: 0.5556 - val_loss: 0.6945 - val_accuracy: 0.5544\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6774 - accuracy: 0.5560 - val_loss: 0.7023 - val_accuracy: 0.5176\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6819 - accuracy: 0.5444 - val_loss: 0.6860 - val_accuracy: 0.5452\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6786 - accuracy: 0.5400 - val_loss: 0.6898 - val_accuracy: 0.5448\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6762 - accuracy: 0.5572 - val_loss: 0.6879 - val_accuracy: 0.5416\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6796 - accuracy: 0.5496 - val_loss: 0.6922 - val_accuracy: 0.5320\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6766 - accuracy: 0.5528 - val_loss: 0.6846 - val_accuracy: 0.5488\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6762 - accuracy: 0.5552 - val_loss: 0.6857 - val_accuracy: 0.5480\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6757 - accuracy: 0.5488 - val_loss: 0.6849 - val_accuracy: 0.5376\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6751 - accuracy: 0.5504 - val_loss: 0.6868 - val_accuracy: 0.5504\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6754 - accuracy: 0.5548 - val_loss: 0.6851 - val_accuracy: 0.5484\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6756 - accuracy: 0.5484 - val_loss: 0.6852 - val_accuracy: 0.5532\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6746 - accuracy: 0.5528 - val_loss: 0.6892 - val_accuracy: 0.5512\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6741 - accuracy: 0.5576 - val_loss: 0.6975 - val_accuracy: 0.5496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5576</td></tr><tr><td>loss</td><td>0.67409</td></tr><tr><td>val_accuracy</td><td>0.5496</td></tr><tr><td>val_loss</td><td>0.69747</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">classic-sweep-4</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/qtsryu0s\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/qtsryu0s</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_221033-qtsryu0s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r68627i9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_221211-r68627i9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/r68627i9\" target=\"_blank\">radiant-sweep-5</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 0s 181us/sample - loss: 1.5693 - accuracy: 0.5016 - val_loss: 0.9606 - val_accuracy: 0.5088\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.8773 - accuracy: 0.5012 - val_loss: 0.7942 - val_accuracy: 0.5108\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.7468 - accuracy: 0.5052 - val_loss: 0.7136 - val_accuracy: 0.5032\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.7092 - accuracy: 0.5044 - val_loss: 0.7075 - val_accuracy: 0.5036\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.7057 - accuracy: 0.5068 - val_loss: 0.7051 - val_accuracy: 0.5036\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.7038 - accuracy: 0.5032 - val_loss: 0.7028 - val_accuracy: 0.5036\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.7021 - accuracy: 0.5036 - val_loss: 0.7009 - val_accuracy: 0.5028\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.7007 - accuracy: 0.5036 - val_loss: 0.6999 - val_accuracy: 0.5068\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6996 - accuracy: 0.5096 - val_loss: 0.6982 - val_accuracy: 0.5000\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6985 - accuracy: 0.5004 - val_loss: 0.6972 - val_accuracy: 0.5028\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6972 - accuracy: 0.5060 - val_loss: 0.6978 - val_accuracy: 0.5052\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6980 - accuracy: 0.4948 - val_loss: 0.6957 - val_accuracy: 0.5024\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6966 - accuracy: 0.5044 - val_loss: 0.6959 - val_accuracy: 0.5116\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6963 - accuracy: 0.4968 - val_loss: 0.6948 - val_accuracy: 0.5024\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6960 - accuracy: 0.4872 - val_loss: 0.6945 - val_accuracy: 0.5004\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6958 - accuracy: 0.4976 - val_loss: 0.6944 - val_accuracy: 0.5044\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6954 - accuracy: 0.5012 - val_loss: 0.6948 - val_accuracy: 0.5100\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6952 - accuracy: 0.4984 - val_loss: 0.6942 - val_accuracy: 0.5024\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6950 - accuracy: 0.4988 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6945 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.5056\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6946 - accuracy: 0.4992 - val_loss: 0.6941 - val_accuracy: 0.5032\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6949 - accuracy: 0.4956 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6949 - accuracy: 0.4944 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6946 - accuracy: 0.5072 - val_loss: 0.6954 - val_accuracy: 0.4952\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6946 - accuracy: 0.4952 - val_loss: 0.6951 - val_accuracy: 0.4936\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6944 - accuracy: 0.5064 - val_loss: 0.6938 - val_accuracy: 0.5060\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6942 - accuracy: 0.5056 - val_loss: 0.6938 - val_accuracy: 0.5044\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6946 - accuracy: 0.4928 - val_loss: 0.6944 - val_accuracy: 0.4900\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6945 - accuracy: 0.4908 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6941 - accuracy: 0.4972 - val_loss: 0.6939 - val_accuracy: 0.4936\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6942 - accuracy: 0.5024 - val_loss: 0.6943 - val_accuracy: 0.4832\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6943 - accuracy: 0.4976 - val_loss: 0.6942 - val_accuracy: 0.4892\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6940 - val_accuracy: 0.5076\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6944 - accuracy: 0.4992 - val_loss: 0.6944 - val_accuracy: 0.4832\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.5096 - val_loss: 0.6942 - val_accuracy: 0.5056\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6944 - accuracy: 0.5024 - val_loss: 0.6939 - val_accuracy: 0.5096\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6941 - accuracy: 0.5080 - val_loss: 0.6939 - val_accuracy: 0.4928\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6940 - accuracy: 0.5004 - val_loss: 0.6938 - val_accuracy: 0.4928\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6939 - val_accuracy: 0.5136\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6939 - accuracy: 0.4996 - val_loss: 0.6941 - val_accuracy: 0.5072\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6941 - accuracy: 0.5024 - val_loss: 0.6938 - val_accuracy: 0.4852\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6942 - val_accuracy: 0.4836\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6940 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6939 - accuracy: 0.4944 - val_loss: 0.6939 - val_accuracy: 0.4948\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.5008 - val_loss: 0.6945 - val_accuracy: 0.5072\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6943 - accuracy: 0.4976 - val_loss: 0.6941 - val_accuracy: 0.4872\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6939 - accuracy: 0.4980 - val_loss: 0.6939 - val_accuracy: 0.4832\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6939 - accuracy: 0.4868 - val_loss: 0.6940 - val_accuracy: 0.4824\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6939 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.4732\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6941 - accuracy: 0.4972 - val_loss: 0.6941 - val_accuracy: 0.4848\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6945 - val_accuracy: 0.4828\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.4956\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6938 - accuracy: 0.4928 - val_loss: 0.6939 - val_accuracy: 0.5164\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6940 - accuracy: 0.4960 - val_loss: 0.6949 - val_accuracy: 0.4812\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5016 - val_loss: 0.6940 - val_accuracy: 0.5140\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.4872\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.5092 - val_loss: 0.6940 - val_accuracy: 0.5204\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6938 - accuracy: 0.5008 - val_loss: 0.6947 - val_accuracy: 0.4808\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6939 - val_accuracy: 0.5084\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.4928 - val_loss: 0.6943 - val_accuracy: 0.5056\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6937 - accuracy: 0.5124 - val_loss: 0.6946 - val_accuracy: 0.4788\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6943 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5192\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6936 - accuracy: 0.4952 - val_loss: 0.6940 - val_accuracy: 0.5172\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6941 - accuracy: 0.5008 - val_loss: 0.6942 - val_accuracy: 0.5148\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6946 - val_accuracy: 0.4788\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6934 - accuracy: 0.5116 - val_loss: 0.6943 - val_accuracy: 0.4788\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6938 - accuracy: 0.5120 - val_loss: 0.6956 - val_accuracy: 0.4880\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.5064 - val_loss: 0.6942 - val_accuracy: 0.4848\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6937 - accuracy: 0.4980 - val_loss: 0.6951 - val_accuracy: 0.4864\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6947 - val_accuracy: 0.4828\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6935 - accuracy: 0.5020 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6936 - accuracy: 0.5032 - val_loss: 0.6940 - val_accuracy: 0.5104\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6936 - accuracy: 0.5012 - val_loss: 0.6955 - val_accuracy: 0.4940\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6941 - accuracy: 0.4968 - val_loss: 0.6951 - val_accuracy: 0.4776\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6942 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.5156\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6936 - accuracy: 0.5068 - val_loss: 0.6944 - val_accuracy: 0.5124\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6943 - val_accuracy: 0.5156\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6939 - accuracy: 0.4952 - val_loss: 0.6938 - val_accuracy: 0.5116\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6955 - val_accuracy: 0.4912\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6936 - accuracy: 0.5032 - val_loss: 0.6942 - val_accuracy: 0.4832\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5144 - val_loss: 0.6965 - val_accuracy: 0.4924\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.5116 - val_loss: 0.6945 - val_accuracy: 0.5084\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.6944 - val_accuracy: 0.5120\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5084 - val_loss: 0.6946 - val_accuracy: 0.4804\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5128 - val_loss: 0.6944 - val_accuracy: 0.4780\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6966 - val_accuracy: 0.4912\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6942 - accuracy: 0.5016 - val_loss: 0.6944 - val_accuracy: 0.4796\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6937 - accuracy: 0.4992 - val_loss: 0.6940 - val_accuracy: 0.5076\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6936 - accuracy: 0.5128 - val_loss: 0.6946 - val_accuracy: 0.4724\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5248 - val_loss: 0.6945 - val_accuracy: 0.5148\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5224 - val_loss: 0.6943 - val_accuracy: 0.4824\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.5020 - val_loss: 0.6944 - val_accuracy: 0.5088\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6935 - accuracy: 0.5100 - val_loss: 0.6947 - val_accuracy: 0.4808\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6940 - val_accuracy: 0.4900\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5180 - val_loss: 0.6978 - val_accuracy: 0.4932\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6941 - accuracy: 0.5072 - val_loss: 0.6948 - val_accuracy: 0.4772\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6926 - accuracy: 0.5200 - val_loss: 0.7009 - val_accuracy: 0.4912\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6942 - accuracy: 0.5052 - val_loss: 0.6941 - val_accuracy: 0.5048\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6942 - val_accuracy: 0.5080\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6944 - val_accuracy: 0.4808\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6941 - val_accuracy: 0.5104\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5064 - val_loss: 0.6950 - val_accuracy: 0.4824\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6944 - val_accuracy: 0.4800\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6954 - val_accuracy: 0.5096\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5084 - val_loss: 0.6947 - val_accuracy: 0.5048\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6940 - accuracy: 0.4960 - val_loss: 0.6947 - val_accuracy: 0.5076\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6932 - accuracy: 0.5116 - val_loss: 0.6944 - val_accuracy: 0.4796\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6937 - accuracy: 0.5156 - val_loss: 0.6944 - val_accuracy: 0.4916\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6946 - val_accuracy: 0.4808\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6947 - val_accuracy: 0.4832\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5172 - val_loss: 0.6947 - val_accuracy: 0.4844\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6954 - val_accuracy: 0.4792\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6930 - accuracy: 0.5140 - val_loss: 0.6944 - val_accuracy: 0.5072\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6935 - accuracy: 0.5096 - val_loss: 0.6944 - val_accuracy: 0.4896\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6929 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.4964\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6930 - accuracy: 0.5172 - val_loss: 0.6943 - val_accuracy: 0.5028\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6949 - val_accuracy: 0.5072\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.5064 - val_loss: 0.6945 - val_accuracy: 0.5008\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5164 - val_loss: 0.6945 - val_accuracy: 0.4916\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5104 - val_loss: 0.6949 - val_accuracy: 0.4804\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5216 - val_loss: 0.6947 - val_accuracy: 0.4868\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6950 - val_accuracy: 0.4756\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5192 - val_loss: 0.6948 - val_accuracy: 0.5028\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6937 - accuracy: 0.5076 - val_loss: 0.6956 - val_accuracy: 0.4816\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6937 - accuracy: 0.4972 - val_loss: 0.6945 - val_accuracy: 0.4884\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5160 - val_loss: 0.6950 - val_accuracy: 0.4844\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6929 - accuracy: 0.5180 - val_loss: 0.6945 - val_accuracy: 0.5024\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6933 - accuracy: 0.5136 - val_loss: 0.6944 - val_accuracy: 0.4940\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.6944 - val_accuracy: 0.4872\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5072 - val_loss: 0.6950 - val_accuracy: 0.4720\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6954 - val_accuracy: 0.4828\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6934 - accuracy: 0.5076 - val_loss: 0.6946 - val_accuracy: 0.4820\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6924 - accuracy: 0.5092 - val_loss: 0.6951 - val_accuracy: 0.5036\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6954 - val_accuracy: 0.5084\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5188 - val_loss: 0.6955 - val_accuracy: 0.4752\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6927 - accuracy: 0.5204 - val_loss: 0.6960 - val_accuracy: 0.4928\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6947 - val_accuracy: 0.5056\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6946 - val_accuracy: 0.4800\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5116 - val_loss: 0.6944 - val_accuracy: 0.5016\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5120 - val_loss: 0.6946 - val_accuracy: 0.5064\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.6948 - val_accuracy: 0.5048\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6935 - accuracy: 0.5104 - val_loss: 0.6946 - val_accuracy: 0.4820\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6948 - val_accuracy: 0.4868\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6933 - accuracy: 0.5156 - val_loss: 0.6949 - val_accuracy: 0.4836\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6932 - accuracy: 0.5188 - val_loss: 0.6945 - val_accuracy: 0.4912\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5016 - val_loss: 0.6947 - val_accuracy: 0.4996\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5160 - val_loss: 0.6954 - val_accuracy: 0.4784\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6932 - accuracy: 0.5128 - val_loss: 0.6948 - val_accuracy: 0.4776\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6949 - val_accuracy: 0.4848\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6929 - accuracy: 0.5156 - val_loss: 0.6960 - val_accuracy: 0.4896\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6929 - accuracy: 0.5140 - val_loss: 0.6947 - val_accuracy: 0.4908\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6930 - accuracy: 0.5020 - val_loss: 0.6947 - val_accuracy: 0.4940\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6925 - accuracy: 0.5084 - val_loss: 0.6971 - val_accuracy: 0.4940\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6930 - accuracy: 0.5088 - val_loss: 0.6953 - val_accuracy: 0.5068\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6926 - accuracy: 0.5080 - val_loss: 0.6964 - val_accuracy: 0.4936\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6959 - val_accuracy: 0.4936\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6945 - val_accuracy: 0.4904\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6928 - accuracy: 0.5212 - val_loss: 0.6951 - val_accuracy: 0.4764\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6927 - accuracy: 0.5160 - val_loss: 0.6949 - val_accuracy: 0.4876\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6931 - accuracy: 0.5156 - val_loss: 0.6948 - val_accuracy: 0.4984\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6933 - accuracy: 0.5036 - val_loss: 0.6955 - val_accuracy: 0.4788\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6950 - val_accuracy: 0.4980\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6926 - accuracy: 0.5164 - val_loss: 0.6952 - val_accuracy: 0.5036\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6934 - accuracy: 0.5128 - val_loss: 0.6966 - val_accuracy: 0.5124\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.5060 - val_loss: 0.6946 - val_accuracy: 0.4900\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6930 - accuracy: 0.5112 - val_loss: 0.6955 - val_accuracy: 0.4792\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6967 - val_accuracy: 0.5100\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6938 - accuracy: 0.5072 - val_loss: 0.6953 - val_accuracy: 0.5072\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6952 - val_accuracy: 0.5080\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5180 - val_loss: 0.6979 - val_accuracy: 0.4864\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6928 - accuracy: 0.5036 - val_loss: 0.6945 - val_accuracy: 0.4952\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5064 - val_loss: 0.6947 - val_accuracy: 0.4844\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5124 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6949 - val_accuracy: 0.5012\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5112 - val_loss: 0.6953 - val_accuracy: 0.5088\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6949 - val_accuracy: 0.4816\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6928 - accuracy: 0.5088 - val_loss: 0.6951 - val_accuracy: 0.4908\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6927 - accuracy: 0.5216 - val_loss: 0.6951 - val_accuracy: 0.4884\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6928 - accuracy: 0.5232 - val_loss: 0.6953 - val_accuracy: 0.4792\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5116 - val_loss: 0.6948 - val_accuracy: 0.4808\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6926 - accuracy: 0.5160 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6950 - val_accuracy: 0.4952\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6925 - accuracy: 0.5172 - val_loss: 0.6947 - val_accuracy: 0.4928\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5088 - val_loss: 0.6949 - val_accuracy: 0.4836\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.5052 - val_loss: 0.6955 - val_accuracy: 0.4740\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6926 - accuracy: 0.5184 - val_loss: 0.6950 - val_accuracy: 0.4860\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6925 - accuracy: 0.5164 - val_loss: 0.6949 - val_accuracy: 0.5044\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6925 - accuracy: 0.5164 - val_loss: 0.6951 - val_accuracy: 0.4864\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6951 - val_accuracy: 0.4932\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5184 - val_loss: 0.6953 - val_accuracy: 0.5080\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5192 - val_loss: 0.6953 - val_accuracy: 0.4784\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6921 - accuracy: 0.5308 - val_loss: 0.6972 - val_accuracy: 0.4876\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6931 - accuracy: 0.5204 - val_loss: 0.6965 - val_accuracy: 0.4892\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6933 - accuracy: 0.5064 - val_loss: 0.6963 - val_accuracy: 0.4816\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5276 - val_loss: 0.6951 - val_accuracy: 0.4784\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5092 - val_loss: 0.6951 - val_accuracy: 0.4868\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6931 - accuracy: 0.5012 - val_loss: 0.6950 - val_accuracy: 0.4812\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6949 - val_accuracy: 0.4868\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6926 - accuracy: 0.5152 - val_loss: 0.6951 - val_accuracy: 0.4916\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6951 - val_accuracy: 0.5028\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6949 - val_accuracy: 0.4860\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6926 - accuracy: 0.5204 - val_loss: 0.6948 - val_accuracy: 0.4916\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6959 - val_accuracy: 0.4852\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6929 - accuracy: 0.5052 - val_loss: 0.6960 - val_accuracy: 0.4852\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6927 - accuracy: 0.5104 - val_loss: 0.6952 - val_accuracy: 0.4896\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6949 - val_accuracy: 0.4864\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6927 - accuracy: 0.5128 - val_loss: 0.6967 - val_accuracy: 0.4876\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6930 - accuracy: 0.5132 - val_loss: 0.6954 - val_accuracy: 0.4816\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6972 - val_accuracy: 0.4892\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6955 - val_accuracy: 0.4884\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5172 - val_loss: 0.6953 - val_accuracy: 0.4884\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6924 - accuracy: 0.5116 - val_loss: 0.6979 - val_accuracy: 0.4904\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6927 - accuracy: 0.5224 - val_loss: 0.6950 - val_accuracy: 0.5020\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5260 - val_loss: 0.6952 - val_accuracy: 0.5052\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6923 - accuracy: 0.5056 - val_loss: 0.6953 - val_accuracy: 0.5040\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6925 - accuracy: 0.5160 - val_loss: 0.6952 - val_accuracy: 0.4884\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6925 - accuracy: 0.5168 - val_loss: 0.6963 - val_accuracy: 0.4728\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6926 - accuracy: 0.5156 - val_loss: 0.6953 - val_accuracy: 0.4848\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5272 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6925 - accuracy: 0.5084 - val_loss: 0.6957 - val_accuracy: 0.4808\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5068 - val_loss: 0.6955 - val_accuracy: 0.4784\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6929 - accuracy: 0.5148 - val_loss: 0.6954 - val_accuracy: 0.4804\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6950 - val_accuracy: 0.4960\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6930 - accuracy: 0.5164 - val_loss: 0.6953 - val_accuracy: 0.4952\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6924 - accuracy: 0.5228 - val_loss: 0.6949 - val_accuracy: 0.5044\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6921 - accuracy: 0.5104 - val_loss: 0.6959 - val_accuracy: 0.4812\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6927 - accuracy: 0.5096 - val_loss: 0.6952 - val_accuracy: 0.4884\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6926 - accuracy: 0.5176 - val_loss: 0.6952 - val_accuracy: 0.5032\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6932 - accuracy: 0.5188 - val_loss: 0.6952 - val_accuracy: 0.5020\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6923 - accuracy: 0.5100 - val_loss: 0.6951 - val_accuracy: 0.4876\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6924 - accuracy: 0.5256 - val_loss: 0.6954 - val_accuracy: 0.5036\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5128 - val_loss: 0.6953 - val_accuracy: 0.4752\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6928 - accuracy: 0.5016 - val_loss: 0.6949 - val_accuracy: 0.5012\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6925 - accuracy: 0.5124 - val_loss: 0.6951 - val_accuracy: 0.4764\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6924 - accuracy: 0.5200 - val_loss: 0.6963 - val_accuracy: 0.4848\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6920 - accuracy: 0.5252 - val_loss: 0.6951 - val_accuracy: 0.4972\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5096 - val_loss: 0.6958 - val_accuracy: 0.4772\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6937 - accuracy: 0.5068 - val_loss: 0.6948 - val_accuracy: 0.5036\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6925 - accuracy: 0.5192 - val_loss: 0.6948 - val_accuracy: 0.4996\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5124 - val_loss: 0.6951 - val_accuracy: 0.4796\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6924 - accuracy: 0.5108 - val_loss: 0.6948 - val_accuracy: 0.5060\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6920 - accuracy: 0.5124 - val_loss: 0.6954 - val_accuracy: 0.4756\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6948 - val_accuracy: 0.5064\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6952 - val_accuracy: 0.4896\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6950 - val_accuracy: 0.5020\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6924 - accuracy: 0.5164 - val_loss: 0.6953 - val_accuracy: 0.4756\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6953 - val_accuracy: 0.4824\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5188 - val_loss: 0.6951 - val_accuracy: 0.4828\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5156 - val_loss: 0.6951 - val_accuracy: 0.4832\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6944 - accuracy: 0.4892 - val_loss: 0.6952 - val_accuracy: 0.4912\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6924 - accuracy: 0.5108 - val_loss: 0.6950 - val_accuracy: 0.4964\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5084 - val_loss: 0.6952 - val_accuracy: 0.5072\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6921 - accuracy: 0.5100 - val_loss: 0.6954 - val_accuracy: 0.4888\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6920 - accuracy: 0.5244 - val_loss: 0.6951 - val_accuracy: 0.4880\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6921 - accuracy: 0.5200 - val_loss: 0.6950 - val_accuracy: 0.5048\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6925 - accuracy: 0.5200 - val_loss: 0.6951 - val_accuracy: 0.5056\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6965 - val_accuracy: 0.4824\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6933 - accuracy: 0.5112 - val_loss: 0.6951 - val_accuracy: 0.4924\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6923 - accuracy: 0.5192 - val_loss: 0.6951 - val_accuracy: 0.4880\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6920 - accuracy: 0.5260 - val_loss: 0.6964 - val_accuracy: 0.4840\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5212 - val_loss: 0.6971 - val_accuracy: 0.4904\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6926 - accuracy: 0.5224 - val_loss: 0.6952 - val_accuracy: 0.4900\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6923 - accuracy: 0.5120 - val_loss: 0.6948 - val_accuracy: 0.5048\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6955 - val_accuracy: 0.5080\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6949 - val_accuracy: 0.5040\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6920 - accuracy: 0.5228 - val_loss: 0.6951 - val_accuracy: 0.5040\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6918 - accuracy: 0.5360 - val_loss: 0.6957 - val_accuracy: 0.4804\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6922 - accuracy: 0.5240 - val_loss: 0.6962 - val_accuracy: 0.4780\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6960 - val_accuracy: 0.4780\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6924 - accuracy: 0.5200 - val_loss: 0.6950 - val_accuracy: 0.5004\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6917 - accuracy: 0.5232 - val_loss: 0.6964 - val_accuracy: 0.4764\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6923 - accuracy: 0.5220 - val_loss: 0.6958 - val_accuracy: 0.4776\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6912 - accuracy: 0.5364 - val_loss: 0.6956 - val_accuracy: 0.5056\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6953 - val_accuracy: 0.4880\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6952 - val_accuracy: 0.5016\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6958 - val_accuracy: 0.4792\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6916 - accuracy: 0.5248 - val_loss: 0.6952 - val_accuracy: 0.4880\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6919 - accuracy: 0.5232 - val_loss: 0.6953 - val_accuracy: 0.4912\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6923 - accuracy: 0.5112 - val_loss: 0.6959 - val_accuracy: 0.4928\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5176 - val_loss: 0.6958 - val_accuracy: 0.4976\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6913 - accuracy: 0.5144 - val_loss: 0.6967 - val_accuracy: 0.4792\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6917 - accuracy: 0.5128 - val_loss: 0.6957 - val_accuracy: 0.5036\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6921 - accuracy: 0.5200 - val_loss: 0.6956 - val_accuracy: 0.4924\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6916 - accuracy: 0.5244 - val_loss: 0.6958 - val_accuracy: 0.4980\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6918 - accuracy: 0.5260 - val_loss: 0.6965 - val_accuracy: 0.4816\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6920 - accuracy: 0.5128 - val_loss: 0.6954 - val_accuracy: 0.4900\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6957 - val_accuracy: 0.4848\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5096 - val_loss: 0.6969 - val_accuracy: 0.4788\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6917 - accuracy: 0.5216 - val_loss: 0.6956 - val_accuracy: 0.4964\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6918 - accuracy: 0.5084 - val_loss: 0.6957 - val_accuracy: 0.4972\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6961 - val_accuracy: 0.4976\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6913 - accuracy: 0.5224 - val_loss: 0.6964 - val_accuracy: 0.4812\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6911 - accuracy: 0.5312 - val_loss: 0.6957 - val_accuracy: 0.4924\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6965 - val_accuracy: 0.4892\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6957 - val_accuracy: 0.4956\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6912 - accuracy: 0.5260 - val_loss: 0.6968 - val_accuracy: 0.4788\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6915 - accuracy: 0.5220 - val_loss: 0.6965 - val_accuracy: 0.4864\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6914 - accuracy: 0.5268 - val_loss: 0.6955 - val_accuracy: 0.4984\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6911 - accuracy: 0.5268 - val_loss: 0.6962 - val_accuracy: 0.4928\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6908 - accuracy: 0.5280 - val_loss: 0.6961 - val_accuracy: 0.4920\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6914 - accuracy: 0.5396 - val_loss: 0.6959 - val_accuracy: 0.4912\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6923 - accuracy: 0.5176 - val_loss: 0.6957 - val_accuracy: 0.4980\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6907 - accuracy: 0.5256 - val_loss: 0.6954 - val_accuracy: 0.5032\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6905 - accuracy: 0.5272 - val_loss: 0.6957 - val_accuracy: 0.4920\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6958 - val_accuracy: 0.4916\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6957 - val_accuracy: 0.4968\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6917 - accuracy: 0.5112 - val_loss: 0.6966 - val_accuracy: 0.4940\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6905 - accuracy: 0.5272 - val_loss: 0.6960 - val_accuracy: 0.4956\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6904 - accuracy: 0.5216 - val_loss: 0.6965 - val_accuracy: 0.5048\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6976 - val_accuracy: 0.4944\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6900 - accuracy: 0.5324 - val_loss: 0.6963 - val_accuracy: 0.4948\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6895 - accuracy: 0.5336 - val_loss: 0.6957 - val_accuracy: 0.4956\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6899 - accuracy: 0.5200 - val_loss: 0.6950 - val_accuracy: 0.5116\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6894 - accuracy: 0.5304 - val_loss: 0.6968 - val_accuracy: 0.5056\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6888 - accuracy: 0.5396 - val_loss: 0.6956 - val_accuracy: 0.5072\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6884 - accuracy: 0.5328 - val_loss: 0.6949 - val_accuracy: 0.5056\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6884 - accuracy: 0.5348 - val_loss: 0.6948 - val_accuracy: 0.5164\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6877 - accuracy: 0.5424 - val_loss: 0.6948 - val_accuracy: 0.5240\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6871 - accuracy: 0.5368 - val_loss: 0.6945 - val_accuracy: 0.5120\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6869 - accuracy: 0.5476 - val_loss: 0.6946 - val_accuracy: 0.5136\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6861 - accuracy: 0.5384 - val_loss: 0.6989 - val_accuracy: 0.5256\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6862 - accuracy: 0.5412 - val_loss: 0.6937 - val_accuracy: 0.5176\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6856 - accuracy: 0.5320 - val_loss: 0.6946 - val_accuracy: 0.5260\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6846 - accuracy: 0.5520 - val_loss: 0.6948 - val_accuracy: 0.5192\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6838 - accuracy: 0.5300 - val_loss: 0.6930 - val_accuracy: 0.5344\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6846 - accuracy: 0.5604 - val_loss: 0.6936 - val_accuracy: 0.5320\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6824 - accuracy: 0.5552 - val_loss: 0.6942 - val_accuracy: 0.5408\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6842 - accuracy: 0.5420 - val_loss: 0.6915 - val_accuracy: 0.5252\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6817 - accuracy: 0.5528 - val_loss: 0.7664 - val_accuracy: 0.5316\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6937 - accuracy: 0.5180 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6957 - val_accuracy: 0.4884\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6907 - accuracy: 0.5328 - val_loss: 0.6958 - val_accuracy: 0.4864\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6893 - accuracy: 0.5300 - val_loss: 0.6965 - val_accuracy: 0.4872\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6881 - accuracy: 0.5372 - val_loss: 0.6959 - val_accuracy: 0.4980\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6880 - accuracy: 0.5396 - val_loss: 0.6957 - val_accuracy: 0.4924\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6872 - accuracy: 0.5436 - val_loss: 0.6958 - val_accuracy: 0.4940\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6866 - accuracy: 0.5444 - val_loss: 0.6947 - val_accuracy: 0.4972\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6854 - accuracy: 0.5468 - val_loss: 0.6946 - val_accuracy: 0.5028\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6848 - accuracy: 0.5524 - val_loss: 0.6936 - val_accuracy: 0.5124\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6845 - accuracy: 0.5528 - val_loss: 0.6926 - val_accuracy: 0.5240\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6837 - accuracy: 0.5508 - val_loss: 0.6921 - val_accuracy: 0.5308\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6825 - accuracy: 0.5528 - val_loss: 0.6917 - val_accuracy: 0.5344\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6822 - accuracy: 0.5532 - val_loss: 0.6921 - val_accuracy: 0.5388\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6816 - accuracy: 0.5568 - val_loss: 0.6914 - val_accuracy: 0.5424\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6809 - accuracy: 0.5564 - val_loss: 0.6911 - val_accuracy: 0.5400\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6813 - accuracy: 0.5616 - val_loss: 0.6913 - val_accuracy: 0.5452\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6805 - accuracy: 0.5600 - val_loss: 0.6919 - val_accuracy: 0.5364\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6807 - accuracy: 0.5536 - val_loss: 0.6932 - val_accuracy: 0.5260\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6811 - accuracy: 0.5608 - val_loss: 0.6908 - val_accuracy: 0.5440\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6800 - accuracy: 0.5624 - val_loss: 0.6917 - val_accuracy: 0.5444\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6803 - accuracy: 0.5664 - val_loss: 0.6902 - val_accuracy: 0.5504\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6790 - accuracy: 0.5652 - val_loss: 0.6900 - val_accuracy: 0.5388\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6793 - accuracy: 0.5604 - val_loss: 0.6901 - val_accuracy: 0.5472\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6787 - accuracy: 0.5696 - val_loss: 0.6916 - val_accuracy: 0.5460\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6787 - accuracy: 0.5620 - val_loss: 0.6896 - val_accuracy: 0.5464\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6777 - accuracy: 0.5696 - val_loss: 0.6992 - val_accuracy: 0.5452\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6786 - accuracy: 0.5660 - val_loss: 0.6893 - val_accuracy: 0.5468\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6773 - accuracy: 0.5764 - val_loss: 0.6971 - val_accuracy: 0.5560\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6828 - accuracy: 0.5696 - val_loss: 0.6896 - val_accuracy: 0.5536\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6776 - accuracy: 0.5724 - val_loss: 0.6895 - val_accuracy: 0.5524\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6770 - accuracy: 0.5768 - val_loss: 0.6888 - val_accuracy: 0.5464\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6752 - accuracy: 0.5752 - val_loss: 0.6926 - val_accuracy: 0.5280\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6849 - accuracy: 0.5404 - val_loss: 0.6947 - val_accuracy: 0.4980\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6910 - accuracy: 0.5260 - val_loss: 0.6949 - val_accuracy: 0.4968\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6891 - accuracy: 0.5332 - val_loss: 0.6948 - val_accuracy: 0.4996\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6872 - accuracy: 0.5524 - val_loss: 0.6939 - val_accuracy: 0.4996\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6829 - accuracy: 0.5488 - val_loss: 0.6927 - val_accuracy: 0.5192\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6791 - accuracy: 0.5628 - val_loss: 0.6914 - val_accuracy: 0.5332\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6773 - accuracy: 0.5660 - val_loss: 0.6886 - val_accuracy: 0.5508\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6764 - accuracy: 0.5716 - val_loss: 0.6879 - val_accuracy: 0.5500\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6759 - accuracy: 0.5704 - val_loss: 0.6885 - val_accuracy: 0.5424\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6754 - accuracy: 0.5768 - val_loss: 0.6884 - val_accuracy: 0.5528\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6743 - accuracy: 0.5724 - val_loss: 0.6879 - val_accuracy: 0.5472\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6752 - accuracy: 0.5704 - val_loss: 0.6898 - val_accuracy: 0.5588\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6743 - accuracy: 0.5776 - val_loss: 0.6887 - val_accuracy: 0.5512\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6743 - accuracy: 0.5780 - val_loss: 0.6896 - val_accuracy: 0.5528\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6741 - accuracy: 0.5776 - val_loss: 0.6892 - val_accuracy: 0.5564\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6741 - accuracy: 0.5768 - val_loss: 0.6879 - val_accuracy: 0.5520\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6733 - accuracy: 0.5832 - val_loss: 0.6880 - val_accuracy: 0.5560\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6728 - accuracy: 0.5832 - val_loss: 0.6875 - val_accuracy: 0.5488\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6731 - accuracy: 0.5804 - val_loss: 0.6903 - val_accuracy: 0.5556\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6732 - accuracy: 0.5832 - val_loss: 0.6886 - val_accuracy: 0.5508\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6713 - accuracy: 0.5812 - val_loss: 0.6881 - val_accuracy: 0.5540\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6717 - accuracy: 0.5808 - val_loss: 0.6877 - val_accuracy: 0.5580\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6717 - accuracy: 0.5824 - val_loss: 0.6867 - val_accuracy: 0.5564\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6695 - accuracy: 0.5840 - val_loss: 0.6935 - val_accuracy: 0.5596\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6698 - accuracy: 0.5892 - val_loss: 0.6877 - val_accuracy: 0.5464\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6690 - accuracy: 0.5876 - val_loss: 0.6874 - val_accuracy: 0.5588\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6698 - accuracy: 0.5884 - val_loss: 0.6862 - val_accuracy: 0.5628\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6686 - accuracy: 0.5948 - val_loss: 0.6865 - val_accuracy: 0.5596\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6682 - accuracy: 0.5956 - val_loss: 0.6881 - val_accuracy: 0.5592\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6681 - accuracy: 0.5892 - val_loss: 0.6869 - val_accuracy: 0.5552\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6679 - accuracy: 0.5868 - val_loss: 0.6853 - val_accuracy: 0.5596\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6652 - accuracy: 0.5956 - val_loss: 0.6869 - val_accuracy: 0.5604\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6660 - accuracy: 0.5924 - val_loss: 0.6849 - val_accuracy: 0.5572\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6642 - accuracy: 0.5976 - val_loss: 0.6898 - val_accuracy: 0.5672\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6649 - accuracy: 0.5972 - val_loss: 0.6846 - val_accuracy: 0.5600\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6639 - accuracy: 0.5948 - val_loss: 0.6879 - val_accuracy: 0.5464\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6656 - accuracy: 0.5976 - val_loss: 0.6845 - val_accuracy: 0.5592\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6637 - accuracy: 0.5984 - val_loss: 0.6880 - val_accuracy: 0.5684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5984</td></tr><tr><td>loss</td><td>0.66369</td></tr><tr><td>val_accuracy</td><td>0.5684</td></tr><tr><td>val_loss</td><td>0.68799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">radiant-sweep-5</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/r68627i9\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/r68627i9</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_221211-r68627i9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ugpb2nc7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_221420-ugpb2nc7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/ugpb2nc7\" target=\"_blank\">vocal-sweep-6</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.7980 - accuracy: 0.4876 - val_loss: 0.7083 - val_accuracy: 0.5028\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.7042 - accuracy: 0.4916 - val_loss: 0.6971 - val_accuracy: 0.5144\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6981 - accuracy: 0.4972 - val_loss: 0.6963 - val_accuracy: 0.5052\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6973 - accuracy: 0.5004 - val_loss: 0.6951 - val_accuracy: 0.5056\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6965 - accuracy: 0.5068 - val_loss: 0.6952 - val_accuracy: 0.5040\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6958 - accuracy: 0.5104 - val_loss: 0.6949 - val_accuracy: 0.5020\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6953 - accuracy: 0.5048 - val_loss: 0.6946 - val_accuracy: 0.5036\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6952 - accuracy: 0.5064 - val_loss: 0.6945 - val_accuracy: 0.5004\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6952 - accuracy: 0.5024 - val_loss: 0.6960 - val_accuracy: 0.4892\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6951 - accuracy: 0.5152 - val_loss: 0.6944 - val_accuracy: 0.5088\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6948 - accuracy: 0.5140 - val_loss: 0.6948 - val_accuracy: 0.5004\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6946 - accuracy: 0.5032 - val_loss: 0.6943 - val_accuracy: 0.5004\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6942 - accuracy: 0.4952 - val_loss: 0.6939 - val_accuracy: 0.5028\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6947 - accuracy: 0.5004 - val_loss: 0.6942 - val_accuracy: 0.4976\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6941 - accuracy: 0.5112 - val_loss: 0.6957 - val_accuracy: 0.4944\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6943 - accuracy: 0.5096 - val_loss: 0.6952 - val_accuracy: 0.5144\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6944 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.4984\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5148 - val_loss: 0.6943 - val_accuracy: 0.5088\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6947 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.4928\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6940 - accuracy: 0.5100 - val_loss: 0.6937 - val_accuracy: 0.5040\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.5096\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6939 - accuracy: 0.4916 - val_loss: 0.6941 - val_accuracy: 0.4852\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6934 - accuracy: 0.5136 - val_loss: 0.6949 - val_accuracy: 0.4912\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6940 - accuracy: 0.5060 - val_loss: 0.6943 - val_accuracy: 0.4916\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6938 - accuracy: 0.5056 - val_loss: 0.6942 - val_accuracy: 0.4860\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6938 - accuracy: 0.5048 - val_loss: 0.6943 - val_accuracy: 0.5116\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6952 - val_accuracy: 0.4904\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5140 - val_loss: 0.6935 - val_accuracy: 0.5132\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6939 - accuracy: 0.5060 - val_loss: 0.6953 - val_accuracy: 0.4928\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6939 - accuracy: 0.4912 - val_loss: 0.6938 - val_accuracy: 0.4936\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6938 - accuracy: 0.5028 - val_loss: 0.6959 - val_accuracy: 0.4908\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6942 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5180\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.5168\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6938 - accuracy: 0.5156 - val_loss: 0.6940 - val_accuracy: 0.4896\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.5056 - val_loss: 0.6938 - val_accuracy: 0.4880\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6937 - accuracy: 0.5124 - val_loss: 0.6936 - val_accuracy: 0.4972\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.4940 - val_loss: 0.6977 - val_accuracy: 0.4940\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6938 - accuracy: 0.4984 - val_loss: 0.6936 - val_accuracy: 0.5148\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5144 - val_loss: 0.6956 - val_accuracy: 0.4932\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.5140\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6940 - accuracy: 0.5056 - val_loss: 0.6941 - val_accuracy: 0.5168\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.5120 - val_loss: 0.6939 - val_accuracy: 0.4884\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5012 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5124\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6936 - accuracy: 0.5108 - val_loss: 0.6946 - val_accuracy: 0.4920\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6947 - val_accuracy: 0.4904\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.5040\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6941 - accuracy: 0.5016 - val_loss: 0.6945 - val_accuracy: 0.4828\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6938 - accuracy: 0.4984 - val_loss: 0.6945 - val_accuracy: 0.5108\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5180 - val_loss: 0.6940 - val_accuracy: 0.4924\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5100 - val_loss: 0.6942 - val_accuracy: 0.4852\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.5116 - val_loss: 0.6941 - val_accuracy: 0.4916\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6939 - val_accuracy: 0.5056\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6938 - val_accuracy: 0.4872\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6939 - accuracy: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.4960\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5136 - val_loss: 0.6935 - val_accuracy: 0.5028\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6936 - accuracy: 0.4952 - val_loss: 0.6971 - val_accuracy: 0.4920\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6941 - val_accuracy: 0.5176\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5112 - val_loss: 0.6938 - val_accuracy: 0.4968\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5012 - val_loss: 0.6946 - val_accuracy: 0.4944\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.6939 - val_accuracy: 0.4888\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6929 - accuracy: 0.5216 - val_loss: 0.6938 - val_accuracy: 0.4944\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6951 - val_accuracy: 0.4896\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.4860\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5172 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6946 - val_accuracy: 0.5112\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5016 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.4868\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.4992 - val_loss: 0.6937 - val_accuracy: 0.4952\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5008 - val_loss: 0.6939 - val_accuracy: 0.5176\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6939 - accuracy: 0.4976 - val_loss: 0.6942 - val_accuracy: 0.5140\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6933 - accuracy: 0.5160 - val_loss: 0.6939 - val_accuracy: 0.4924\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.4984 - val_loss: 0.6943 - val_accuracy: 0.4880\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6940 - accuracy: 0.5016 - val_loss: 0.6969 - val_accuracy: 0.5108\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6928 - accuracy: 0.5204 - val_loss: 0.6961 - val_accuracy: 0.4868\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6939 - accuracy: 0.4996 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6937 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.5172\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6930 - accuracy: 0.5064 - val_loss: 0.6955 - val_accuracy: 0.4844\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.5088\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6934 - accuracy: 0.5116 - val_loss: 0.6956 - val_accuracy: 0.5108\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6933 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.5112\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6939 - val_accuracy: 0.4876\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6948 - val_accuracy: 0.5100\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6937 - val_accuracy: 0.4884\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6937 - val_accuracy: 0.4860\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6934 - val_accuracy: 0.4976\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.4976 - val_loss: 0.6940 - val_accuracy: 0.4912\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5112 - val_loss: 0.6947 - val_accuracy: 0.4880\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6945 - val_accuracy: 0.4924\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6937 - val_accuracy: 0.5120\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6936 - accuracy: 0.4936 - val_loss: 0.6942 - val_accuracy: 0.5124\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6938 - val_accuracy: 0.5116\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6939 - accuracy: 0.5080 - val_loss: 0.6957 - val_accuracy: 0.4916\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6931 - accuracy: 0.4980 - val_loss: 0.6968 - val_accuracy: 0.4908\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6939 - val_accuracy: 0.5144\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5044 - val_loss: 0.6936 - val_accuracy: 0.5032\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6946 - val_accuracy: 0.4852\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.4864 - val_loss: 0.6939 - val_accuracy: 0.4920\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6938 - val_accuracy: 0.5004\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6931 - accuracy: 0.5044 - val_loss: 0.6939 - val_accuracy: 0.5116\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6943 - val_accuracy: 0.4904\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6933 - accuracy: 0.5012 - val_loss: 0.6943 - val_accuracy: 0.5108\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6938 - accuracy: 0.5096 - val_loss: 0.6937 - val_accuracy: 0.5152\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6938 - accuracy: 0.4956 - val_loss: 0.6954 - val_accuracy: 0.4844\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6929 - accuracy: 0.5160 - val_loss: 0.6949 - val_accuracy: 0.4864\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.4968 - val_loss: 0.6937 - val_accuracy: 0.4852\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6959 - val_accuracy: 0.4852\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6943 - val_accuracy: 0.4924\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6942 - val_accuracy: 0.4984\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6933 - accuracy: 0.5140 - val_loss: 0.6946 - val_accuracy: 0.4872\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6976 - val_accuracy: 0.5104\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6941 - accuracy: 0.5032 - val_loss: 0.6941 - val_accuracy: 0.5168\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6939 - val_accuracy: 0.4940\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6942 - val_accuracy: 0.5096\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5096 - val_loss: 0.6950 - val_accuracy: 0.4880\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6946 - val_accuracy: 0.4928\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.4908 - val_loss: 0.6938 - val_accuracy: 0.5116\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6938 - val_accuracy: 0.4936\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6936 - accuracy: 0.4996 - val_loss: 0.6940 - val_accuracy: 0.4932\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6936 - val_accuracy: 0.4952\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6938 - val_accuracy: 0.4940\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.4960 - val_loss: 0.6941 - val_accuracy: 0.4904\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.4908\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5020 - val_loss: 0.6938 - val_accuracy: 0.5116\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 101us/sample - loss: 0.6922 - accuracy: 0.5264 - val_loss: 0.6998 - val_accuracy: 0.5092\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6939 - accuracy: 0.5068 - val_loss: 0.6937 - val_accuracy: 0.5080\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.4996 - val_loss: 0.6938 - val_accuracy: 0.4916\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.5048\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5024 - val_loss: 0.6942 - val_accuracy: 0.4872\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5004 - val_loss: 0.6940 - val_accuracy: 0.4972\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 103us/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 100us/sample - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6943 - val_accuracy: 0.4844\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 110us/sample - loss: 0.6929 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.4872\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 102us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6958 - val_accuracy: 0.5108\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.4980 - val_loss: 0.6940 - val_accuracy: 0.5136\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5056 - val_loss: 0.6944 - val_accuracy: 0.4896\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6940 - val_accuracy: 0.5120\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6928 - accuracy: 0.5220 - val_loss: 0.6955 - val_accuracy: 0.5100\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6934 - accuracy: 0.5160 - val_loss: 0.6947 - val_accuracy: 0.5112\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6932 - accuracy: 0.5140 - val_loss: 0.6945 - val_accuracy: 0.4928\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5064 - val_loss: 0.6967 - val_accuracy: 0.4904\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6940 - val_accuracy: 0.5140\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6931 - accuracy: 0.5136 - val_loss: 0.6947 - val_accuracy: 0.5120\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6960 - val_accuracy: 0.4824\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.4916\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6942 - val_accuracy: 0.5120\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6930 - accuracy: 0.5048 - val_loss: 0.6942 - val_accuracy: 0.5156\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5136 - val_loss: 0.6939 - val_accuracy: 0.5096\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6936 - accuracy: 0.4952 - val_loss: 0.6947 - val_accuracy: 0.4836\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6944 - val_accuracy: 0.5140\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6944 - val_accuracy: 0.4880\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6952 - val_accuracy: 0.4880\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6930 - accuracy: 0.5040 - val_loss: 0.6945 - val_accuracy: 0.4896\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6939 - val_accuracy: 0.4936\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6935 - accuracy: 0.5088 - val_loss: 0.6942 - val_accuracy: 0.5128\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.4924\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5028\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6928 - accuracy: 0.5148 - val_loss: 0.6941 - val_accuracy: 0.5144\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6943 - val_accuracy: 0.4932\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6933 - accuracy: 0.4996 - val_loss: 0.6939 - val_accuracy: 0.4928\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5140 - val_loss: 0.6968 - val_accuracy: 0.4864\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6941 - val_accuracy: 0.4940\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.5200 - val_loss: 0.6953 - val_accuracy: 0.4924\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6942 - val_accuracy: 0.5124\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6938 - val_accuracy: 0.5064\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6939 - val_accuracy: 0.4888\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6933 - accuracy: 0.4940 - val_loss: 0.6948 - val_accuracy: 0.4888\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5120 - val_loss: 0.6940 - val_accuracy: 0.5108\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.5108\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6936 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.5124\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.4964 - val_loss: 0.6942 - val_accuracy: 0.4920\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.5052 - val_loss: 0.6949 - val_accuracy: 0.5096\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6932 - accuracy: 0.5092 - val_loss: 0.6953 - val_accuracy: 0.4920\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6953 - val_accuracy: 0.4880\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6949 - val_accuracy: 0.4832\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6937 - val_accuracy: 0.4984\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5148 - val_loss: 0.6943 - val_accuracy: 0.4908\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.4864\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6933 - accuracy: 0.4992 - val_loss: 0.6939 - val_accuracy: 0.5084\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5148 - val_loss: 0.6941 - val_accuracy: 0.5116\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.4956\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6946 - val_accuracy: 0.5132\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6925 - accuracy: 0.5228 - val_loss: 0.6992 - val_accuracy: 0.4940\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6942 - accuracy: 0.5008 - val_loss: 0.6941 - val_accuracy: 0.5060\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6933 - accuracy: 0.5032 - val_loss: 0.6941 - val_accuracy: 0.5092\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.4960\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6951 - val_accuracy: 0.4856\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6926 - accuracy: 0.5224 - val_loss: 0.6979 - val_accuracy: 0.4920\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.4972 - val_loss: 0.6945 - val_accuracy: 0.4876\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6941 - val_accuracy: 0.5092\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6958 - val_accuracy: 0.4800\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6944 - val_accuracy: 0.5108\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4980\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.4916\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6927 - accuracy: 0.5120 - val_loss: 0.7004 - val_accuracy: 0.4924\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6942 - accuracy: 0.4980 - val_loss: 0.6947 - val_accuracy: 0.5096\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5076 - val_loss: 0.6939 - val_accuracy: 0.4848\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6934 - accuracy: 0.5064 - val_loss: 0.6943 - val_accuracy: 0.5132\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6930 - accuracy: 0.5104 - val_loss: 0.6970 - val_accuracy: 0.4924\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6942 - val_accuracy: 0.5136\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5016 - val_loss: 0.6939 - val_accuracy: 0.4860\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6931 - accuracy: 0.5168 - val_loss: 0.6943 - val_accuracy: 0.4840\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6933 - accuracy: 0.5148 - val_loss: 0.6963 - val_accuracy: 0.4892\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6926 - accuracy: 0.5204 - val_loss: 0.6942 - val_accuracy: 0.5124\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.4960 - val_loss: 0.6940 - val_accuracy: 0.5072\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.4916\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5184 - val_loss: 0.6942 - val_accuracy: 0.5132\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5028\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.4900\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6930 - accuracy: 0.5132 - val_loss: 0.6966 - val_accuracy: 0.4876\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6934 - accuracy: 0.5016 - val_loss: 0.6942 - val_accuracy: 0.4944\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.5064\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6943 - val_accuracy: 0.4888\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6931 - accuracy: 0.4996 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5112 - val_loss: 0.6949 - val_accuracy: 0.4896\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6932 - accuracy: 0.5136 - val_loss: 0.6937 - val_accuracy: 0.5068\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6957 - val_accuracy: 0.5112\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5072 - val_loss: 0.6957 - val_accuracy: 0.4872\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6945 - val_accuracy: 0.5124\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6927 - accuracy: 0.5196 - val_loss: 0.6961 - val_accuracy: 0.4856\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6930 - accuracy: 0.5112 - val_loss: 0.6951 - val_accuracy: 0.4924\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.5120 - val_loss: 0.6942 - val_accuracy: 0.4908\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6932 - accuracy: 0.5140 - val_loss: 0.6981 - val_accuracy: 0.4904\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6960 - val_accuracy: 0.4888\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6933 - accuracy: 0.4968 - val_loss: 0.6940 - val_accuracy: 0.5044\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6930 - accuracy: 0.5076 - val_loss: 0.6939 - val_accuracy: 0.4924\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6939 - val_accuracy: 0.4972\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6928 - accuracy: 0.5136 - val_loss: 0.6938 - val_accuracy: 0.5060\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6929 - accuracy: 0.5096 - val_loss: 0.6941 - val_accuracy: 0.4888\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5208 - val_loss: 0.6940 - val_accuracy: 0.5092\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6969 - val_accuracy: 0.4876\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.4924\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5092 - val_loss: 0.6938 - val_accuracy: 0.5044\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5052 - val_loss: 0.6952 - val_accuracy: 0.4872\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6927 - accuracy: 0.5168 - val_loss: 0.6943 - val_accuracy: 0.5152\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6933 - accuracy: 0.5012 - val_loss: 0.6951 - val_accuracy: 0.5108\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5080\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6934 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6946 - val_accuracy: 0.4944\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6934 - accuracy: 0.5040 - val_loss: 0.6953 - val_accuracy: 0.5112\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.5084\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5184 - val_loss: 0.6938 - val_accuracy: 0.5076\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.4900\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6943 - val_accuracy: 0.4940\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6930 - accuracy: 0.5088 - val_loss: 0.6941 - val_accuracy: 0.4928\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6942 - val_accuracy: 0.4904\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6930 - accuracy: 0.5144 - val_loss: 0.6939 - val_accuracy: 0.5084\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6937 - val_accuracy: 0.5016\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6931 - accuracy: 0.5032 - val_loss: 0.6942 - val_accuracy: 0.4840\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6929 - accuracy: 0.5020 - val_loss: 0.6984 - val_accuracy: 0.4912\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6955 - val_accuracy: 0.4892\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.4908\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6941 - val_accuracy: 0.5112\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6942 - val_accuracy: 0.4904\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6951 - val_accuracy: 0.4888\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6942 - val_accuracy: 0.4908\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6929 - accuracy: 0.5176 - val_loss: 0.6940 - val_accuracy: 0.5092\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6939 - val_accuracy: 0.5036\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5048 - val_loss: 0.6939 - val_accuracy: 0.4972\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6929 - accuracy: 0.5044 - val_loss: 0.6939 - val_accuracy: 0.4884\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6927 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.5028\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6930 - accuracy: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.5088\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6945 - val_accuracy: 0.5096\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6940 - val_accuracy: 0.5112\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6941 - val_accuracy: 0.4940\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6926 - accuracy: 0.5060 - val_loss: 0.6940 - val_accuracy: 0.4940\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6930 - accuracy: 0.5116 - val_loss: 0.6939 - val_accuracy: 0.5120\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6929 - accuracy: 0.5124 - val_loss: 0.6940 - val_accuracy: 0.5060\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6939 - val_accuracy: 0.5132\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6928 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.4912\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6939 - val_accuracy: 0.4864\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6931 - accuracy: 0.5120 - val_loss: 0.6938 - val_accuracy: 0.5012\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6939 - val_accuracy: 0.5128\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.4944 - val_loss: 0.6940 - val_accuracy: 0.4864\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5068 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.5068\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.4824\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6941 - val_accuracy: 0.4876\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5084 - val_loss: 0.6956 - val_accuracy: 0.4892\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.5060\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6930 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.4996\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5136 - val_loss: 0.6940 - val_accuracy: 0.4988\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5196 - val_loss: 0.6941 - val_accuracy: 0.4852\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5188 - val_loss: 0.6940 - val_accuracy: 0.5024\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6952 - val_accuracy: 0.4916\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6930 - accuracy: 0.5172 - val_loss: 0.6939 - val_accuracy: 0.5060\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6941 - val_accuracy: 0.5120\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6925 - accuracy: 0.5136 - val_loss: 0.6948 - val_accuracy: 0.5112\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6930 - accuracy: 0.5048 - val_loss: 0.6940 - val_accuracy: 0.4984\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6928 - accuracy: 0.5108 - val_loss: 0.6946 - val_accuracy: 0.5088\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6940 - val_accuracy: 0.4988\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6941 - val_accuracy: 0.4944\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6927 - accuracy: 0.5156 - val_loss: 0.6941 - val_accuracy: 0.4900\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6930 - accuracy: 0.5004 - val_loss: 0.6942 - val_accuracy: 0.4916\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.5056 - val_loss: 0.6945 - val_accuracy: 0.5092\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6945 - val_accuracy: 0.4812\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6928 - accuracy: 0.5256 - val_loss: 0.6940 - val_accuracy: 0.4940\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6931 - accuracy: 0.5224 - val_loss: 0.6945 - val_accuracy: 0.4924\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6928 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.5060\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6929 - accuracy: 0.5036 - val_loss: 0.6961 - val_accuracy: 0.4868\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6931 - accuracy: 0.5172 - val_loss: 0.6941 - val_accuracy: 0.4976\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6929 - accuracy: 0.5200 - val_loss: 0.6948 - val_accuracy: 0.4876\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6927 - accuracy: 0.5140 - val_loss: 0.6945 - val_accuracy: 0.5164\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5156 - val_loss: 0.6945 - val_accuracy: 0.4912\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6960 - val_accuracy: 0.4808\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6929 - accuracy: 0.5144 - val_loss: 0.6940 - val_accuracy: 0.5112\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5024 - val_loss: 0.6940 - val_accuracy: 0.4928\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6946 - val_accuracy: 0.4904\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6929 - accuracy: 0.5048 - val_loss: 0.6945 - val_accuracy: 0.4900\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4988\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6931 - accuracy: 0.5156 - val_loss: 0.6941 - val_accuracy: 0.5144\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5144 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6929 - accuracy: 0.5104 - val_loss: 0.6945 - val_accuracy: 0.4808\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5132 - val_loss: 0.6949 - val_accuracy: 0.4844\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6930 - accuracy: 0.5168 - val_loss: 0.6949 - val_accuracy: 0.4876\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6928 - accuracy: 0.5224 - val_loss: 0.6941 - val_accuracy: 0.4932\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6927 - accuracy: 0.5112 - val_loss: 0.6946 - val_accuracy: 0.4856\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6929 - accuracy: 0.5040 - val_loss: 0.6951 - val_accuracy: 0.5112\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6930 - accuracy: 0.5016 - val_loss: 0.6941 - val_accuracy: 0.5016\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6958 - val_accuracy: 0.4944\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5136 - val_loss: 0.6946 - val_accuracy: 0.5128\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6930 - accuracy: 0.5116 - val_loss: 0.6941 - val_accuracy: 0.4944\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5156 - val_loss: 0.6943 - val_accuracy: 0.4908\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6941 - val_accuracy: 0.4968\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6953 - val_accuracy: 0.4912\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6928 - accuracy: 0.5136 - val_loss: 0.6945 - val_accuracy: 0.4884\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6935 - accuracy: 0.5068 - val_loss: 0.6973 - val_accuracy: 0.4924\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6944 - val_accuracy: 0.5116\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6941 - val_accuracy: 0.5080\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6929 - accuracy: 0.5188 - val_loss: 0.6948 - val_accuracy: 0.4848\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6928 - accuracy: 0.5176 - val_loss: 0.6941 - val_accuracy: 0.4888\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6929 - accuracy: 0.5112 - val_loss: 0.6948 - val_accuracy: 0.5136\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6934 - accuracy: 0.5112 - val_loss: 0.6952 - val_accuracy: 0.5120\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6952 - val_accuracy: 0.4920\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6933 - accuracy: 0.5172 - val_loss: 0.6944 - val_accuracy: 0.4824\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6930 - accuracy: 0.5112 - val_loss: 0.6947 - val_accuracy: 0.4852\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6930 - accuracy: 0.5204 - val_loss: 0.6946 - val_accuracy: 0.5140\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6926 - accuracy: 0.5068 - val_loss: 0.6967 - val_accuracy: 0.5104\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6941 - val_accuracy: 0.5048\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6930 - accuracy: 0.5072 - val_loss: 0.6940 - val_accuracy: 0.4944\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6926 - accuracy: 0.5172 - val_loss: 0.6944 - val_accuracy: 0.4952\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6927 - accuracy: 0.5204 - val_loss: 0.6954 - val_accuracy: 0.4880\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6928 - accuracy: 0.4980 - val_loss: 0.6941 - val_accuracy: 0.4960\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6940 - val_accuracy: 0.4936\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5052 - val_loss: 0.6944 - val_accuracy: 0.5104\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5020 - val_loss: 0.6939 - val_accuracy: 0.4968\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5184 - val_loss: 0.6942 - val_accuracy: 0.4988\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5132 - val_loss: 0.6953 - val_accuracy: 0.4892\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6928 - accuracy: 0.5284 - val_loss: 0.6947 - val_accuracy: 0.4804\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5148 - val_loss: 0.6941 - val_accuracy: 0.4944\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 99us/sample - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6949 - val_accuracy: 0.4848\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5184 - val_loss: 0.6968 - val_accuracy: 0.4832\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5212 - val_loss: 0.6960 - val_accuracy: 0.4904\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6931 - accuracy: 0.5188 - val_loss: 0.6942 - val_accuracy: 0.4984\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6928 - accuracy: 0.5096 - val_loss: 0.6947 - val_accuracy: 0.4824\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6928 - accuracy: 0.5164 - val_loss: 0.6944 - val_accuracy: 0.5128\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6962 - val_accuracy: 0.4836\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6943 - val_accuracy: 0.5092\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6929 - accuracy: 0.5156 - val_loss: 0.6951 - val_accuracy: 0.5096\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6939 - val_accuracy: 0.4980\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 98us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6945 - val_accuracy: 0.4896\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 99us/sample - loss: 0.6927 - accuracy: 0.5268 - val_loss: 0.6943 - val_accuracy: 0.5148\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6923 - accuracy: 0.5176 - val_loss: 0.6947 - val_accuracy: 0.4880\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6950 - val_accuracy: 0.4848\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6943 - val_accuracy: 0.4856\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6928 - accuracy: 0.5076 - val_loss: 0.6958 - val_accuracy: 0.4868\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6941 - val_accuracy: 0.5172\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6928 - accuracy: 0.5084 - val_loss: 0.6943 - val_accuracy: 0.5072\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6942 - val_accuracy: 0.5084\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.5136\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6947 - val_accuracy: 0.5084\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6939 - val_accuracy: 0.5028\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6927 - accuracy: 0.5140 - val_loss: 0.6948 - val_accuracy: 0.4840\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.5072\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6959 - val_accuracy: 0.5112\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6950 - val_accuracy: 0.4896\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6929 - accuracy: 0.5088 - val_loss: 0.6944 - val_accuracy: 0.4868\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6929 - accuracy: 0.5124 - val_loss: 0.6941 - val_accuracy: 0.4936\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5176 - val_loss: 0.6943 - val_accuracy: 0.4864\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6926 - accuracy: 0.5144 - val_loss: 0.6943 - val_accuracy: 0.5088\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6930 - accuracy: 0.4992 - val_loss: 0.6949 - val_accuracy: 0.5116\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6927 - accuracy: 0.5096 - val_loss: 0.6945 - val_accuracy: 0.4892\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6960 - val_accuracy: 0.4792\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6933 - accuracy: 0.5168 - val_loss: 0.6943 - val_accuracy: 0.5080\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6942 - val_accuracy: 0.4848\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.6940 - val_accuracy: 0.4980\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6930 - accuracy: 0.5092 - val_loss: 0.6941 - val_accuracy: 0.4968\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6921 - accuracy: 0.5192 - val_loss: 0.6958 - val_accuracy: 0.4912\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5148 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6927 - accuracy: 0.5168 - val_loss: 0.6944 - val_accuracy: 0.4904\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6928 - accuracy: 0.5164 - val_loss: 0.6942 - val_accuracy: 0.4964\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6924 - accuracy: 0.5272 - val_loss: 0.6952 - val_accuracy: 0.5112\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.4948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5104</td></tr><tr><td>loss</td><td>0.6933</td></tr><tr><td>val_accuracy</td><td>0.4948</td></tr><tr><td>val_loss</td><td>0.694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vocal-sweep-6</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/ugpb2nc7\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/ugpb2nc7</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_221420-ugpb2nc7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tbhznpyk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_221622-tbhznpyk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/tbhznpyk\" target=\"_blank\">treasured-sweep-7</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 0s 140us/sample - loss: 5.4558 - accuracy: 0.5020 - val_loss: 4.8897 - val_accuracy: 0.5076\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 4.8788 - accuracy: 0.5020 - val_loss: 4.3185 - val_accuracy: 0.5076\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 4.0140 - accuracy: 0.5016 - val_loss: 3.3835 - val_accuracy: 0.5104\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 2.8981 - accuracy: 0.5016 - val_loss: 2.0069 - val_accuracy: 0.5080\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 1.6714 - accuracy: 0.5028 - val_loss: 1.3644 - val_accuracy: 0.5100\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 1.1741 - accuracy: 0.4980 - val_loss: 1.0623 - val_accuracy: 0.5124\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 52us/sample - loss: 0.8949 - accuracy: 0.4932 - val_loss: 0.7897 - val_accuracy: 0.5024\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.7706 - accuracy: 0.4956 - val_loss: 0.7634 - val_accuracy: 0.5012\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.7464 - accuracy: 0.4996 - val_loss: 0.7448 - val_accuracy: 0.5052\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.7326 - accuracy: 0.4944 - val_loss: 0.7334 - val_accuracy: 0.5124\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 51us/sample - loss: 0.7258 - accuracy: 0.4948 - val_loss: 0.7243 - val_accuracy: 0.5040\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.7210 - accuracy: 0.4960 - val_loss: 0.7189 - val_accuracy: 0.5016\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.7171 - accuracy: 0.4892 - val_loss: 0.7152 - val_accuracy: 0.4976\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.7137 - accuracy: 0.4884 - val_loss: 0.7125 - val_accuracy: 0.4972\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.7113 - accuracy: 0.4908 - val_loss: 0.7105 - val_accuracy: 0.4980\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.7094 - accuracy: 0.4860 - val_loss: 0.7092 - val_accuracy: 0.5020\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 52us/sample - loss: 0.7082 - accuracy: 0.4884 - val_loss: 0.7080 - val_accuracy: 0.4988\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.7069 - accuracy: 0.4892 - val_loss: 0.7068 - val_accuracy: 0.4960\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.7057 - accuracy: 0.4884 - val_loss: 0.7058 - val_accuracy: 0.5000\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.7046 - accuracy: 0.4872 - val_loss: 0.7050 - val_accuracy: 0.4988\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.7037 - accuracy: 0.4884 - val_loss: 0.7042 - val_accuracy: 0.4960\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.7028 - accuracy: 0.4872 - val_loss: 0.7035 - val_accuracy: 0.4912\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.7022 - accuracy: 0.4880 - val_loss: 0.7030 - val_accuracy: 0.4904\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.7016 - accuracy: 0.4864 - val_loss: 0.7025 - val_accuracy: 0.4928\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.7011 - accuracy: 0.4892 - val_loss: 0.7021 - val_accuracy: 0.4912\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.7006 - accuracy: 0.4904 - val_loss: 0.7017 - val_accuracy: 0.4880\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.7001 - accuracy: 0.4904 - val_loss: 0.7013 - val_accuracy: 0.4852\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6997 - accuracy: 0.4876 - val_loss: 0.7009 - val_accuracy: 0.4892\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6992 - accuracy: 0.4844 - val_loss: 0.7005 - val_accuracy: 0.4912\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6990 - accuracy: 0.4868 - val_loss: 0.7003 - val_accuracy: 0.4944\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6988 - accuracy: 0.4884 - val_loss: 0.7001 - val_accuracy: 0.4936\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6985 - accuracy: 0.4896 - val_loss: 0.6999 - val_accuracy: 0.4944\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6982 - accuracy: 0.4900 - val_loss: 0.6998 - val_accuracy: 0.4940\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6980 - accuracy: 0.4936 - val_loss: 0.6995 - val_accuracy: 0.4924\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6976 - accuracy: 0.4988 - val_loss: 0.6994 - val_accuracy: 0.4932\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6975 - accuracy: 0.4932 - val_loss: 0.6991 - val_accuracy: 0.4960\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6973 - accuracy: 0.4900 - val_loss: 0.6988 - val_accuracy: 0.4996\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6971 - accuracy: 0.4892 - val_loss: 0.6986 - val_accuracy: 0.4992\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6969 - accuracy: 0.4904 - val_loss: 0.6985 - val_accuracy: 0.4988\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6967 - accuracy: 0.4944 - val_loss: 0.6983 - val_accuracy: 0.4936\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6965 - accuracy: 0.4928 - val_loss: 0.6982 - val_accuracy: 0.4976\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.6964 - accuracy: 0.4940 - val_loss: 0.6981 - val_accuracy: 0.4952\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6962 - accuracy: 0.4936 - val_loss: 0.6980 - val_accuracy: 0.4956\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6961 - accuracy: 0.4936 - val_loss: 0.6978 - val_accuracy: 0.4944\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6959 - accuracy: 0.4960 - val_loss: 0.6976 - val_accuracy: 0.4896\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6958 - accuracy: 0.4964 - val_loss: 0.6974 - val_accuracy: 0.4968\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6956 - accuracy: 0.5032 - val_loss: 0.6973 - val_accuracy: 0.4912\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6955 - accuracy: 0.4984 - val_loss: 0.6972 - val_accuracy: 0.4904\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6954 - accuracy: 0.5008 - val_loss: 0.6971 - val_accuracy: 0.4936\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6953 - accuracy: 0.4984 - val_loss: 0.6971 - val_accuracy: 0.4884\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6951 - accuracy: 0.5016 - val_loss: 0.6969 - val_accuracy: 0.4864\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6949 - accuracy: 0.5056 - val_loss: 0.6968 - val_accuracy: 0.4872\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6948 - accuracy: 0.5028 - val_loss: 0.6966 - val_accuracy: 0.4872\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6947 - accuracy: 0.5000 - val_loss: 0.6965 - val_accuracy: 0.4856\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6947 - accuracy: 0.5040 - val_loss: 0.6965 - val_accuracy: 0.4848\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6947 - accuracy: 0.5068 - val_loss: 0.6963 - val_accuracy: 0.4876\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6945 - accuracy: 0.5040 - val_loss: 0.6963 - val_accuracy: 0.4840\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6944 - accuracy: 0.5048 - val_loss: 0.6962 - val_accuracy: 0.4808\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6943 - accuracy: 0.5112 - val_loss: 0.6962 - val_accuracy: 0.4804\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6943 - accuracy: 0.5096 - val_loss: 0.6962 - val_accuracy: 0.4808\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6944 - accuracy: 0.5100 - val_loss: 0.6960 - val_accuracy: 0.4820\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6940 - accuracy: 0.5108 - val_loss: 0.6959 - val_accuracy: 0.4788\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6940 - accuracy: 0.5136 - val_loss: 0.6958 - val_accuracy: 0.4780\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.5092 - val_loss: 0.6956 - val_accuracy: 0.4804\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.5116 - val_loss: 0.6956 - val_accuracy: 0.4828\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.5072 - val_loss: 0.6956 - val_accuracy: 0.4812\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5108 - val_loss: 0.6953 - val_accuracy: 0.4844\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5088 - val_loss: 0.6952 - val_accuracy: 0.4876\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.4960 - val_loss: 0.6952 - val_accuracy: 0.4900\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.4980 - val_loss: 0.6952 - val_accuracy: 0.4856\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6951 - val_accuracy: 0.4848\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5024 - val_loss: 0.6951 - val_accuracy: 0.4784\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.4980 - val_loss: 0.6951 - val_accuracy: 0.4784\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5032 - val_loss: 0.6950 - val_accuracy: 0.4788\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5056 - val_loss: 0.6951 - val_accuracy: 0.4824\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.5112 - val_loss: 0.6950 - val_accuracy: 0.4820\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5064 - val_loss: 0.6948 - val_accuracy: 0.4812\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5056 - val_loss: 0.6948 - val_accuracy: 0.4876\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6948 - val_accuracy: 0.4832\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5052 - val_loss: 0.6950 - val_accuracy: 0.4768\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6949 - val_accuracy: 0.4808\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6947 - val_accuracy: 0.4860\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6947 - val_accuracy: 0.4900\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5172 - val_loss: 0.6949 - val_accuracy: 0.4828\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6951 - val_accuracy: 0.4840\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6950 - val_accuracy: 0.4868\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6950 - val_accuracy: 0.4836\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6945 - val_accuracy: 0.4864\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6946 - val_accuracy: 0.4916\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6946 - val_accuracy: 0.4852\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6930 - accuracy: 0.5108 - val_loss: 0.6945 - val_accuracy: 0.4840\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6930 - accuracy: 0.5140 - val_loss: 0.6947 - val_accuracy: 0.4828\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6947 - val_accuracy: 0.4896\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.6933 - accuracy: 0.5120 - val_loss: 0.6948 - val_accuracy: 0.4848\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6951 - val_accuracy: 0.4864\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6951 - val_accuracy: 0.4864\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5004 - val_loss: 0.6949 - val_accuracy: 0.4828\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6945 - val_accuracy: 0.4856\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6945 - val_accuracy: 0.4852\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6944 - val_accuracy: 0.4860\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6930 - accuracy: 0.5072 - val_loss: 0.6944 - val_accuracy: 0.4860\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6942 - val_accuracy: 0.5008\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6943 - val_accuracy: 0.4928\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5160 - val_loss: 0.6946 - val_accuracy: 0.4852\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.4900\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5176 - val_loss: 0.6944 - val_accuracy: 0.4916\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5176 - val_loss: 0.6944 - val_accuracy: 0.4888\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5136 - val_loss: 0.6945 - val_accuracy: 0.4816\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6930 - accuracy: 0.5020 - val_loss: 0.6943 - val_accuracy: 0.4872\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6945 - val_accuracy: 0.4892\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6946 - val_accuracy: 0.4928\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6945 - val_accuracy: 0.4940\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5064 - val_loss: 0.6943 - val_accuracy: 0.4948\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.4948\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.5132 - val_loss: 0.6946 - val_accuracy: 0.4932\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6930 - accuracy: 0.5024 - val_loss: 0.6943 - val_accuracy: 0.4968\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5136 - val_loss: 0.6942 - val_accuracy: 0.4956\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5144 - val_loss: 0.6946 - val_accuracy: 0.4920\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5040 - val_loss: 0.6946 - val_accuracy: 0.4904\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5048 - val_loss: 0.6943 - val_accuracy: 0.4932\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5204 - val_loss: 0.6944 - val_accuracy: 0.4940\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6942 - val_accuracy: 0.4948\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5168 - val_loss: 0.6945 - val_accuracy: 0.4912\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5012 - val_loss: 0.6945 - val_accuracy: 0.4940\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.4952 - val_loss: 0.6942 - val_accuracy: 0.4948\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5144 - val_loss: 0.6939 - val_accuracy: 0.4956\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.5220 - val_loss: 0.6940 - val_accuracy: 0.4976\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5116 - val_loss: 0.6944 - val_accuracy: 0.4908\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5068 - val_loss: 0.6944 - val_accuracy: 0.4900\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6930 - accuracy: 0.4964 - val_loss: 0.6942 - val_accuracy: 0.5016\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5204 - val_loss: 0.6942 - val_accuracy: 0.4972\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5096 - val_loss: 0.6943 - val_accuracy: 0.4956\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5052 - val_loss: 0.6940 - val_accuracy: 0.4960\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5188 - val_loss: 0.6940 - val_accuracy: 0.4956\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5172 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.5076 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.4996 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5104 - val_loss: 0.6939 - val_accuracy: 0.4996\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6939 - val_accuracy: 0.5008\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5124 - val_loss: 0.6939 - val_accuracy: 0.5040\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6931 - accuracy: 0.5084 - val_loss: 0.6939 - val_accuracy: 0.5028\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6947 - val_accuracy: 0.4888\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5124 - val_loss: 0.6939 - val_accuracy: 0.5060\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5128 - val_loss: 0.6939 - val_accuracy: 0.5056\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5144 - val_loss: 0.6942 - val_accuracy: 0.5116\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6932 - accuracy: 0.5160 - val_loss: 0.6943 - val_accuracy: 0.4972\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6942 - val_accuracy: 0.4972\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6941 - val_accuracy: 0.4972\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5136 - val_loss: 0.6941 - val_accuracy: 0.4972\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5056 - val_loss: 0.6939 - val_accuracy: 0.5084\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5216 - val_loss: 0.6937 - val_accuracy: 0.5004\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6940 - val_accuracy: 0.4968\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.4988 - val_loss: 0.6943 - val_accuracy: 0.4892\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5072 - val_loss: 0.6940 - val_accuracy: 0.5060\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5136 - val_loss: 0.6942 - val_accuracy: 0.4960\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6927 - accuracy: 0.5112 - val_loss: 0.6948 - val_accuracy: 0.4948\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5136 - val_loss: 0.6941 - val_accuracy: 0.5080\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6942 - val_accuracy: 0.4952\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5140 - val_loss: 0.6944 - val_accuracy: 0.4972\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5148 - val_loss: 0.6947 - val_accuracy: 0.4948\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6930 - accuracy: 0.5052 - val_loss: 0.6942 - val_accuracy: 0.4884\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6946 - val_accuracy: 0.4888\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5048 - val_loss: 0.6946 - val_accuracy: 0.4892\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.4856\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6938 - val_accuracy: 0.5020\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5104 - val_loss: 0.6937 - val_accuracy: 0.5012\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5172 - val_loss: 0.6940 - val_accuracy: 0.4976\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6927 - accuracy: 0.5072 - val_loss: 0.6944 - val_accuracy: 0.4928\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6930 - accuracy: 0.5144 - val_loss: 0.6954 - val_accuracy: 0.4896\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6929 - accuracy: 0.5024 - val_loss: 0.6941 - val_accuracy: 0.5072\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6947 - val_accuracy: 0.4980\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5032 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5148 - val_loss: 0.6938 - val_accuracy: 0.5056\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5176 - val_loss: 0.6950 - val_accuracy: 0.4872\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5084 - val_loss: 0.6939 - val_accuracy: 0.5072\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5132 - val_loss: 0.6946 - val_accuracy: 0.4944\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5040 - val_loss: 0.6939 - val_accuracy: 0.5036\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6925 - accuracy: 0.5204 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5120 - val_loss: 0.6940 - val_accuracy: 0.5052\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5128 - val_loss: 0.6938 - val_accuracy: 0.5084\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6929 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.5028\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6937 - val_accuracy: 0.5004\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5160 - val_loss: 0.6938 - val_accuracy: 0.5088\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5116 - val_loss: 0.6940 - val_accuracy: 0.4968\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5104 - val_loss: 0.6941 - val_accuracy: 0.4940\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6929 - accuracy: 0.5020 - val_loss: 0.6938 - val_accuracy: 0.5012\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5080 - val_loss: 0.6936 - val_accuracy: 0.5060\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6926 - accuracy: 0.5184 - val_loss: 0.6938 - val_accuracy: 0.4988\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5124 - val_loss: 0.6941 - val_accuracy: 0.4980\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5104 - val_loss: 0.6937 - val_accuracy: 0.5056\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5096 - val_loss: 0.6938 - val_accuracy: 0.5112\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5160 - val_loss: 0.6936 - val_accuracy: 0.5028\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5180 - val_loss: 0.6936 - val_accuracy: 0.5024\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5172 - val_loss: 0.6937 - val_accuracy: 0.5048\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6938 - val_accuracy: 0.5104\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5044 - val_loss: 0.6937 - val_accuracy: 0.4996\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5176 - val_loss: 0.6938 - val_accuracy: 0.5052\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5180 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5184 - val_loss: 0.6938 - val_accuracy: 0.4964\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5224 - val_loss: 0.6940 - val_accuracy: 0.4988\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6930 - accuracy: 0.5064 - val_loss: 0.6946 - val_accuracy: 0.4888\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6938 - val_accuracy: 0.4936\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.5060 - val_loss: 0.6937 - val_accuracy: 0.4988\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5144 - val_loss: 0.6940 - val_accuracy: 0.4956\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6937 - val_accuracy: 0.5024\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5136 - val_loss: 0.6936 - val_accuracy: 0.4976\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6945 - val_accuracy: 0.4852\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5052 - val_loss: 0.6942 - val_accuracy: 0.4920\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.4912\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5176 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5144 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.5224 - val_loss: 0.6945 - val_accuracy: 0.4932\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5056 - val_loss: 0.6938 - val_accuracy: 0.5032\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6926 - accuracy: 0.4972 - val_loss: 0.6937 - val_accuracy: 0.5028\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5144 - val_loss: 0.6943 - val_accuracy: 0.4952\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5080 - val_loss: 0.6939 - val_accuracy: 0.5068\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6940 - val_accuracy: 0.5136\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6938 - val_accuracy: 0.5052\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5160 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5216 - val_loss: 0.6942 - val_accuracy: 0.4892\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.4992 - val_loss: 0.6936 - val_accuracy: 0.5012\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.5024\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6937 - val_accuracy: 0.4984\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.5020\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6937 - val_accuracy: 0.5008\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6930 - accuracy: 0.5040 - val_loss: 0.6939 - val_accuracy: 0.5016\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5188 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6925 - accuracy: 0.5180 - val_loss: 0.6938 - val_accuracy: 0.5048\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5072\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.4860\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6924 - accuracy: 0.5088 - val_loss: 0.6936 - val_accuracy: 0.5020\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6926 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.5024\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5124 - val_loss: 0.6949 - val_accuracy: 0.4924\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5040 - val_loss: 0.6939 - val_accuracy: 0.5020\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5084 - val_loss: 0.6940 - val_accuracy: 0.5028\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6924 - accuracy: 0.5208 - val_loss: 0.6947 - val_accuracy: 0.4980\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.4972\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5140 - val_loss: 0.6944 - val_accuracy: 0.4952\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6926 - accuracy: 0.5124 - val_loss: 0.6942 - val_accuracy: 0.5004\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.5076\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6938 - val_accuracy: 0.5036\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6925 - accuracy: 0.5192 - val_loss: 0.6938 - val_accuracy: 0.5032\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6937 - val_accuracy: 0.5020\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.6939 - val_accuracy: 0.5008\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6938 - val_accuracy: 0.4984\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6940 - val_accuracy: 0.5024\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6940 - val_accuracy: 0.4988\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5212 - val_loss: 0.6937 - val_accuracy: 0.5056\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6923 - accuracy: 0.5088 - val_loss: 0.6936 - val_accuracy: 0.4972\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.5060\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5184 - val_loss: 0.6937 - val_accuracy: 0.4996\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5112 - val_loss: 0.6944 - val_accuracy: 0.4952\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5048 - val_loss: 0.6938 - val_accuracy: 0.5044\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5172 - val_loss: 0.6939 - val_accuracy: 0.5076\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6930 - accuracy: 0.5124 - val_loss: 0.6938 - val_accuracy: 0.5028\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.5012\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6927 - accuracy: 0.5144 - val_loss: 0.6942 - val_accuracy: 0.5004\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6924 - accuracy: 0.5184 - val_loss: 0.6946 - val_accuracy: 0.4948\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.4988\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5104 - val_loss: 0.6939 - val_accuracy: 0.5016\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5136 - val_loss: 0.6940 - val_accuracy: 0.5020\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5192 - val_loss: 0.6942 - val_accuracy: 0.4992\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6945 - val_accuracy: 0.4988\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6940 - val_accuracy: 0.5028\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5232 - val_loss: 0.6937 - val_accuracy: 0.5068\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5164 - val_loss: 0.6937 - val_accuracy: 0.4988\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6923 - accuracy: 0.5136 - val_loss: 0.6938 - val_accuracy: 0.5028\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5196 - val_loss: 0.6941 - val_accuracy: 0.4996\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6924 - accuracy: 0.5052 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.5016\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6923 - accuracy: 0.5108 - val_loss: 0.6938 - val_accuracy: 0.4972\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5128 - val_loss: 0.6940 - val_accuracy: 0.5036\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6942 - val_accuracy: 0.4992\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5120 - val_loss: 0.6939 - val_accuracy: 0.5024\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6940 - val_accuracy: 0.5036\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5120 - val_loss: 0.6943 - val_accuracy: 0.5004\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5188 - val_loss: 0.6940 - val_accuracy: 0.5064\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6924 - accuracy: 0.5132 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6925 - accuracy: 0.5092 - val_loss: 0.6940 - val_accuracy: 0.5048\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6924 - accuracy: 0.5128 - val_loss: 0.6940 - val_accuracy: 0.5020\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5112 - val_loss: 0.6940 - val_accuracy: 0.4992\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5200 - val_loss: 0.6944 - val_accuracy: 0.4988\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6942 - val_accuracy: 0.5012\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5140 - val_loss: 0.6944 - val_accuracy: 0.4964\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5088 - val_loss: 0.6940 - val_accuracy: 0.4996\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6927 - accuracy: 0.5108 - val_loss: 0.6940 - val_accuracy: 0.5012\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5208 - val_loss: 0.6941 - val_accuracy: 0.5036\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5096 - val_loss: 0.6940 - val_accuracy: 0.5056\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6943 - val_accuracy: 0.5032\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6940 - val_accuracy: 0.4964\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6929 - accuracy: 0.5124 - val_loss: 0.6945 - val_accuracy: 0.5072\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5176 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5248 - val_loss: 0.6942 - val_accuracy: 0.5060\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6925 - accuracy: 0.5112 - val_loss: 0.6947 - val_accuracy: 0.4928\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5056 - val_loss: 0.6939 - val_accuracy: 0.5080\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.5036\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6940 - val_accuracy: 0.4956\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6946 - val_accuracy: 0.4996\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5128 - val_loss: 0.6949 - val_accuracy: 0.4988\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 52us/sample - loss: 0.6925 - accuracy: 0.5180 - val_loss: 0.6942 - val_accuracy: 0.5008\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5140 - val_loss: 0.6949 - val_accuracy: 0.4976\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.5020\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5192 - val_loss: 0.6941 - val_accuracy: 0.5028\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5012\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5208 - val_loss: 0.6940 - val_accuracy: 0.4980\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.4980\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5108 - val_loss: 0.6940 - val_accuracy: 0.4968\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6940 - val_accuracy: 0.5024\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6944 - val_accuracy: 0.5024\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6948 - val_accuracy: 0.4992\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6941 - val_accuracy: 0.5016\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6941 - val_accuracy: 0.5020\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6928 - accuracy: 0.5060 - val_loss: 0.6945 - val_accuracy: 0.5020\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5196 - val_loss: 0.6939 - val_accuracy: 0.5068\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5136 - val_loss: 0.6938 - val_accuracy: 0.5080\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6922 - accuracy: 0.5296 - val_loss: 0.6941 - val_accuracy: 0.4984\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6938 - val_accuracy: 0.5024\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5196 - val_loss: 0.6940 - val_accuracy: 0.4952\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.4872\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5084 - val_loss: 0.6942 - val_accuracy: 0.5068\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5212 - val_loss: 0.6945 - val_accuracy: 0.4940\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6942 - val_accuracy: 0.4992\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5188 - val_loss: 0.6943 - val_accuracy: 0.5044\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6940 - val_accuracy: 0.5044\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6942 - val_accuracy: 0.5052\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6926 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.5032\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6924 - accuracy: 0.4964 - val_loss: 0.6945 - val_accuracy: 0.5056\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5124 - val_loss: 0.6945 - val_accuracy: 0.5036\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5088 - val_loss: 0.6943 - val_accuracy: 0.5040\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5128 - val_loss: 0.6948 - val_accuracy: 0.5024\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6949 - val_accuracy: 0.4948\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.5084 - val_loss: 0.6942 - val_accuracy: 0.5008\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6942 - val_accuracy: 0.5036\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5024 - val_loss: 0.6944 - val_accuracy: 0.5044\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6920 - accuracy: 0.5216 - val_loss: 0.6940 - val_accuracy: 0.5064\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6925 - accuracy: 0.5192 - val_loss: 0.6940 - val_accuracy: 0.5020\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5144 - val_loss: 0.6939 - val_accuracy: 0.5056\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6941 - val_accuracy: 0.5084\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.5044\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5208 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5188 - val_loss: 0.6951 - val_accuracy: 0.4984\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6944 - val_accuracy: 0.5008\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6944 - val_accuracy: 0.5004\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5168 - val_loss: 0.6941 - val_accuracy: 0.4952\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5208 - val_loss: 0.6939 - val_accuracy: 0.4992\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6944 - val_accuracy: 0.5080\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6928 - accuracy: 0.4940 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5188 - val_loss: 0.6941 - val_accuracy: 0.5012\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5136 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5184 - val_loss: 0.6945 - val_accuracy: 0.4976\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6942 - val_accuracy: 0.4972\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5128 - val_loss: 0.6945 - val_accuracy: 0.5028\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5196 - val_loss: 0.6944 - val_accuracy: 0.5044\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6921 - accuracy: 0.5204 - val_loss: 0.6942 - val_accuracy: 0.5048\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6922 - accuracy: 0.5120 - val_loss: 0.6941 - val_accuracy: 0.5028\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6926 - accuracy: 0.5116 - val_loss: 0.6940 - val_accuracy: 0.5020\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5196 - val_loss: 0.6943 - val_accuracy: 0.5020\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6923 - accuracy: 0.5084 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6926 - accuracy: 0.5176 - val_loss: 0.6941 - val_accuracy: 0.5092\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5096 - val_loss: 0.6940 - val_accuracy: 0.5036\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6925 - accuracy: 0.5152 - val_loss: 0.6942 - val_accuracy: 0.5020\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6923 - accuracy: 0.5124 - val_loss: 0.6941 - val_accuracy: 0.4936\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5096 - val_loss: 0.6944 - val_accuracy: 0.5024\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6925 - accuracy: 0.5200 - val_loss: 0.6953 - val_accuracy: 0.4976\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5024 - val_loss: 0.6944 - val_accuracy: 0.5032\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5116 - val_loss: 0.6946 - val_accuracy: 0.5024\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6944 - val_accuracy: 0.4988\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6926 - accuracy: 0.5136 - val_loss: 0.6945 - val_accuracy: 0.4992\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6922 - accuracy: 0.5204 - val_loss: 0.6944 - val_accuracy: 0.5036\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6922 - accuracy: 0.5204 - val_loss: 0.6946 - val_accuracy: 0.4968\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6924 - accuracy: 0.5152 - val_loss: 0.6942 - val_accuracy: 0.5016\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6920 - accuracy: 0.5216 - val_loss: 0.6945 - val_accuracy: 0.5068\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6928 - accuracy: 0.5044 - val_loss: 0.6940 - val_accuracy: 0.5056\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5188 - val_loss: 0.6941 - val_accuracy: 0.5040\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6943 - val_accuracy: 0.5008\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6920 - accuracy: 0.5204 - val_loss: 0.6945 - val_accuracy: 0.5056\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6943 - val_accuracy: 0.5012\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6941 - val_accuracy: 0.4988\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6947 - val_accuracy: 0.4940\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5088 - val_loss: 0.6941 - val_accuracy: 0.5024\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6939 - val_accuracy: 0.5072\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6921 - accuracy: 0.5136 - val_loss: 0.6941 - val_accuracy: 0.5020\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6918 - accuracy: 0.5152 - val_loss: 0.6948 - val_accuracy: 0.4896\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6923 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.5056\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.4948 - val_loss: 0.6943 - val_accuracy: 0.5036\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5116 - val_loss: 0.6943 - val_accuracy: 0.5024\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6922 - accuracy: 0.5032 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6924 - accuracy: 0.5248 - val_loss: 0.6942 - val_accuracy: 0.4988\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6918 - accuracy: 0.5160 - val_loss: 0.6940 - val_accuracy: 0.4968\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6923 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.4988\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6921 - accuracy: 0.5200 - val_loss: 0.6944 - val_accuracy: 0.5004\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6921 - accuracy: 0.5124 - val_loss: 0.6943 - val_accuracy: 0.5032\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6943 - val_accuracy: 0.5004\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6921 - accuracy: 0.5252 - val_loss: 0.6945 - val_accuracy: 0.4988\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6921 - accuracy: 0.5252 - val_loss: 0.6947 - val_accuracy: 0.5032\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5100 - val_loss: 0.6940 - val_accuracy: 0.5040\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6922 - accuracy: 0.5220 - val_loss: 0.6939 - val_accuracy: 0.5120\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6941 - val_accuracy: 0.5036\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6940 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.516</td></tr><tr><td>loss</td><td>0.69188</td></tr><tr><td>val_accuracy</td><td>0.5068</td></tr><tr><td>val_loss</td><td>0.69395</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">treasured-sweep-7</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/tbhznpyk\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/tbhznpyk</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_221622-tbhznpyk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: odylz54l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_221803-odylz54l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/odylz54l\" target=\"_blank\">eager-sweep-8</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 0s 120us/sample - loss: 0.8607 - accuracy: 0.5180 - val_loss: 0.7124 - val_accuracy: 0.5116\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.7007 - accuracy: 0.5136 - val_loss: 0.7072 - val_accuracy: 0.4868\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6957 - accuracy: 0.5080 - val_loss: 0.6955 - val_accuracy: 0.5092\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6943 - accuracy: 0.5076 - val_loss: 0.6938 - val_accuracy: 0.5060\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5076\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6935 - val_accuracy: 0.5012\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6937 - val_accuracy: 0.4928\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.4924 - val_loss: 0.6936 - val_accuracy: 0.4912\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4892 - val_loss: 0.6952 - val_accuracy: 0.4872\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.4980\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6941 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.5088\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5128 - val_loss: 0.6961 - val_accuracy: 0.4880\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6944 - accuracy: 0.4992 - val_loss: 0.6939 - val_accuracy: 0.4956\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.4988 - val_loss: 0.6936 - val_accuracy: 0.5104\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4952 - val_loss: 0.6955 - val_accuracy: 0.4888\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6949 - val_accuracy: 0.5088\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.5128\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4992 - val_loss: 0.6958 - val_accuracy: 0.4968\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.5152\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.5088\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5048 - val_loss: 0.6936 - val_accuracy: 0.5104\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.4964 - val_loss: 0.6936 - val_accuracy: 0.5108\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5012 - val_loss: 0.6939 - val_accuracy: 0.4860\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6945 - val_accuracy: 0.4984\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4956 - val_loss: 0.6939 - val_accuracy: 0.5028\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6941 - accuracy: 0.5028 - val_loss: 0.6943 - val_accuracy: 0.5156\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.5108 - val_loss: 0.6942 - val_accuracy: 0.5108\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6944 - val_accuracy: 0.4956\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5048 - val_loss: 0.6934 - val_accuracy: 0.4980\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6961 - val_accuracy: 0.4940\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.4976 - val_loss: 0.6944 - val_accuracy: 0.4940\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5092 - val_loss: 0.6935 - val_accuracy: 0.5052\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6930 - accuracy: 0.5192 - val_loss: 0.6936 - val_accuracy: 0.5084\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.4976 - val_loss: 0.6938 - val_accuracy: 0.5068\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.5108 - val_loss: 0.6937 - val_accuracy: 0.5048\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6941 - val_accuracy: 0.4964\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6942 - val_accuracy: 0.4996\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.7015 - val_accuracy: 0.4920\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5056 - val_loss: 0.6938 - val_accuracy: 0.5056\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5148 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5020 - val_loss: 0.6963 - val_accuracy: 0.5088\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5240 - val_loss: 0.6991 - val_accuracy: 0.4916\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6945 - accuracy: 0.4912 - val_loss: 0.6938 - val_accuracy: 0.4904\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.4888 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.4972 - val_loss: 0.6955 - val_accuracy: 0.4892\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.4900\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6957 - val_accuracy: 0.5088\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6942 - accuracy: 0.4932 - val_loss: 0.6945 - val_accuracy: 0.4952\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.4936 - val_loss: 0.6939 - val_accuracy: 0.4984\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6960 - val_accuracy: 0.4880\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5088 - val_loss: 0.6940 - val_accuracy: 0.5088\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5112 - val_loss: 0.6983 - val_accuracy: 0.4928\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6944 - accuracy: 0.4916 - val_loss: 0.6939 - val_accuracy: 0.5084\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5004 - val_loss: 0.6962 - val_accuracy: 0.4872\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.4952 - val_loss: 0.6982 - val_accuracy: 0.4892\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5012 - val_loss: 0.6948 - val_accuracy: 0.4864\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.4996 - val_loss: 0.6957 - val_accuracy: 0.4912\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6992 - val_accuracy: 0.5088\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6945 - accuracy: 0.4964 - val_loss: 0.6937 - val_accuracy: 0.4976\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5028 - val_loss: 0.6949 - val_accuracy: 0.5088\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6933 - accuracy: 0.5144 - val_loss: 0.6957 - val_accuracy: 0.4900\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6947 - val_accuracy: 0.4928\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5128 - val_loss: 0.6958 - val_accuracy: 0.5088\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6953 - val_accuracy: 0.4884\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6980 - val_accuracy: 0.4912\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6943 - accuracy: 0.5076 - val_loss: 0.6957 - val_accuracy: 0.4908\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4900 - val_loss: 0.6966 - val_accuracy: 0.5088\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6943 - accuracy: 0.5028 - val_loss: 0.6954 - val_accuracy: 0.5088\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4976 - val_loss: 0.6973 - val_accuracy: 0.4860\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5128 - val_loss: 0.6964 - val_accuracy: 0.4884\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5104 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6938 - val_accuracy: 0.5088\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5084 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6961 - val_accuracy: 0.4860\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5008 - val_loss: 0.6942 - val_accuracy: 0.5092\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.4952 - val_loss: 0.6958 - val_accuracy: 0.4880\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4964 - val_loss: 0.6948 - val_accuracy: 0.5088\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5112 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6959 - val_accuracy: 0.4940\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6943 - val_accuracy: 0.5088\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5064 - val_loss: 0.6972 - val_accuracy: 0.4916\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6951 - val_accuracy: 0.5088\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.4972 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6956 - val_accuracy: 0.4928\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5008 - val_loss: 0.6943 - val_accuracy: 0.4928\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6943 - val_accuracy: 0.4896\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6939 - accuracy: 0.5064 - val_loss: 0.6939 - val_accuracy: 0.4988\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5004 - val_loss: 0.6957 - val_accuracy: 0.5088\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.4996 - val_loss: 0.7031 - val_accuracy: 0.4916\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6944 - accuracy: 0.5008 - val_loss: 0.6942 - val_accuracy: 0.4916\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.4956 - val_loss: 0.6954 - val_accuracy: 0.5088\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.4956 - val_loss: 0.6937 - val_accuracy: 0.4996\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6927 - accuracy: 0.5188 - val_loss: 0.6972 - val_accuracy: 0.4872\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6939 - accuracy: 0.5120 - val_loss: 0.6937 - val_accuracy: 0.4948\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5112 - val_loss: 0.6992 - val_accuracy: 0.4884\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.5068 - val_loss: 0.6936 - val_accuracy: 0.4992\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5056 - val_loss: 0.6957 - val_accuracy: 0.5088\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5108 - val_loss: 0.6962 - val_accuracy: 0.4944\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5120 - val_loss: 0.6952 - val_accuracy: 0.4956\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.4892\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5136 - val_loss: 0.6948 - val_accuracy: 0.4868\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6964 - val_accuracy: 0.4872\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.5124 - val_loss: 0.6944 - val_accuracy: 0.4924\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6938 - val_accuracy: 0.5088\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.4988 - val_loss: 0.6937 - val_accuracy: 0.5020\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6941 - val_accuracy: 0.5088\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6935 - val_accuracy: 0.5072\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6933 - accuracy: 0.5124 - val_loss: 0.6937 - val_accuracy: 0.5012\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5004\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6935 - val_accuracy: 0.5064\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6936 - accuracy: 0.4980 - val_loss: 0.6956 - val_accuracy: 0.5088\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6940 - accuracy: 0.5004 - val_loss: 0.6943 - val_accuracy: 0.5088\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4864 - val_loss: 0.6980 - val_accuracy: 0.4872\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6929 - accuracy: 0.5200 - val_loss: 0.7042 - val_accuracy: 0.4916\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6946 - accuracy: 0.4996 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5152 - val_loss: 0.6937 - val_accuracy: 0.5084\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.4952 - val_loss: 0.6936 - val_accuracy: 0.5108\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5096 - val_loss: 0.6977 - val_accuracy: 0.5088\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6936 - val_accuracy: 0.5040\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.4956 - val_loss: 0.6971 - val_accuracy: 0.4892\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.5020\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.4912 - val_loss: 0.6941 - val_accuracy: 0.5084\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6937 - val_accuracy: 0.5076\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6938 - val_accuracy: 0.4932\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6947 - val_accuracy: 0.5088\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6933 - accuracy: 0.5124 - val_loss: 0.6958 - val_accuracy: 0.4936\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5172 - val_loss: 0.6962 - val_accuracy: 0.5088\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6939 - accuracy: 0.5108 - val_loss: 0.6961 - val_accuracy: 0.4868\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6951 - val_accuracy: 0.5088\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.4980 - val_loss: 0.6954 - val_accuracy: 0.5088\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6939 - val_accuracy: 0.4904\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5028 - val_loss: 0.6968 - val_accuracy: 0.4880\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.4996 - val_loss: 0.6947 - val_accuracy: 0.4948\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5112 - val_loss: 0.6949 - val_accuracy: 0.4880\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6940 - val_accuracy: 0.4968\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.4992\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6985 - val_accuracy: 0.5088\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6948 - accuracy: 0.4992 - val_loss: 0.6941 - val_accuracy: 0.4996\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5064 - val_loss: 0.6939 - val_accuracy: 0.4988\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5056 - val_loss: 0.6937 - val_accuracy: 0.4868\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6949 - val_accuracy: 0.5088\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5020 - val_loss: 0.6935 - val_accuracy: 0.4856\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6938 - accuracy: 0.4968 - val_loss: 0.6941 - val_accuracy: 0.4904\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6933 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.5064\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6938 - accuracy: 0.4976 - val_loss: 0.6952 - val_accuracy: 0.4952\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6937 - val_accuracy: 0.5016\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6952 - val_accuracy: 0.5088\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5108 - val_loss: 0.6956 - val_accuracy: 0.4836\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5104 - val_loss: 0.6978 - val_accuracy: 0.5088\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5172 - val_loss: 0.6952 - val_accuracy: 0.5088\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5008 - val_loss: 0.6964 - val_accuracy: 0.4908\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5100 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6943 - accuracy: 0.4832 - val_loss: 0.6953 - val_accuracy: 0.4896\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.4972 - val_loss: 0.6969 - val_accuracy: 0.4904\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6987 - val_accuracy: 0.4860\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6937 - accuracy: 0.5128 - val_loss: 0.6971 - val_accuracy: 0.5088\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.5012 - val_loss: 0.7035 - val_accuracy: 0.4916\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.4948\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6925 - accuracy: 0.5120 - val_loss: 0.6997 - val_accuracy: 0.5088\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6947 - accuracy: 0.5004 - val_loss: 0.6971 - val_accuracy: 0.4920\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6966 - val_accuracy: 0.5088\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6946 - accuracy: 0.5056 - val_loss: 0.6969 - val_accuracy: 0.5088\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5104 - val_loss: 0.6975 - val_accuracy: 0.4860\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5132 - val_loss: 0.6937 - val_accuracy: 0.4988\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5012 - val_loss: 0.6957 - val_accuracy: 0.5088\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6939 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.5032\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6939 - val_accuracy: 0.5052\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.4924 - val_loss: 0.6971 - val_accuracy: 0.4900\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.4928 - val_loss: 0.6959 - val_accuracy: 0.4852\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.4964\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6963 - val_accuracy: 0.4928\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.4940 - val_loss: 0.7002 - val_accuracy: 0.4924\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5012 - val_loss: 0.6958 - val_accuracy: 0.4980\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5124 - val_loss: 0.6938 - val_accuracy: 0.5020\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6993 - val_accuracy: 0.4916\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6945 - accuracy: 0.4924 - val_loss: 0.6947 - val_accuracy: 0.4896\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6933 - accuracy: 0.5160 - val_loss: 0.6948 - val_accuracy: 0.4896\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5076 - val_loss: 0.6971 - val_accuracy: 0.5088\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6944 - accuracy: 0.4996 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6963 - val_accuracy: 0.4876\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5148 - val_loss: 0.7000 - val_accuracy: 0.4916\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6940 - accuracy: 0.4968 - val_loss: 0.6970 - val_accuracy: 0.4880\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6968 - val_accuracy: 0.5088\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5124 - val_loss: 0.6964 - val_accuracy: 0.4932\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.7023 - val_accuracy: 0.4900\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6946 - accuracy: 0.4992 - val_loss: 0.6946 - val_accuracy: 0.4896\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6960 - val_accuracy: 0.4864\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5068 - val_loss: 0.6937 - val_accuracy: 0.4980\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6955 - val_accuracy: 0.4984\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6958 - val_accuracy: 0.4980\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6938 - val_accuracy: 0.5024\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5068 - val_loss: 0.6984 - val_accuracy: 0.4864\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5080 - val_loss: 0.6949 - val_accuracy: 0.4908\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5044 - val_loss: 0.6966 - val_accuracy: 0.4896\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5128 - val_loss: 0.6949 - val_accuracy: 0.5088\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5028 - val_loss: 0.6973 - val_accuracy: 0.4904\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6961 - val_accuracy: 0.5088\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5092 - val_loss: 0.6988 - val_accuracy: 0.5088\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.6951 - val_accuracy: 0.5088\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.4988 - val_loss: 0.6941 - val_accuracy: 0.5088\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6937 - val_accuracy: 0.5072\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.4992\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6946 - val_accuracy: 0.5088\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5052 - val_loss: 0.6935 - val_accuracy: 0.5012\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6919 - accuracy: 0.5256 - val_loss: 0.6940 - val_accuracy: 0.5088\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5008 - val_loss: 0.6993 - val_accuracy: 0.4924\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4988 - val_loss: 0.6937 - val_accuracy: 0.5024\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6948 - val_accuracy: 0.4956\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6953 - val_accuracy: 0.4972\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6940 - val_accuracy: 0.4996\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.4984\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5056 - val_loss: 0.6936 - val_accuracy: 0.5068\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5148 - val_loss: 0.6937 - val_accuracy: 0.5072\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6935 - val_accuracy: 0.5084\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5084 - val_loss: 0.6936 - val_accuracy: 0.4988\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6938 - val_accuracy: 0.5008\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6938 - val_accuracy: 0.5076\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.4884\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6941 - val_accuracy: 0.4980\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6938 - accuracy: 0.5108 - val_loss: 0.7029 - val_accuracy: 0.4904\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6944 - accuracy: 0.5008 - val_loss: 0.6976 - val_accuracy: 0.4900\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.5072 - val_loss: 0.6941 - val_accuracy: 0.4892\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.4988 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5164 - val_loss: 0.6941 - val_accuracy: 0.4960\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6927 - accuracy: 0.5228 - val_loss: 0.6953 - val_accuracy: 0.4984\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5060 - val_loss: 0.6943 - val_accuracy: 0.5088\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5056 - val_loss: 0.6941 - val_accuracy: 0.5072\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5140 - val_loss: 0.6955 - val_accuracy: 0.4972\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6967 - val_accuracy: 0.4888\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.4912 - val_loss: 0.6946 - val_accuracy: 0.5084\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5132 - val_loss: 0.6946 - val_accuracy: 0.4936\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6939 - val_accuracy: 0.4956\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6936 - val_accuracy: 0.5064\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5032 - val_loss: 0.6936 - val_accuracy: 0.5008\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6944 - val_accuracy: 0.4948\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5048 - val_loss: 0.6951 - val_accuracy: 0.4844\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6974 - val_accuracy: 0.4860\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6938 - val_accuracy: 0.5008\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6947 - val_accuracy: 0.4864\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6935 - val_accuracy: 0.5012\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6937 - val_accuracy: 0.4964\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6933 - accuracy: 0.5012 - val_loss: 0.6999 - val_accuracy: 0.5088\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6945 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.5088\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6932 - accuracy: 0.5188 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5060 - val_loss: 0.6945 - val_accuracy: 0.5088\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5088 - val_loss: 0.6938 - val_accuracy: 0.4928\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5168 - val_loss: 0.6951 - val_accuracy: 0.5088\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6942 - val_accuracy: 0.4928\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.5076\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5156 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5068 - val_loss: 0.7008 - val_accuracy: 0.4920\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6939 - accuracy: 0.5116 - val_loss: 0.6981 - val_accuracy: 0.4876\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5168 - val_loss: 0.6999 - val_accuracy: 0.5088\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6950 - accuracy: 0.5100 - val_loss: 0.6948 - val_accuracy: 0.4916\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5148 - val_loss: 0.6949 - val_accuracy: 0.5088\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6930 - accuracy: 0.5120 - val_loss: 0.6946 - val_accuracy: 0.4964\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5044 - val_loss: 0.6939 - val_accuracy: 0.5044\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5076 - val_loss: 0.6950 - val_accuracy: 0.4992\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4952 - val_loss: 0.6940 - val_accuracy: 0.4960\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6926 - accuracy: 0.5112 - val_loss: 0.6942 - val_accuracy: 0.5140\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5068 - val_loss: 0.6939 - val_accuracy: 0.5016\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5212 - val_loss: 0.6937 - val_accuracy: 0.5056\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.4984 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.4984 - val_loss: 0.6956 - val_accuracy: 0.5088\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.4916 - val_loss: 0.6959 - val_accuracy: 0.5088\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.5060\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5068 - val_loss: 0.6938 - val_accuracy: 0.5020\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6966 - val_accuracy: 0.4876\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.4992 - val_loss: 0.7007 - val_accuracy: 0.4916\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6937 - accuracy: 0.5140 - val_loss: 0.6963 - val_accuracy: 0.4940\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6968 - val_accuracy: 0.4868\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6930 - accuracy: 0.5220 - val_loss: 0.6950 - val_accuracy: 0.4980\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6983 - val_accuracy: 0.4900\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.4976 - val_loss: 0.6982 - val_accuracy: 0.5088\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6945 - accuracy: 0.4956 - val_loss: 0.6936 - val_accuracy: 0.5084\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6967 - val_accuracy: 0.4912\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6936 - accuracy: 0.5104 - val_loss: 0.6947 - val_accuracy: 0.4896\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5124 - val_loss: 0.6968 - val_accuracy: 0.5088\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6939 - accuracy: 0.5048 - val_loss: 0.6962 - val_accuracy: 0.5088\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6939 - accuracy: 0.5144 - val_loss: 0.6940 - val_accuracy: 0.4936\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5160 - val_loss: 0.6946 - val_accuracy: 0.4932\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6937 - accuracy: 0.4996 - val_loss: 0.6946 - val_accuracy: 0.5088\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6949 - val_accuracy: 0.5084\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.5040\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.4824\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6944 - val_accuracy: 0.5088\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5156 - val_loss: 0.6984 - val_accuracy: 0.5088\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6938 - accuracy: 0.5140 - val_loss: 0.6960 - val_accuracy: 0.4864\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6937 - val_accuracy: 0.4824\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5020 - val_loss: 0.6935 - val_accuracy: 0.5036\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5164 - val_loss: 0.6967 - val_accuracy: 0.4920\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.4984 - val_loss: 0.6946 - val_accuracy: 0.4864\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6956 - val_accuracy: 0.5088\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6951 - val_accuracy: 0.5088\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.4980\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6936 - val_accuracy: 0.4952\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5024 - val_loss: 0.7026 - val_accuracy: 0.4924\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6944 - accuracy: 0.4940 - val_loss: 0.6970 - val_accuracy: 0.4900\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6940 - accuracy: 0.4960 - val_loss: 0.7019 - val_accuracy: 0.4920\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6941 - accuracy: 0.5016 - val_loss: 0.6943 - val_accuracy: 0.5088\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5096 - val_loss: 0.6940 - val_accuracy: 0.4984\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6938 - accuracy: 0.5124 - val_loss: 0.6965 - val_accuracy: 0.4904\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6940 - accuracy: 0.4992 - val_loss: 0.6937 - val_accuracy: 0.4932\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6957 - val_accuracy: 0.4856\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.4980\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6928 - accuracy: 0.5204 - val_loss: 0.6942 - val_accuracy: 0.4980\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.4984 - val_loss: 0.6938 - val_accuracy: 0.5096\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5024 - val_loss: 0.6941 - val_accuracy: 0.4976\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6931 - accuracy: 0.5176 - val_loss: 0.6950 - val_accuracy: 0.4952\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5112 - val_loss: 0.6941 - val_accuracy: 0.5064\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 51us/sample - loss: 0.6938 - accuracy: 0.4956 - val_loss: 0.6945 - val_accuracy: 0.4932\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 51us/sample - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6945 - val_accuracy: 0.5088\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6937 - accuracy: 0.5132 - val_loss: 0.7008 - val_accuracy: 0.4920\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.6931 - accuracy: 0.5136 - val_loss: 0.6937 - val_accuracy: 0.5092\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6928 - accuracy: 0.5108 - val_loss: 0.6983 - val_accuracy: 0.4916\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6936 - accuracy: 0.4972 - val_loss: 0.6952 - val_accuracy: 0.5088\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6939 - accuracy: 0.4972 - val_loss: 0.6954 - val_accuracy: 0.5080\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 50us/sample - loss: 0.6936 - accuracy: 0.5104 - val_loss: 0.6937 - val_accuracy: 0.4956\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 54us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6942 - val_accuracy: 0.5136\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5124 - val_loss: 0.6945 - val_accuracy: 0.5088\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.5080\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5176 - val_loss: 0.6969 - val_accuracy: 0.4912\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6942 - accuracy: 0.5056 - val_loss: 0.6951 - val_accuracy: 0.4940\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6936 - accuracy: 0.4984 - val_loss: 0.7004 - val_accuracy: 0.4916\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.7033 - val_accuracy: 0.4916\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6947 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.4980\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6941 - val_accuracy: 0.5088\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6982 - val_accuracy: 0.4900\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.4928 - val_loss: 0.6937 - val_accuracy: 0.5064\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5052 - val_loss: 0.6939 - val_accuracy: 0.4872\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6935 - accuracy: 0.4996 - val_loss: 0.6941 - val_accuracy: 0.4844\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6940 - val_accuracy: 0.5056\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 51us/sample - loss: 0.6936 - accuracy: 0.5104 - val_loss: 0.6940 - val_accuracy: 0.5016\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6936 - val_accuracy: 0.4908\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.7040 - val_accuracy: 0.4916\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6945 - accuracy: 0.5004 - val_loss: 0.6941 - val_accuracy: 0.4980\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6929 - accuracy: 0.5044 - val_loss: 0.6956 - val_accuracy: 0.5088\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 51us/sample - loss: 0.6939 - accuracy: 0.4968 - val_loss: 0.6970 - val_accuracy: 0.5088\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6944 - accuracy: 0.4988 - val_loss: 0.6967 - val_accuracy: 0.5088\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6941 - accuracy: 0.4980 - val_loss: 0.6944 - val_accuracy: 0.5088\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 0s 53us/sample - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6959 - val_accuracy: 0.5088\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6942 - accuracy: 0.4872 - val_loss: 0.6950 - val_accuracy: 0.5088\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6936 - accuracy: 0.4992 - val_loss: 0.6942 - val_accuracy: 0.5056\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6935 - accuracy: 0.5024 - val_loss: 0.6938 - val_accuracy: 0.5004\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6932 - accuracy: 0.5192 - val_loss: 0.6937 - val_accuracy: 0.4964\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6945 - val_accuracy: 0.4888\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6937 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.5048\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5020\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6934 - accuracy: 0.4948 - val_loss: 0.6939 - val_accuracy: 0.5088\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.5004 - val_loss: 0.6938 - val_accuracy: 0.4976\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 49us/sample - loss: 0.6933 - accuracy: 0.5200 - val_loss: 0.6958 - val_accuracy: 0.4940\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5056 - val_loss: 0.6945 - val_accuracy: 0.4924\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6956 - val_accuracy: 0.4996\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.6980 - val_accuracy: 0.5088\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6969 - val_accuracy: 0.4876\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5024 - val_loss: 0.6963 - val_accuracy: 0.4872\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6936 - accuracy: 0.4892 - val_loss: 0.6936 - val_accuracy: 0.5036\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.4988 - val_loss: 0.6936 - val_accuracy: 0.4912\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6947 - val_accuracy: 0.4992\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.4944 - val_loss: 0.6964 - val_accuracy: 0.4888\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6937 - accuracy: 0.4976 - val_loss: 0.6976 - val_accuracy: 0.5088\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6944 - accuracy: 0.5032 - val_loss: 0.6936 - val_accuracy: 0.5024\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6929 - accuracy: 0.5172 - val_loss: 0.6935 - val_accuracy: 0.4988\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6936 - accuracy: 0.4912 - val_loss: 0.6936 - val_accuracy: 0.4968\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6933 - accuracy: 0.4976 - val_loss: 0.6961 - val_accuracy: 0.5088\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6938 - accuracy: 0.5012 - val_loss: 0.6941 - val_accuracy: 0.4936\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6952 - val_accuracy: 0.4880\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6931 - accuracy: 0.5040 - val_loss: 0.6937 - val_accuracy: 0.4876\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5008 - val_loss: 0.6936 - val_accuracy: 0.4988\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5016 - val_loss: 0.6971 - val_accuracy: 0.4932\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6951 - val_accuracy: 0.5072\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.4952 - val_loss: 0.6955 - val_accuracy: 0.5080\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6936 - accuracy: 0.5176 - val_loss: 0.6957 - val_accuracy: 0.5024\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6932 - accuracy: 0.5128 - val_loss: 0.6993 - val_accuracy: 0.5088\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 48us/sample - loss: 0.6943 - accuracy: 0.5152 - val_loss: 0.6950 - val_accuracy: 0.5088\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.7009 - val_accuracy: 0.4916\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6941 - accuracy: 0.5028 - val_loss: 0.6946 - val_accuracy: 0.5088\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6933 - accuracy: 0.5140 - val_loss: 0.6955 - val_accuracy: 0.5088\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6937 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.4980\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 45us/sample - loss: 0.6934 - accuracy: 0.5116 - val_loss: 0.6957 - val_accuracy: 0.4856\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6953 - val_accuracy: 0.4880\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6937 - accuracy: 0.5116 - val_loss: 0.6955 - val_accuracy: 0.4852\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6940 - val_accuracy: 0.5028\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6936 - accuracy: 0.4960 - val_loss: 0.6939 - val_accuracy: 0.5008\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6930 - accuracy: 0.5140 - val_loss: 0.6949 - val_accuracy: 0.4900\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6962 - val_accuracy: 0.4976\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 47us/sample - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6941 - val_accuracy: 0.4976\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6932 - accuracy: 0.5128 - val_loss: 0.6942 - val_accuracy: 0.5012\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6931 - accuracy: 0.5076 - val_loss: 0.6953 - val_accuracy: 0.5088\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 44us/sample - loss: 0.6938 - accuracy: 0.5092 - val_loss: 0.6949 - val_accuracy: 0.4852\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 43us/sample - loss: 0.6936 - accuracy: 0.5056 - val_loss: 0.6950 - val_accuracy: 0.5088\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 46us/sample - loss: 0.6938 - accuracy: 0.4908 - val_loss: 0.6937 - val_accuracy: 0.4972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.4908</td></tr><tr><td>loss</td><td>0.69382</td></tr><tr><td>val_accuracy</td><td>0.4972</td></tr><tr><td>val_loss</td><td>0.69366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-8</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/odylz54l\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/odylz54l</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_221803-odylz54l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pdvn1wx8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_221947-pdvn1wx8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/pdvn1wx8\" target=\"_blank\">whole-sweep-9</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 1s 254us/sample - loss: 3.0246 - accuracy: 0.5016 - val_loss: 1.0489 - val_accuracy: 0.5088\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.7957 - accuracy: 0.4996 - val_loss: 0.7011 - val_accuracy: 0.5180\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.7025 - accuracy: 0.4880 - val_loss: 0.6976 - val_accuracy: 0.4996\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6991 - accuracy: 0.4948 - val_loss: 0.6966 - val_accuracy: 0.4936\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6977 - accuracy: 0.4884 - val_loss: 0.6959 - val_accuracy: 0.4884\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6972 - accuracy: 0.4892 - val_loss: 0.6959 - val_accuracy: 0.4844\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6959 - accuracy: 0.5112 - val_loss: 0.6958 - val_accuracy: 0.4904\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6966 - accuracy: 0.4964 - val_loss: 0.6958 - val_accuracy: 0.5028\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6962 - accuracy: 0.4848 - val_loss: 0.6971 - val_accuracy: 0.4892\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6962 - accuracy: 0.4992 - val_loss: 0.6958 - val_accuracy: 0.4836\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6962 - accuracy: 0.5020 - val_loss: 0.6951 - val_accuracy: 0.4944\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6962 - accuracy: 0.4884 - val_loss: 0.6956 - val_accuracy: 0.5100\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6956 - accuracy: 0.4892 - val_loss: 0.6949 - val_accuracy: 0.4972\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6958 - accuracy: 0.4852 - val_loss: 0.6947 - val_accuracy: 0.4956\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6956 - accuracy: 0.4848 - val_loss: 0.6946 - val_accuracy: 0.4972\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6952 - accuracy: 0.4964 - val_loss: 0.6948 - val_accuracy: 0.5152\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6955 - accuracy: 0.4900 - val_loss: 0.6943 - val_accuracy: 0.4864\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6956 - accuracy: 0.4928 - val_loss: 0.6943 - val_accuracy: 0.4860\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6953 - accuracy: 0.4816 - val_loss: 0.6942 - val_accuracy: 0.4980\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.6951 - accuracy: 0.4932 - val_loss: 0.6942 - val_accuracy: 0.4996\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6954 - accuracy: 0.4912 - val_loss: 0.6944 - val_accuracy: 0.5116\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6955 - accuracy: 0.4984 - val_loss: 0.6944 - val_accuracy: 0.4876\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 182us/sample - loss: 0.6958 - accuracy: 0.4832 - val_loss: 0.6943 - val_accuracy: 0.4896\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6938 - accuracy: 0.5104 - val_loss: 0.7009 - val_accuracy: 0.4912\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6954 - accuracy: 0.4980 - val_loss: 0.6943 - val_accuracy: 0.4864\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6953 - accuracy: 0.4796 - val_loss: 0.6938 - val_accuracy: 0.4944\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6949 - accuracy: 0.4964 - val_loss: 0.6943 - val_accuracy: 0.4928\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6949 - accuracy: 0.4936 - val_loss: 0.6936 - val_accuracy: 0.4916\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6949 - accuracy: 0.4916 - val_loss: 0.6938 - val_accuracy: 0.4952\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6945 - accuracy: 0.5028 - val_loss: 0.6940 - val_accuracy: 0.4884\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6947 - accuracy: 0.4996 - val_loss: 0.6950 - val_accuracy: 0.4948\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6941 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6942 - accuracy: 0.5044 - val_loss: 0.6935 - val_accuracy: 0.4928\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 171us/sample - loss: 0.6945 - accuracy: 0.4940 - val_loss: 0.6940 - val_accuracy: 0.4940\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6942 - accuracy: 0.5104 - val_loss: 0.6943 - val_accuracy: 0.5096\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6942 - accuracy: 0.5004 - val_loss: 0.6943 - val_accuracy: 0.4944\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6945 - accuracy: 0.4988 - val_loss: 0.6937 - val_accuracy: 0.5064\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6942 - accuracy: 0.5136 - val_loss: 0.6933 - val_accuracy: 0.5148\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6948 - accuracy: 0.4936 - val_loss: 0.6935 - val_accuracy: 0.4916\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6941 - accuracy: 0.4976 - val_loss: 0.6936 - val_accuracy: 0.4952\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 173us/sample - loss: 0.6941 - accuracy: 0.5008 - val_loss: 0.6937 - val_accuracy: 0.4928\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6942 - accuracy: 0.4984 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6941 - accuracy: 0.5012 - val_loss: 0.6933 - val_accuracy: 0.4992\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6943 - accuracy: 0.4964 - val_loss: 0.6944 - val_accuracy: 0.4904\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6941 - accuracy: 0.4932 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6956 - val_accuracy: 0.4932\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6945 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.5124\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6944 - accuracy: 0.4976 - val_loss: 0.6939 - val_accuracy: 0.4992\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 0.6936 - accuracy: 0.5180 - val_loss: 0.6938 - val_accuracy: 0.5028\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6937 - accuracy: 0.5128 - val_loss: 0.6936 - val_accuracy: 0.5016\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6944 - accuracy: 0.5048 - val_loss: 0.6933 - val_accuracy: 0.4968\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6944 - accuracy: 0.5092 - val_loss: 0.6941 - val_accuracy: 0.4928\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6940 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5156\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5100\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6941 - accuracy: 0.5032 - val_loss: 0.6933 - val_accuracy: 0.5088\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6936 - accuracy: 0.5056 - val_loss: 0.6955 - val_accuracy: 0.5088\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6948 - accuracy: 0.5076 - val_loss: 0.6937 - val_accuracy: 0.4992\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6945 - accuracy: 0.4796 - val_loss: 0.6936 - val_accuracy: 0.4916\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6940 - accuracy: 0.4988 - val_loss: 0.6939 - val_accuracy: 0.4876\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6927 - accuracy: 0.5244 - val_loss: 0.7014 - val_accuracy: 0.4912\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6943 - accuracy: 0.5040 - val_loss: 0.6942 - val_accuracy: 0.5108\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6938 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.5096\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6938 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.4980\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6942 - accuracy: 0.5024 - val_loss: 0.6959 - val_accuracy: 0.4936\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6935 - accuracy: 0.5084 - val_loss: 0.6937 - val_accuracy: 0.4928\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6937 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5116\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6938 - accuracy: 0.5068 - val_loss: 0.6932 - val_accuracy: 0.5152\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.5112\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6934 - val_accuracy: 0.5108\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6940 - accuracy: 0.5084 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6938 - accuracy: 0.5060 - val_loss: 0.6933 - val_accuracy: 0.5020\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6972 - val_accuracy: 0.5088\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6935 - val_accuracy: 0.4944\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6934 - accuracy: 0.5100 - val_loss: 0.6938 - val_accuracy: 0.4896\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6941 - accuracy: 0.4992 - val_loss: 0.6936 - val_accuracy: 0.4996\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6939 - accuracy: 0.5016 - val_loss: 0.6935 - val_accuracy: 0.5068\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6936 - accuracy: 0.5080 - val_loss: 0.6933 - val_accuracy: 0.5124\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6936 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6940 - accuracy: 0.4916 - val_loss: 0.6934 - val_accuracy: 0.5092\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6965 - val_accuracy: 0.4908\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6937 - accuracy: 0.5120 - val_loss: 0.6943 - val_accuracy: 0.5104\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6934 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.4864\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6937 - val_accuracy: 0.5140\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6937 - accuracy: 0.5040 - val_loss: 0.6944 - val_accuracy: 0.5100\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6944 - accuracy: 0.4944 - val_loss: 0.6934 - val_accuracy: 0.5124\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6932 - val_accuracy: 0.5076\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6933 - accuracy: 0.5164 - val_loss: 0.6942 - val_accuracy: 0.4884\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 183us/sample - loss: 0.6935 - accuracy: 0.5136 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 171us/sample - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6936 - val_accuracy: 0.5140\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 181us/sample - loss: 0.6932 - accuracy: 0.5124 - val_loss: 0.6941 - val_accuracy: 0.5084\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 176us/sample - loss: 0.6935 - accuracy: 0.5100 - val_loss: 0.6935 - val_accuracy: 0.4940\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 174us/sample - loss: 0.6941 - accuracy: 0.4984 - val_loss: 0.6937 - val_accuracy: 0.4908\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 173us/sample - loss: 0.6938 - accuracy: 0.5008 - val_loss: 0.6934 - val_accuracy: 0.5164\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 180us/sample - loss: 0.6938 - accuracy: 0.5152 - val_loss: 0.6949 - val_accuracy: 0.4900\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 173us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6932 - val_accuracy: 0.5060\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.6934 - val_accuracy: 0.4996\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 177us/sample - loss: 0.6931 - accuracy: 0.5244 - val_loss: 0.6934 - val_accuracy: 0.5116\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6944 - val_accuracy: 0.4884\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6937 - accuracy: 0.5020 - val_loss: 0.6952 - val_accuracy: 0.4900\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 172us/sample - loss: 0.6933 - accuracy: 0.4980 - val_loss: 0.6950 - val_accuracy: 0.4924\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6940 - accuracy: 0.4992 - val_loss: 0.6938 - val_accuracy: 0.5072\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6938 - accuracy: 0.5052 - val_loss: 0.6933 - val_accuracy: 0.5108\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6940 - accuracy: 0.5060 - val_loss: 0.6934 - val_accuracy: 0.5088\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6942 - val_accuracy: 0.4912\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6938 - val_accuracy: 0.4912\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6933 - accuracy: 0.5104 - val_loss: 0.6935 - val_accuracy: 0.5056\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6959 - val_accuracy: 0.4908\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5108\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6944 - val_accuracy: 0.4908\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6962 - val_accuracy: 0.4932\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6932 - accuracy: 0.5172 - val_loss: 0.6944 - val_accuracy: 0.5084\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6938 - accuracy: 0.5148 - val_loss: 0.6935 - val_accuracy: 0.5012\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 183us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6937 - val_accuracy: 0.4968\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 173us/sample - loss: 0.6934 - accuracy: 0.5116 - val_loss: 0.6949 - val_accuracy: 0.4856\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 176us/sample - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6941 - val_accuracy: 0.4884\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6933 - val_accuracy: 0.5120\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6936 - accuracy: 0.5024 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.5008\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 173us/sample - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6934 - val_accuracy: 0.4972\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 174us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.4892\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6930 - accuracy: 0.5204 - val_loss: 0.6959 - val_accuracy: 0.4944\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6938 - accuracy: 0.5028 - val_loss: 0.6937 - val_accuracy: 0.4896\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.6942 - val_accuracy: 0.4944\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6942 - accuracy: 0.5004 - val_loss: 0.6933 - val_accuracy: 0.5048\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6934 - accuracy: 0.5044 - val_loss: 0.6934 - val_accuracy: 0.5088\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6946 - val_accuracy: 0.4948\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6943 - val_accuracy: 0.4932\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6929 - accuracy: 0.5180 - val_loss: 0.6942 - val_accuracy: 0.5136\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6941 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.5144\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6934 - accuracy: 0.5044 - val_loss: 0.6941 - val_accuracy: 0.4852\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6930 - accuracy: 0.5104 - val_loss: 0.6936 - val_accuracy: 0.5160\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6932 - accuracy: 0.5168 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6944 - val_accuracy: 0.5116\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6934 - val_accuracy: 0.5140\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6965 - val_accuracy: 0.4932\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6936 - accuracy: 0.4960 - val_loss: 0.6939 - val_accuracy: 0.4884\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6933 - val_accuracy: 0.5064\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6931 - accuracy: 0.5180 - val_loss: 0.6942 - val_accuracy: 0.4868\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6934 - accuracy: 0.5064 - val_loss: 0.6946 - val_accuracy: 0.4936\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6940 - val_accuracy: 0.4880\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6930 - accuracy: 0.5168 - val_loss: 0.6934 - val_accuracy: 0.5048\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6932 - accuracy: 0.5084 - val_loss: 0.6950 - val_accuracy: 0.4888\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.4952\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6931 - accuracy: 0.5004 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6928 - accuracy: 0.4948 - val_loss: 0.6940 - val_accuracy: 0.5172\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6931 - accuracy: 0.5220 - val_loss: 0.6934 - val_accuracy: 0.5056\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6934 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6930 - accuracy: 0.5164 - val_loss: 0.6939 - val_accuracy: 0.5024\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6931 - accuracy: 0.5212 - val_loss: 0.6947 - val_accuracy: 0.4872\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6939 - val_accuracy: 0.5164\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6933 - accuracy: 0.5052 - val_loss: 0.6940 - val_accuracy: 0.4980\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6934 - accuracy: 0.4992 - val_loss: 0.6936 - val_accuracy: 0.5112\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6943 - val_accuracy: 0.5132\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6935 - accuracy: 0.4988 - val_loss: 0.6937 - val_accuracy: 0.5056\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6941 - val_accuracy: 0.4840\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6932 - accuracy: 0.5140 - val_loss: 0.6937 - val_accuracy: 0.5008\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6930 - accuracy: 0.5108 - val_loss: 0.6938 - val_accuracy: 0.5028\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6923 - accuracy: 0.5180 - val_loss: 0.6956 - val_accuracy: 0.4884\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 157us/sample - loss: 0.6933 - accuracy: 0.5168 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6927 - accuracy: 0.5116 - val_loss: 0.6934 - val_accuracy: 0.5092\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6930 - accuracy: 0.5056 - val_loss: 0.6934 - val_accuracy: 0.5104\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6934 - accuracy: 0.5116 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6928 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.5156\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6927 - accuracy: 0.5184 - val_loss: 0.6936 - val_accuracy: 0.5044\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6930 - accuracy: 0.5028 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6926 - accuracy: 0.5116 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6942 - val_accuracy: 0.4908\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6938 - val_accuracy: 0.5108\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6937 - val_accuracy: 0.5152\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6930 - accuracy: 0.5104 - val_loss: 0.6938 - val_accuracy: 0.5112\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6928 - accuracy: 0.5116 - val_loss: 0.6935 - val_accuracy: 0.5152\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6940 - val_accuracy: 0.4952\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6928 - accuracy: 0.5204 - val_loss: 0.6948 - val_accuracy: 0.4908\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6926 - accuracy: 0.5116 - val_loss: 0.6935 - val_accuracy: 0.5120\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6939 - val_accuracy: 0.5120\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6929 - accuracy: 0.5008 - val_loss: 0.6939 - val_accuracy: 0.5136\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6930 - accuracy: 0.4992 - val_loss: 0.6946 - val_accuracy: 0.4912\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.4940\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6929 - accuracy: 0.5144 - val_loss: 0.6934 - val_accuracy: 0.5100\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6926 - accuracy: 0.5192 - val_loss: 0.6937 - val_accuracy: 0.5124\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6928 - accuracy: 0.5252 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6925 - accuracy: 0.5204 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6926 - accuracy: 0.5168 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6927 - accuracy: 0.5160 - val_loss: 0.6940 - val_accuracy: 0.4992\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6924 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.5124\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6928 - accuracy: 0.5036 - val_loss: 0.6935 - val_accuracy: 0.5184\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6927 - accuracy: 0.5084 - val_loss: 0.6934 - val_accuracy: 0.5104\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6942 - val_accuracy: 0.5152\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5128\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6922 - accuracy: 0.5116 - val_loss: 0.6934 - val_accuracy: 0.5160\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6921 - accuracy: 0.5132 - val_loss: 0.6944 - val_accuracy: 0.4992\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6922 - accuracy: 0.5176 - val_loss: 0.6934 - val_accuracy: 0.5172\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6931 - val_accuracy: 0.5164\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6916 - accuracy: 0.5148 - val_loss: 0.6957 - val_accuracy: 0.4984\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6925 - accuracy: 0.5100 - val_loss: 0.6946 - val_accuracy: 0.4996\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 176us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6949 - val_accuracy: 0.5052\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6920 - accuracy: 0.5244 - val_loss: 0.6932 - val_accuracy: 0.5180\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.6924 - accuracy: 0.5108 - val_loss: 0.6930 - val_accuracy: 0.5212\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6947 - val_accuracy: 0.5132\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.6917 - accuracy: 0.5272 - val_loss: 0.6941 - val_accuracy: 0.5160\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6922 - accuracy: 0.5060 - val_loss: 0.6933 - val_accuracy: 0.5148\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6931 - val_accuracy: 0.5212\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6949 - val_accuracy: 0.5120\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6932 - val_accuracy: 0.5184\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6927 - val_accuracy: 0.5240\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6910 - accuracy: 0.5224 - val_loss: 0.6927 - val_accuracy: 0.5280\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6917 - accuracy: 0.5120 - val_loss: 0.6922 - val_accuracy: 0.5224\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6909 - accuracy: 0.5108 - val_loss: 0.6920 - val_accuracy: 0.5308\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5260\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6899 - accuracy: 0.5228 - val_loss: 0.6935 - val_accuracy: 0.5288\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6900 - accuracy: 0.5356 - val_loss: 0.6921 - val_accuracy: 0.5332\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6896 - accuracy: 0.5360 - val_loss: 0.6921 - val_accuracy: 0.5324\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6900 - accuracy: 0.5284 - val_loss: 0.6905 - val_accuracy: 0.5408\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6892 - accuracy: 0.5356 - val_loss: 0.6913 - val_accuracy: 0.5376\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6886 - accuracy: 0.5340 - val_loss: 0.6916 - val_accuracy: 0.5416\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6884 - accuracy: 0.5296 - val_loss: 0.6917 - val_accuracy: 0.5224\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6885 - accuracy: 0.5364 - val_loss: 0.6888 - val_accuracy: 0.5396\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6884 - accuracy: 0.5376 - val_loss: 0.6888 - val_accuracy: 0.5496\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 157us/sample - loss: 0.6877 - accuracy: 0.5348 - val_loss: 0.6876 - val_accuracy: 0.5376\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6872 - accuracy: 0.5364 - val_loss: 0.6897 - val_accuracy: 0.5416\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6869 - accuracy: 0.5336 - val_loss: 0.6884 - val_accuracy: 0.5416\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6860 - accuracy: 0.5336 - val_loss: 0.6869 - val_accuracy: 0.5496\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.6851 - accuracy: 0.5436 - val_loss: 0.6865 - val_accuracy: 0.5448\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6843 - accuracy: 0.5400 - val_loss: 0.6852 - val_accuracy: 0.5532\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6822 - accuracy: 0.5420 - val_loss: 0.6864 - val_accuracy: 0.5396\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6812 - accuracy: 0.5468 - val_loss: 0.6816 - val_accuracy: 0.5628\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6796 - accuracy: 0.5588 - val_loss: 0.6797 - val_accuracy: 0.5592\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6772 - accuracy: 0.5632 - val_loss: 0.6743 - val_accuracy: 0.5824\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6694 - accuracy: 0.5784 - val_loss: 0.6757 - val_accuracy: 0.5852\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6724 - accuracy: 0.5864 - val_loss: 0.6737 - val_accuracy: 0.5892\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6627 - accuracy: 0.5956 - val_loss: 0.6598 - val_accuracy: 0.6136\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6551 - accuracy: 0.6096 - val_loss: 0.6629 - val_accuracy: 0.6060\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6635 - accuracy: 0.6072 - val_loss: 0.6564 - val_accuracy: 0.6184\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6483 - accuracy: 0.6180 - val_loss: 0.6623 - val_accuracy: 0.6164\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6458 - accuracy: 0.6228 - val_loss: 0.6568 - val_accuracy: 0.6212\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6450 - accuracy: 0.6236 - val_loss: 0.6496 - val_accuracy: 0.6240\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6412 - accuracy: 0.6336 - val_loss: 0.6646 - val_accuracy: 0.6040\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 154us/sample - loss: 0.6407 - accuracy: 0.6396 - val_loss: 0.6544 - val_accuracy: 0.6164\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 153us/sample - loss: 0.6430 - accuracy: 0.6400 - val_loss: 0.6460 - val_accuracy: 0.6376\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6370 - accuracy: 0.6312 - val_loss: 0.6625 - val_accuracy: 0.6356\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6363 - accuracy: 0.6352 - val_loss: 0.6431 - val_accuracy: 0.6436\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6320 - accuracy: 0.6408 - val_loss: 0.6477 - val_accuracy: 0.6316\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6352 - accuracy: 0.6440 - val_loss: 0.6694 - val_accuracy: 0.6372\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6274 - accuracy: 0.6508 - val_loss: 0.6486 - val_accuracy: 0.6476\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6252 - accuracy: 0.6516 - val_loss: 0.6468 - val_accuracy: 0.6420\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.6264 - accuracy: 0.6556 - val_loss: 0.6377 - val_accuracy: 0.6376\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6233 - accuracy: 0.6524 - val_loss: 0.6428 - val_accuracy: 0.6464\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6183 - accuracy: 0.6596 - val_loss: 0.6355 - val_accuracy: 0.6524\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.6149 - accuracy: 0.6580 - val_loss: 0.6419 - val_accuracy: 0.6592\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6141 - accuracy: 0.6584 - val_loss: 0.6468 - val_accuracy: 0.6600\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6129 - accuracy: 0.6608 - val_loss: 0.6351 - val_accuracy: 0.6624\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6080 - accuracy: 0.6644 - val_loss: 0.6374 - val_accuracy: 0.6592\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.6052 - accuracy: 0.6652 - val_loss: 0.6428 - val_accuracy: 0.6576\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6044 - accuracy: 0.6688 - val_loss: 0.6310 - val_accuracy: 0.6616\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.6033 - accuracy: 0.6660 - val_loss: 0.6329 - val_accuracy: 0.6612\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6049 - accuracy: 0.6672 - val_loss: 0.6351 - val_accuracy: 0.6572\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.5984 - accuracy: 0.6740 - val_loss: 0.6222 - val_accuracy: 0.6664\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5961 - accuracy: 0.6716 - val_loss: 0.6233 - val_accuracy: 0.6604\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5939 - accuracy: 0.6752 - val_loss: 0.6263 - val_accuracy: 0.6664\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.5910 - accuracy: 0.6792 - val_loss: 0.6297 - val_accuracy: 0.6720\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.5875 - accuracy: 0.6832 - val_loss: 0.6116 - val_accuracy: 0.6720\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.6052 - accuracy: 0.6728 - val_loss: 0.6267 - val_accuracy: 0.6616\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.5844 - accuracy: 0.6848 - val_loss: 0.6125 - val_accuracy: 0.6820\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.5796 - accuracy: 0.6908 - val_loss: 0.6097 - val_accuracy: 0.6860\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.5789 - accuracy: 0.6912 - val_loss: 0.6143 - val_accuracy: 0.6804\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.5756 - accuracy: 0.6968 - val_loss: 0.6117 - val_accuracy: 0.6792\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.5730 - accuracy: 0.6932 - val_loss: 0.6071 - val_accuracy: 0.6856\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.5770 - accuracy: 0.6980 - val_loss: 0.6047 - val_accuracy: 0.6804\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.5649 - accuracy: 0.6972 - val_loss: 0.6076 - val_accuracy: 0.6784\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.5653 - accuracy: 0.7008 - val_loss: 0.5972 - val_accuracy: 0.6864\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.5613 - accuracy: 0.7036 - val_loss: 0.6034 - val_accuracy: 0.6904\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.5561 - accuracy: 0.7068 - val_loss: 0.5954 - val_accuracy: 0.6904\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.5537 - accuracy: 0.7152 - val_loss: 0.5912 - val_accuracy: 0.6960\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6137 - accuracy: 0.6716 - val_loss: 0.7553 - val_accuracy: 0.5604\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.6299 - accuracy: 0.6588 - val_loss: 0.5892 - val_accuracy: 0.6908\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.5602 - accuracy: 0.7172 - val_loss: 0.5843 - val_accuracy: 0.6988\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.5472 - accuracy: 0.7216 - val_loss: 0.5883 - val_accuracy: 0.7072\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.5409 - accuracy: 0.7276 - val_loss: 0.5843 - val_accuracy: 0.7084\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 181us/sample - loss: 0.5395 - accuracy: 0.7240 - val_loss: 0.5845 - val_accuracy: 0.7160\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 175us/sample - loss: 0.5340 - accuracy: 0.7284 - val_loss: 0.5726 - val_accuracy: 0.7140\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.5299 - accuracy: 0.7296 - val_loss: 0.5817 - val_accuracy: 0.7044\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 176us/sample - loss: 0.5281 - accuracy: 0.7292 - val_loss: 0.5886 - val_accuracy: 0.7148\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.5251 - accuracy: 0.7376 - val_loss: 0.5703 - val_accuracy: 0.7212\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.5286 - accuracy: 0.7308 - val_loss: 0.5605 - val_accuracy: 0.7340\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.5185 - accuracy: 0.7412 - val_loss: 0.5547 - val_accuracy: 0.7316\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.5153 - accuracy: 0.7420 - val_loss: 0.5618 - val_accuracy: 0.7352\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.5088 - accuracy: 0.7540 - val_loss: 0.5558 - val_accuracy: 0.7404\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.5074 - accuracy: 0.7556 - val_loss: 0.5398 - val_accuracy: 0.7348\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.5123 - accuracy: 0.7468 - val_loss: 0.5739 - val_accuracy: 0.7096\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 172us/sample - loss: 0.4960 - accuracy: 0.7620 - val_loss: 0.5506 - val_accuracy: 0.7512\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.4900 - accuracy: 0.7700 - val_loss: 0.5315 - val_accuracy: 0.7580\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.4841 - accuracy: 0.7744 - val_loss: 0.5246 - val_accuracy: 0.7600\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.4847 - accuracy: 0.7720 - val_loss: 0.5221 - val_accuracy: 0.7620\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.4753 - accuracy: 0.7796 - val_loss: 0.5140 - val_accuracy: 0.7776\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.4730 - accuracy: 0.7864 - val_loss: 0.5243 - val_accuracy: 0.7796\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 171us/sample - loss: 0.4623 - accuracy: 0.7904 - val_loss: 0.5038 - val_accuracy: 0.7740\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.4533 - accuracy: 0.7956 - val_loss: 0.4921 - val_accuracy: 0.7960\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.4506 - accuracy: 0.8024 - val_loss: 0.4808 - val_accuracy: 0.8020\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.7486 - accuracy: 0.6504 - val_loss: 0.8732 - val_accuracy: 0.5764\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.8330 - accuracy: 0.5940 - val_loss: 0.8091 - val_accuracy: 0.5940\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.7729 - accuracy: 0.6152 - val_loss: 0.7600 - val_accuracy: 0.6132\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.7271 - accuracy: 0.6328 - val_loss: 0.7198 - val_accuracy: 0.6316\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 165us/sample - loss: 0.6864 - accuracy: 0.6604 - val_loss: 0.6859 - val_accuracy: 0.6480\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.6564 - accuracy: 0.6772 - val_loss: 0.6599 - val_accuracy: 0.6624\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6337 - accuracy: 0.6864 - val_loss: 0.6388 - val_accuracy: 0.6732\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.6158 - accuracy: 0.6908 - val_loss: 0.6225 - val_accuracy: 0.6792\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.6023 - accuracy: 0.6972 - val_loss: 0.6093 - val_accuracy: 0.6844\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5921 - accuracy: 0.7032 - val_loss: 0.5994 - val_accuracy: 0.6912\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.5844 - accuracy: 0.7032 - val_loss: 0.5917 - val_accuracy: 0.6964\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5785 - accuracy: 0.7060 - val_loss: 0.5859 - val_accuracy: 0.7000\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.5739 - accuracy: 0.7040 - val_loss: 0.5811 - val_accuracy: 0.7004\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5703 - accuracy: 0.7032 - val_loss: 0.5772 - val_accuracy: 0.7020\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5674 - accuracy: 0.7064 - val_loss: 0.5741 - val_accuracy: 0.7048\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.5649 - accuracy: 0.7096 - val_loss: 0.5713 - val_accuracy: 0.7068\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5628 - accuracy: 0.7120 - val_loss: 0.5690 - val_accuracy: 0.7084\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.5608 - accuracy: 0.7128 - val_loss: 0.5670 - val_accuracy: 0.7100\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5591 - accuracy: 0.7148 - val_loss: 0.5650 - val_accuracy: 0.7148\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5573 - accuracy: 0.7160 - val_loss: 0.5631 - val_accuracy: 0.7192\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.5557 - accuracy: 0.7188 - val_loss: 0.5613 - val_accuracy: 0.7220\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 0.5540 - accuracy: 0.7216 - val_loss: 0.5596 - val_accuracy: 0.7272\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 174us/sample - loss: 0.5524 - accuracy: 0.7244 - val_loss: 0.5579 - val_accuracy: 0.7324\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5506 - accuracy: 0.7284 - val_loss: 0.5561 - val_accuracy: 0.7372\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.5488 - accuracy: 0.7340 - val_loss: 0.5541 - val_accuracy: 0.7452\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 192us/sample - loss: 0.5472 - accuracy: 0.7364 - val_loss: 0.5525 - val_accuracy: 0.7472\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 1s 241us/sample - loss: 0.5452 - accuracy: 0.7388 - val_loss: 0.5507 - val_accuracy: 0.7476\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 167us/sample - loss: 0.5434 - accuracy: 0.7428 - val_loss: 0.5485 - val_accuracy: 0.7536\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.5412 - accuracy: 0.7480 - val_loss: 0.5464 - val_accuracy: 0.7560\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.5394 - accuracy: 0.7504 - val_loss: 0.5447 - val_accuracy: 0.7580\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5370 - accuracy: 0.7592 - val_loss: 0.5420 - val_accuracy: 0.7632\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5344 - accuracy: 0.7588 - val_loss: 0.5396 - val_accuracy: 0.7664\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5319 - accuracy: 0.7628 - val_loss: 0.5392 - val_accuracy: 0.7612\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.5296 - accuracy: 0.7648 - val_loss: 0.5344 - val_accuracy: 0.7696\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5388 - accuracy: 0.7544 - val_loss: 0.5488 - val_accuracy: 0.7552\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.5296 - accuracy: 0.7688 - val_loss: 0.5300 - val_accuracy: 0.7748\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.5213 - accuracy: 0.7748 - val_loss: 0.5263 - val_accuracy: 0.7780\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.5175 - accuracy: 0.7752 - val_loss: 0.5231 - val_accuracy: 0.7788\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 157us/sample - loss: 0.5140 - accuracy: 0.7772 - val_loss: 0.5201 - val_accuracy: 0.7800\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.5106 - accuracy: 0.7804 - val_loss: 0.5165 - val_accuracy: 0.7788\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.5069 - accuracy: 0.7828 - val_loss: 0.5128 - val_accuracy: 0.7812\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.5042 - accuracy: 0.7808 - val_loss: 0.5102 - val_accuracy: 0.7828\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.4987 - accuracy: 0.7896 - val_loss: 0.5048 - val_accuracy: 0.7908\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.4946 - accuracy: 0.7884 - val_loss: 0.4999 - val_accuracy: 0.7944\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 1s 217us/sample - loss: 0.4896 - accuracy: 0.7964 - val_loss: 0.4958 - val_accuracy: 0.7960\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 1s 203us/sample - loss: 0.4856 - accuracy: 0.7928 - val_loss: 0.4912 - val_accuracy: 0.7972\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 1s 240us/sample - loss: 0.4838 - accuracy: 0.8016 - val_loss: 0.4870 - val_accuracy: 0.8016\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 0.4786 - accuracy: 0.8028 - val_loss: 0.4997 - val_accuracy: 0.8156\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.4795 - accuracy: 0.8064 - val_loss: 0.4778 - val_accuracy: 0.8128\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.4640 - accuracy: 0.8144 - val_loss: 0.4710 - val_accuracy: 0.8140\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 1s 252us/sample - loss: 0.4585 - accuracy: 0.8188 - val_loss: 0.4645 - val_accuracy: 0.8240\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.4526 - accuracy: 0.8280 - val_loss: 0.4580 - val_accuracy: 0.8208\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 172us/sample - loss: 0.4463 - accuracy: 0.8232 - val_loss: 0.4555 - val_accuracy: 0.8340\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.4398 - accuracy: 0.8288 - val_loss: 0.4451 - val_accuracy: 0.8300\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.4412 - accuracy: 0.8340 - val_loss: 0.4477 - val_accuracy: 0.8388\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.4452 - accuracy: 0.8380 - val_loss: 0.4353 - val_accuracy: 0.8372\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.4345 - accuracy: 0.8360 - val_loss: 0.4240 - val_accuracy: 0.8492\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 1s 211us/sample - loss: 0.4210 - accuracy: 0.8424 - val_loss: 0.4146 - val_accuracy: 0.8576\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 1s 255us/sample - loss: 0.4119 - accuracy: 0.8584 - val_loss: 0.4133 - val_accuracy: 0.8536\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.4339 - accuracy: 0.8608 - val_loss: 0.4081 - val_accuracy: 0.8608\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.3910 - accuracy: 0.8636 - val_loss: 0.3976 - val_accuracy: 0.8676\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.3975 - accuracy: 0.8660 - val_loss: 0.3849 - val_accuracy: 0.8784\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 1s 210us/sample - loss: 0.3798 - accuracy: 0.8780 - val_loss: 0.3895 - val_accuracy: 0.8776\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 175us/sample - loss: 0.3957 - accuracy: 0.8648 - val_loss: 0.4402 - val_accuracy: 0.8452\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.3779 - accuracy: 0.8784 - val_loss: 0.3795 - val_accuracy: 0.8840\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.3539 - accuracy: 0.8936 - val_loss: 0.3750 - val_accuracy: 0.8928\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 172us/sample - loss: 0.3576 - accuracy: 0.9100 - val_loss: 0.3558 - val_accuracy: 0.9084\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.3420 - accuracy: 0.9152 - val_loss: 0.3662 - val_accuracy: 0.9028\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.3331 - accuracy: 0.9136 - val_loss: 0.3596 - val_accuracy: 0.9080\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.3545 - accuracy: 0.9196 - val_loss: 0.3622 - val_accuracy: 0.9088\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.3302 - accuracy: 0.9160 - val_loss: 0.3451 - val_accuracy: 0.9164\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.3220 - accuracy: 0.9264 - val_loss: 0.3419 - val_accuracy: 0.9220\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.3186 - accuracy: 0.9268 - val_loss: 0.3407 - val_accuracy: 0.9256\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.3287 - accuracy: 0.9284 - val_loss: 0.3355 - val_accuracy: 0.9248\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.3357 - accuracy: 0.9324 - val_loss: 0.3523 - val_accuracy: 0.9284\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.3474 - accuracy: 0.9384 - val_loss: 0.3566 - val_accuracy: 0.9324\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.3454 - accuracy: 0.9396 - val_loss: 0.3346 - val_accuracy: 0.9356\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.3308 - accuracy: 0.9416 - val_loss: 0.3088 - val_accuracy: 0.9372\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.3395 - accuracy: 0.9340 - val_loss: 0.6318 - val_accuracy: 0.8176\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.3121 - accuracy: 0.9328 - val_loss: 0.2725 - val_accuracy: 0.9404\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.2879 - accuracy: 0.9432 - val_loss: 0.2726 - val_accuracy: 0.9384\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.3125 - accuracy: 0.9448 - val_loss: 0.3056 - val_accuracy: 0.9412\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 163us/sample - loss: 0.3022 - accuracy: 0.9444 - val_loss: 0.2684 - val_accuracy: 0.9448\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 171us/sample - loss: 0.2885 - accuracy: 0.9488 - val_loss: 0.2695 - val_accuracy: 0.9408\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 170us/sample - loss: 0.3004 - accuracy: 0.9488 - val_loss: 0.2781 - val_accuracy: 0.9448\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 166us/sample - loss: 0.2835 - accuracy: 0.9496 - val_loss: 0.2666 - val_accuracy: 0.9468\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.2888 - accuracy: 0.9512 - val_loss: 0.2737 - val_accuracy: 0.9460\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 168us/sample - loss: 0.3360 - accuracy: 0.9428 - val_loss: 0.2641 - val_accuracy: 0.9492\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 0.2685 - accuracy: 0.9512 - val_loss: 0.2394 - val_accuracy: 0.9564\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 161us/sample - loss: 0.2640 - accuracy: 0.9536 - val_loss: 0.2379 - val_accuracy: 0.9568\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.4089 - accuracy: 0.9096 - val_loss: 0.3000 - val_accuracy: 0.9220\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.2510 - accuracy: 0.9424 - val_loss: 0.2175 - val_accuracy: 0.9500\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 158us/sample - loss: 0.2355 - accuracy: 0.9512 - val_loss: 0.2036 - val_accuracy: 0.9512\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 164us/sample - loss: 0.2277 - accuracy: 0.9504 - val_loss: 0.2117 - val_accuracy: 0.9496\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.2238 - accuracy: 0.9524 - val_loss: 0.2129 - val_accuracy: 0.9556\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 0.2678 - accuracy: 0.9560 - val_loss: 0.2000 - val_accuracy: 0.9584\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 160us/sample - loss: 0.2366 - accuracy: 0.9556 - val_loss: 0.1969 - val_accuracy: 0.9544\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 162us/sample - loss: 0.2169 - accuracy: 0.9524 - val_loss: 0.2024 - val_accuracy: 0.9520\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9524</td></tr><tr><td>loss</td><td>0.21694</td></tr><tr><td>val_accuracy</td><td>0.952</td></tr><tr><td>val_loss</td><td>0.20243</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">whole-sweep-9</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/pdvn1wx8\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/pdvn1wx8</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_221947-pdvn1wx8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mpu3764q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_222317-mpu3764q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/mpu3764q\" target=\"_blank\">devoted-sweep-10</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 0s 159us/sample - loss: 1.1780 - accuracy: 0.4880 - val_loss: 0.7125 - val_accuracy: 0.4980\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.7025 - accuracy: 0.4828 - val_loss: 0.6953 - val_accuracy: 0.4868\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6962 - accuracy: 0.4928 - val_loss: 0.6991 - val_accuracy: 0.4924\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6951 - accuracy: 0.4832 - val_loss: 0.6935 - val_accuracy: 0.5136\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6947 - accuracy: 0.5076 - val_loss: 0.6933 - val_accuracy: 0.5116\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6952 - accuracy: 0.4932 - val_loss: 0.6954 - val_accuracy: 0.4908\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6950 - accuracy: 0.4920 - val_loss: 0.7002 - val_accuracy: 0.4916\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.7015 - val_accuracy: 0.5088\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6943 - accuracy: 0.5200 - val_loss: 0.6963 - val_accuracy: 0.4952\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6955 - accuracy: 0.4920 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6946 - accuracy: 0.4904 - val_loss: 0.6966 - val_accuracy: 0.4924\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6946 - accuracy: 0.4900 - val_loss: 0.6943 - val_accuracy: 0.4932\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6945 - accuracy: 0.5104 - val_loss: 0.6946 - val_accuracy: 0.4896\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6944 - accuracy: 0.4920 - val_loss: 0.6951 - val_accuracy: 0.4924\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6941 - accuracy: 0.5072 - val_loss: 0.6953 - val_accuracy: 0.4916\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6946 - accuracy: 0.4880 - val_loss: 0.6940 - val_accuracy: 0.5088\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6948 - accuracy: 0.4852 - val_loss: 0.6939 - val_accuracy: 0.5156\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6943 - accuracy: 0.5104 - val_loss: 0.6933 - val_accuracy: 0.5092\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6952 - accuracy: 0.4908 - val_loss: 0.6932 - val_accuracy: 0.5056\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6944 - accuracy: 0.5008 - val_loss: 0.6980 - val_accuracy: 0.5088\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.4944 - val_loss: 0.7025 - val_accuracy: 0.5088\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6952 - accuracy: 0.4916 - val_loss: 0.6933 - val_accuracy: 0.4964\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6939 - accuracy: 0.5040 - val_loss: 0.6963 - val_accuracy: 0.4916\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6947 - accuracy: 0.5008 - val_loss: 0.6930 - val_accuracy: 0.5100\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6942 - accuracy: 0.5048 - val_loss: 0.6959 - val_accuracy: 0.4916\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6945 - accuracy: 0.4984 - val_loss: 0.6935 - val_accuracy: 0.4976\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6946 - accuracy: 0.5000 - val_loss: 0.6945 - val_accuracy: 0.4936\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6943 - accuracy: 0.5052 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6943 - accuracy: 0.4956 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6940 - accuracy: 0.5064 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5024\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6942 - accuracy: 0.5004 - val_loss: 0.6938 - val_accuracy: 0.4964\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6942 - accuracy: 0.4908 - val_loss: 0.6939 - val_accuracy: 0.4980\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6944 - accuracy: 0.5064 - val_loss: 0.6934 - val_accuracy: 0.5048\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6935 - accuracy: 0.5112 - val_loss: 0.6940 - val_accuracy: 0.4992\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6942 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5024\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6942 - accuracy: 0.4848 - val_loss: 0.6937 - val_accuracy: 0.5132\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6945 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.5148\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6945 - accuracy: 0.4884 - val_loss: 0.6932 - val_accuracy: 0.5040\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6944 - accuracy: 0.4960 - val_loss: 0.6954 - val_accuracy: 0.5136\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6939 - accuracy: 0.5084 - val_loss: 0.6944 - val_accuracy: 0.4972\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6939 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5044\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6942 - accuracy: 0.4900 - val_loss: 0.6930 - val_accuracy: 0.5040\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5020\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6941 - accuracy: 0.5080 - val_loss: 0.6932 - val_accuracy: 0.5072\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6943 - accuracy: 0.4900 - val_loss: 0.6930 - val_accuracy: 0.5080\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6946 - accuracy: 0.4868 - val_loss: 0.6949 - val_accuracy: 0.4892\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.4916\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.4944 - val_loss: 0.6976 - val_accuracy: 0.5088\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6950 - accuracy: 0.4972 - val_loss: 0.6929 - val_accuracy: 0.5064\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6992 - val_accuracy: 0.5088\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6946 - accuracy: 0.5036 - val_loss: 0.6954 - val_accuracy: 0.5088\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6944 - accuracy: 0.4992 - val_loss: 0.6930 - val_accuracy: 0.5120\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6941 - accuracy: 0.5020 - val_loss: 0.6933 - val_accuracy: 0.5056\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6942 - accuracy: 0.4936 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6938 - accuracy: 0.5152 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6940 - accuracy: 0.5004 - val_loss: 0.6937 - val_accuracy: 0.4988\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6942 - accuracy: 0.4988 - val_loss: 0.6933 - val_accuracy: 0.5020\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6944 - accuracy: 0.5116 - val_loss: 0.6932 - val_accuracy: 0.5028\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6943 - accuracy: 0.4964 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.6933 - val_accuracy: 0.5048\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6941 - accuracy: 0.5024 - val_loss: 0.6942 - val_accuracy: 0.4920\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.5080 - val_loss: 0.7001 - val_accuracy: 0.4912\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6949 - accuracy: 0.4992 - val_loss: 0.6948 - val_accuracy: 0.4956\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6942 - accuracy: 0.5080 - val_loss: 0.6955 - val_accuracy: 0.4924\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6942 - accuracy: 0.5016 - val_loss: 0.6934 - val_accuracy: 0.5136\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6941 - accuracy: 0.4936 - val_loss: 0.6931 - val_accuracy: 0.5064\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6941 - accuracy: 0.4976 - val_loss: 0.6952 - val_accuracy: 0.5088\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6941 - accuracy: 0.5064 - val_loss: 0.6930 - val_accuracy: 0.5128\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.5024 - val_loss: 0.6935 - val_accuracy: 0.5116\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6941 - accuracy: 0.5020 - val_loss: 0.6944 - val_accuracy: 0.5096\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6940 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5128\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6943 - accuracy: 0.5044 - val_loss: 0.6940 - val_accuracy: 0.4928\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6945 - accuracy: 0.4852 - val_loss: 0.6940 - val_accuracy: 0.5124\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6942 - accuracy: 0.5032 - val_loss: 0.6934 - val_accuracy: 0.5028\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.5068 - val_loss: 0.6959 - val_accuracy: 0.4904\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6942 - accuracy: 0.4976 - val_loss: 0.6972 - val_accuracy: 0.4912\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6943 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6943 - val_accuracy: 0.4960\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5160\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6978 - val_accuracy: 0.4912\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6944 - accuracy: 0.4856 - val_loss: 0.6931 - val_accuracy: 0.5116\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.5132 - val_loss: 0.6960 - val_accuracy: 0.5088\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6956 - val_accuracy: 0.4900\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6942 - accuracy: 0.4940 - val_loss: 0.6939 - val_accuracy: 0.4940\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6982 - val_accuracy: 0.4916\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6947 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.4880\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6944 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.5016\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6943 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5112\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6940 - accuracy: 0.4916 - val_loss: 0.6944 - val_accuracy: 0.4908\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.4944 - val_loss: 0.6941 - val_accuracy: 0.5012\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.4932 - val_loss: 0.6944 - val_accuracy: 0.4964\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6940 - accuracy: 0.4948 - val_loss: 0.6956 - val_accuracy: 0.4908\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6944 - accuracy: 0.4848 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6937 - val_accuracy: 0.5008\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6942 - accuracy: 0.5052 - val_loss: 0.6949 - val_accuracy: 0.4912\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5124\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.5008 - val_loss: 0.6940 - val_accuracy: 0.4984\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5040 - val_loss: 0.6988 - val_accuracy: 0.4912\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6944 - accuracy: 0.5012 - val_loss: 0.6946 - val_accuracy: 0.4916\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.5152 - val_loss: 0.6957 - val_accuracy: 0.5088\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6964 - val_accuracy: 0.4912\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5124 - val_loss: 0.6938 - val_accuracy: 0.5120\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6943 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.4992\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.4984 - val_loss: 0.6933 - val_accuracy: 0.4980\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6934 - accuracy: 0.5108 - val_loss: 0.6973 - val_accuracy: 0.4916\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6941 - accuracy: 0.5032 - val_loss: 0.6933 - val_accuracy: 0.5116\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6942 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5004\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6942 - accuracy: 0.5028 - val_loss: 0.6948 - val_accuracy: 0.5088\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.6956 - val_accuracy: 0.4904\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5100\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6941 - accuracy: 0.4940 - val_loss: 0.6930 - val_accuracy: 0.5044\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6935 - val_accuracy: 0.5128\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6942 - accuracy: 0.4984 - val_loss: 0.6930 - val_accuracy: 0.5120\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6933 - val_accuracy: 0.5072\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6938 - accuracy: 0.5004 - val_loss: 0.6940 - val_accuracy: 0.5032\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6930 - val_accuracy: 0.5032\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6939 - accuracy: 0.4984 - val_loss: 0.6931 - val_accuracy: 0.4976\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6940 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.4988\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6940 - accuracy: 0.4940 - val_loss: 0.6948 - val_accuracy: 0.4932\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6936 - accuracy: 0.4952 - val_loss: 0.6937 - val_accuracy: 0.5140\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6940 - accuracy: 0.4920 - val_loss: 0.6955 - val_accuracy: 0.4924\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6943 - accuracy: 0.5148 - val_loss: 0.6937 - val_accuracy: 0.4988\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.5100\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.5080 - val_loss: 0.6943 - val_accuracy: 0.4988\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.4988 - val_loss: 0.6937 - val_accuracy: 0.5048\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.5012 - val_loss: 0.6937 - val_accuracy: 0.5012\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6940 - accuracy: 0.5068 - val_loss: 0.6969 - val_accuracy: 0.4924\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6941 - accuracy: 0.5092 - val_loss: 0.6937 - val_accuracy: 0.5088\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6939 - accuracy: 0.5032 - val_loss: 0.6951 - val_accuracy: 0.4964\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6939 - accuracy: 0.5096 - val_loss: 0.6942 - val_accuracy: 0.5008\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5148 - val_loss: 0.6953 - val_accuracy: 0.4900\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6941 - accuracy: 0.5064 - val_loss: 0.6936 - val_accuracy: 0.5040\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6942 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.5144\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6939 - accuracy: 0.4928 - val_loss: 0.6942 - val_accuracy: 0.5112\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6939 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.4976\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6937 - accuracy: 0.5068 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.5004 - val_loss: 0.6948 - val_accuracy: 0.4920\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6950 - val_accuracy: 0.4916\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.5072 - val_loss: 0.6953 - val_accuracy: 0.5092\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6943 - accuracy: 0.4936 - val_loss: 0.6941 - val_accuracy: 0.4952\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6937 - accuracy: 0.5020 - val_loss: 0.6967 - val_accuracy: 0.4928\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6939 - accuracy: 0.4924 - val_loss: 0.6951 - val_accuracy: 0.4900\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6938 - accuracy: 0.4960 - val_loss: 0.6932 - val_accuracy: 0.4968\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5076 - val_loss: 0.6932 - val_accuracy: 0.4988\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6941 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5148\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.5056 - val_loss: 0.6955 - val_accuracy: 0.4908\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.5116\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6939 - accuracy: 0.5028 - val_loss: 0.6963 - val_accuracy: 0.4920\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6945 - val_accuracy: 0.4932\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6935 - val_accuracy: 0.5036\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.4936 - val_loss: 0.6945 - val_accuracy: 0.5036\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6938 - accuracy: 0.5168 - val_loss: 0.6949 - val_accuracy: 0.4932\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6941 - accuracy: 0.4976 - val_loss: 0.6933 - val_accuracy: 0.5116\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.6930 - val_accuracy: 0.5056\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6939 - accuracy: 0.4908 - val_loss: 0.6973 - val_accuracy: 0.5088\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5164 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6941 - accuracy: 0.4928 - val_loss: 0.6949 - val_accuracy: 0.4888\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6953 - val_accuracy: 0.4920\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6999 - val_accuracy: 0.4912\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6945 - accuracy: 0.5012 - val_loss: 0.6945 - val_accuracy: 0.4964\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6936 - accuracy: 0.5048 - val_loss: 0.6943 - val_accuracy: 0.5104\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6942 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4984\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.7010 - val_accuracy: 0.5088\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6949 - accuracy: 0.4920 - val_loss: 0.6935 - val_accuracy: 0.5036\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6939 - accuracy: 0.5040 - val_loss: 0.6951 - val_accuracy: 0.4892\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6931 - val_accuracy: 0.5068\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5116\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6930 - accuracy: 0.5140 - val_loss: 0.6933 - val_accuracy: 0.4960\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.4992 - val_loss: 0.6962 - val_accuracy: 0.4916\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6939 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5048\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6930 - accuracy: 0.5200 - val_loss: 0.6978 - val_accuracy: 0.5100\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6943 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.4928\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6931 - accuracy: 0.5204 - val_loss: 0.6967 - val_accuracy: 0.4904\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6939 - accuracy: 0.4940 - val_loss: 0.6953 - val_accuracy: 0.4908\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5156 - val_loss: 0.6933 - val_accuracy: 0.5108\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6939 - val_accuracy: 0.5024\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5072 - val_loss: 0.6934 - val_accuracy: 0.4960\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6938 - accuracy: 0.5120 - val_loss: 0.6932 - val_accuracy: 0.4944\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6940 - val_accuracy: 0.5016\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6979 - val_accuracy: 0.4912\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6939 - accuracy: 0.5032 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6940 - accuracy: 0.4980 - val_loss: 0.6935 - val_accuracy: 0.4976\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6966 - val_accuracy: 0.4904\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5088 - val_loss: 0.6932 - val_accuracy: 0.5064\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6937 - accuracy: 0.5060 - val_loss: 0.6933 - val_accuracy: 0.4996\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6936 - accuracy: 0.5060 - val_loss: 0.6938 - val_accuracy: 0.5016\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5044 - val_loss: 0.6936 - val_accuracy: 0.5136\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6939 - accuracy: 0.5036 - val_loss: 0.6930 - val_accuracy: 0.5144\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5096 - val_loss: 0.6979 - val_accuracy: 0.5088\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6944 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.5036\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6937 - accuracy: 0.4956 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6930 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.4984\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6945 - val_accuracy: 0.4972\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6929 - val_accuracy: 0.5028\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6940 - val_accuracy: 0.5104\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5116 - val_loss: 0.6963 - val_accuracy: 0.4912\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.4992 - val_loss: 0.6934 - val_accuracy: 0.5116\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6933 - val_accuracy: 0.4920\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6930 - val_accuracy: 0.5048\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6946 - val_accuracy: 0.5096\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6932 - accuracy: 0.5176 - val_loss: 0.6950 - val_accuracy: 0.5092\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6939 - accuracy: 0.5044 - val_loss: 0.6934 - val_accuracy: 0.5116\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5116\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5040 - val_loss: 0.6937 - val_accuracy: 0.5148\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6941 - accuracy: 0.4956 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.4992 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.4996 - val_loss: 0.6939 - val_accuracy: 0.4972\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6933 - accuracy: 0.5168 - val_loss: 0.6933 - val_accuracy: 0.5108\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6936 - accuracy: 0.5044 - val_loss: 0.6930 - val_accuracy: 0.5112\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6938 - accuracy: 0.4964 - val_loss: 0.6948 - val_accuracy: 0.4956\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6939 - accuracy: 0.4980 - val_loss: 0.6938 - val_accuracy: 0.5084\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6933 - accuracy: 0.5132 - val_loss: 0.6952 - val_accuracy: 0.4904\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.4968\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6942 - val_accuracy: 0.5032\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6936 - val_accuracy: 0.4952\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6934 - accuracy: 0.5164 - val_loss: 0.6966 - val_accuracy: 0.4912\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6940 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.5076 - val_loss: 0.6938 - val_accuracy: 0.5080\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5136\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6943 - val_accuracy: 0.5108\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.4924\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6934 - val_accuracy: 0.4940\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6944 - val_accuracy: 0.4924\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6933 - accuracy: 0.4988 - val_loss: 0.7003 - val_accuracy: 0.4912\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6943 - accuracy: 0.5108 - val_loss: 0.6941 - val_accuracy: 0.5012\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6952 - val_accuracy: 0.4944\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6961 - val_accuracy: 0.4924\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5028 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5120 - val_loss: 0.6947 - val_accuracy: 0.5112\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.4976 - val_loss: 0.6946 - val_accuracy: 0.4948\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6941 - val_accuracy: 0.5120\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6932 - val_accuracy: 0.5072\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.4992\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6931 - accuracy: 0.5216 - val_loss: 0.6957 - val_accuracy: 0.4928\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.5008\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6939 - accuracy: 0.5032 - val_loss: 0.6970 - val_accuracy: 0.4920\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.4920\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6931 - accuracy: 0.5156 - val_loss: 0.6947 - val_accuracy: 0.4944\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.4968 - val_loss: 0.6935 - val_accuracy: 0.4956\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6949 - val_accuracy: 0.4952\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.4940\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5012 - val_loss: 0.6936 - val_accuracy: 0.5016\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5128 - val_loss: 0.6959 - val_accuracy: 0.4908\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6931 - accuracy: 0.5108 - val_loss: 0.6968 - val_accuracy: 0.5148\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6941 - accuracy: 0.5084 - val_loss: 0.6933 - val_accuracy: 0.4936\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6936 - accuracy: 0.4980 - val_loss: 0.6934 - val_accuracy: 0.5156\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6934 - val_accuracy: 0.5008\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6940 - accuracy: 0.5076 - val_loss: 0.6933 - val_accuracy: 0.5100\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6939 - accuracy: 0.5004 - val_loss: 0.6935 - val_accuracy: 0.5144\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6938 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.5060\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5012 - val_loss: 0.6933 - val_accuracy: 0.5088\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6938 - accuracy: 0.5036 - val_loss: 0.6955 - val_accuracy: 0.5128\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6937 - accuracy: 0.5064 - val_loss: 0.6977 - val_accuracy: 0.4912\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.4928\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5120 - val_loss: 0.6945 - val_accuracy: 0.4984\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5156 - val_loss: 0.6933 - val_accuracy: 0.5116\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.4960\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6932 - val_accuracy: 0.4892\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.5020 - val_loss: 0.6933 - val_accuracy: 0.5144\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6938 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.4924\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5068 - val_loss: 0.6937 - val_accuracy: 0.4968\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6933 - accuracy: 0.5076 - val_loss: 0.6934 - val_accuracy: 0.4944\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5024 - val_loss: 0.6935 - val_accuracy: 0.4932\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6937 - accuracy: 0.5108 - val_loss: 0.6943 - val_accuracy: 0.5116\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.4992\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6926 - accuracy: 0.5208 - val_loss: 0.6996 - val_accuracy: 0.5088\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6947 - accuracy: 0.5044 - val_loss: 0.6943 - val_accuracy: 0.4960\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.4932\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.5152\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5144 - val_loss: 0.6959 - val_accuracy: 0.4916\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6935 - val_accuracy: 0.4956\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6930 - accuracy: 0.5140 - val_loss: 0.6974 - val_accuracy: 0.5088\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6929 - accuracy: 0.5104 - val_loss: 0.6956 - val_accuracy: 0.4928\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.5032 - val_loss: 0.6959 - val_accuracy: 0.4912\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6938 - accuracy: 0.4968 - val_loss: 0.6934 - val_accuracy: 0.4924\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5016 - val_loss: 0.6940 - val_accuracy: 0.5032\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6934 - accuracy: 0.4928 - val_loss: 0.6933 - val_accuracy: 0.4912\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6934 - val_accuracy: 0.5152\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5044\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5176 - val_loss: 0.6932 - val_accuracy: 0.5040\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.7012 - val_accuracy: 0.4912\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6943 - accuracy: 0.5088 - val_loss: 0.6953 - val_accuracy: 0.4908\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6948 - val_accuracy: 0.4956\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6941 - val_accuracy: 0.5032\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6937 - val_accuracy: 0.4976\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6938 - accuracy: 0.4992 - val_loss: 0.6935 - val_accuracy: 0.4940\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5032 - val_loss: 0.6942 - val_accuracy: 0.5152\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6942 - val_accuracy: 0.5144\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5020 - val_loss: 0.6937 - val_accuracy: 0.4980\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5036 - val_loss: 0.6934 - val_accuracy: 0.5076\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6930 - accuracy: 0.5120 - val_loss: 0.6934 - val_accuracy: 0.4920\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5136 - val_loss: 0.6958 - val_accuracy: 0.5104\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6939 - accuracy: 0.4948 - val_loss: 0.6934 - val_accuracy: 0.4912\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6934 - accuracy: 0.5016 - val_loss: 0.6963 - val_accuracy: 0.4912\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6932 - val_accuracy: 0.5092\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5116 - val_loss: 0.6933 - val_accuracy: 0.5032\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6938 - accuracy: 0.5084 - val_loss: 0.6934 - val_accuracy: 0.4940\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5156 - val_loss: 0.6942 - val_accuracy: 0.4984\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6935 - val_accuracy: 0.4952\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6933 - accuracy: 0.5096 - val_loss: 0.6947 - val_accuracy: 0.5140\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.5068 - val_loss: 0.6935 - val_accuracy: 0.4980\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5108 - val_loss: 0.6967 - val_accuracy: 0.4912\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6941 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.4956\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5068 - val_loss: 0.6944 - val_accuracy: 0.4980\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6934 - accuracy: 0.5044 - val_loss: 0.7003 - val_accuracy: 0.4912\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6942 - accuracy: 0.5004 - val_loss: 0.6934 - val_accuracy: 0.5116\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.4948\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6958 - val_accuracy: 0.4932\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6936 - val_accuracy: 0.5084\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6936 - accuracy: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.5128\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5064 - val_loss: 0.6940 - val_accuracy: 0.4968\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6943 - val_accuracy: 0.4960\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6935 - accuracy: 0.4984 - val_loss: 0.6945 - val_accuracy: 0.5144\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.5096\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6930 - accuracy: 0.5024 - val_loss: 0.6934 - val_accuracy: 0.4936\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6996 - val_accuracy: 0.4912\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6941 - accuracy: 0.5012 - val_loss: 0.6950 - val_accuracy: 0.5096\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6935 - accuracy: 0.5200 - val_loss: 0.6982 - val_accuracy: 0.4912\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.5008 - val_loss: 0.6950 - val_accuracy: 0.4932\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.5044\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6932 - accuracy: 0.5180 - val_loss: 0.6934 - val_accuracy: 0.4928\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6934 - val_accuracy: 0.4936\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5132 - val_loss: 0.6931 - val_accuracy: 0.5064\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6931 - accuracy: 0.5148 - val_loss: 0.6932 - val_accuracy: 0.5108\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6945 - val_accuracy: 0.5136\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 96us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6932 - val_accuracy: 0.5004\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6935 - val_accuracy: 0.5068\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6937 - accuracy: 0.5120 - val_loss: 0.6967 - val_accuracy: 0.5096\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6941 - accuracy: 0.5084 - val_loss: 0.6937 - val_accuracy: 0.4952\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6933 - accuracy: 0.5064 - val_loss: 0.6953 - val_accuracy: 0.4936\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6924 - accuracy: 0.5256 - val_loss: 0.6942 - val_accuracy: 0.5136\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5084 - val_loss: 0.6945 - val_accuracy: 0.4980\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5068 - val_loss: 0.6963 - val_accuracy: 0.4912\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6933 - accuracy: 0.5132 - val_loss: 0.6936 - val_accuracy: 0.4856\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6944 - val_accuracy: 0.4968\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6940 - val_accuracy: 0.4960\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5228 - val_loss: 0.6936 - val_accuracy: 0.5164\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.4916\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6933 - val_accuracy: 0.5084\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6936 - accuracy: 0.5120 - val_loss: 0.6944 - val_accuracy: 0.5112\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5008 - val_loss: 0.6934 - val_accuracy: 0.5084\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6937 - val_accuracy: 0.5076\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5120 - val_loss: 0.6935 - val_accuracy: 0.5048\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.5088 - val_loss: 0.6948 - val_accuracy: 0.5136\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6940 - accuracy: 0.5132 - val_loss: 0.6946 - val_accuracy: 0.5012\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6935 - accuracy: 0.5116 - val_loss: 0.6938 - val_accuracy: 0.4904\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6937 - accuracy: 0.4988 - val_loss: 0.6935 - val_accuracy: 0.4948\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6937 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.5124\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6936 - val_accuracy: 0.4972\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6929 - accuracy: 0.5068 - val_loss: 0.6936 - val_accuracy: 0.4952\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6938 - accuracy: 0.5032 - val_loss: 0.6947 - val_accuracy: 0.4960\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6930 - accuracy: 0.5076 - val_loss: 0.6953 - val_accuracy: 0.5124\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6934 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.5132\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5152 - val_loss: 0.6944 - val_accuracy: 0.5112\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6952 - val_accuracy: 0.5128\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6928 - accuracy: 0.5236 - val_loss: 0.6934 - val_accuracy: 0.5112\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6934 - accuracy: 0.5128 - val_loss: 0.6946 - val_accuracy: 0.4968\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6933 - accuracy: 0.5128 - val_loss: 0.6940 - val_accuracy: 0.5004\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6935 - accuracy: 0.5072 - val_loss: 0.6943 - val_accuracy: 0.4924\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6934 - accuracy: 0.5080 - val_loss: 0.6944 - val_accuracy: 0.5140\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6936 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5092\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6953 - val_accuracy: 0.4928\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6933 - accuracy: 0.4980 - val_loss: 0.6937 - val_accuracy: 0.5132\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6937 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.4996\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5132 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6946 - val_accuracy: 0.5020\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6941 - val_accuracy: 0.5100\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6938 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5128\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6943 - val_accuracy: 0.4968\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6937 - val_accuracy: 0.5128\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6932 - accuracy: 0.5112 - val_loss: 0.6932 - val_accuracy: 0.5132\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6937 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.4884\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6936 - val_accuracy: 0.4924\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6935 - accuracy: 0.5136 - val_loss: 0.6936 - val_accuracy: 0.5140\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6938 - accuracy: 0.5024 - val_loss: 0.6940 - val_accuracy: 0.4936\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6930 - accuracy: 0.5268 - val_loss: 0.6950 - val_accuracy: 0.5132\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6939 - accuracy: 0.5060 - val_loss: 0.6937 - val_accuracy: 0.4944\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6942 - val_accuracy: 0.4972\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6936 - accuracy: 0.4936 - val_loss: 0.6935 - val_accuracy: 0.4956\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5140 - val_loss: 0.6935 - val_accuracy: 0.5128\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6935 - accuracy: 0.5068 - val_loss: 0.6932 - val_accuracy: 0.5148\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6933 - accuracy: 0.4956 - val_loss: 0.6963 - val_accuracy: 0.4916\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6936 - accuracy: 0.5076 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6935 - accuracy: 0.5044 - val_loss: 0.6956 - val_accuracy: 0.4932\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6931 - accuracy: 0.5044 - val_loss: 0.6939 - val_accuracy: 0.5104\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6935 - accuracy: 0.5116 - val_loss: 0.6934 - val_accuracy: 0.5080\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6935 - val_accuracy: 0.4972\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5180 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6937 - val_accuracy: 0.4888\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.512</td></tr><tr><td>loss</td><td>0.69315</td></tr><tr><td>val_accuracy</td><td>0.4888</td></tr><tr><td>val_loss</td><td>0.69367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-sweep-10</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/mpu3764q\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/mpu3764q</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_222317-mpu3764q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nbysk9ti with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\kavan\\Documents\\GitHub\\tensorflow-ml\\source\\wandb\\run-20230312_222548-nbysk9ti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kavp/tensorflow-test/runs/nbysk9ti\" target=\"_blank\">woven-sweep-11</a></strong> to <a href=\"https://wandb.ai/kavp/tensorflow-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/sweeps/tsmolat6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "Epoch 1/400\n",
      "2500/2500 [==============================] - 0s 169us/sample - loss: 3.0716 - accuracy: 0.5016 - val_loss: 1.7708 - val_accuracy: 0.5088\n",
      "Epoch 2/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 1.4235 - accuracy: 0.5016 - val_loss: 1.1840 - val_accuracy: 0.5088\n",
      "Epoch 3/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 1.1304 - accuracy: 0.5016 - val_loss: 1.0652 - val_accuracy: 0.5088\n",
      "Epoch 4/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 1.0378 - accuracy: 0.5016 - val_loss: 0.9910 - val_accuracy: 0.5088\n",
      "Epoch 5/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.9715 - accuracy: 0.5016 - val_loss: 0.9324 - val_accuracy: 0.5088\n",
      "Epoch 6/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.9174 - accuracy: 0.5016 - val_loss: 0.8840 - val_accuracy: 0.5088\n",
      "Epoch 7/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.8721 - accuracy: 0.5016 - val_loss: 0.8415 - val_accuracy: 0.5088\n",
      "Epoch 8/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.8312 - accuracy: 0.5016 - val_loss: 0.8039 - val_accuracy: 0.5088\n",
      "Epoch 9/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.7951 - accuracy: 0.5016 - val_loss: 0.7712 - val_accuracy: 0.5088\n",
      "Epoch 10/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.7638 - accuracy: 0.5012 - val_loss: 0.7438 - val_accuracy: 0.5088\n",
      "Epoch 11/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.7387 - accuracy: 0.5032 - val_loss: 0.7225 - val_accuracy: 0.5100\n",
      "Epoch 12/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.7202 - accuracy: 0.5008 - val_loss: 0.7092 - val_accuracy: 0.5100\n",
      "Epoch 13/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.7101 - accuracy: 0.4924 - val_loss: 0.7031 - val_accuracy: 0.5044\n",
      "Epoch 14/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.7056 - accuracy: 0.5000 - val_loss: 0.7008 - val_accuracy: 0.5168\n",
      "Epoch 15/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.7038 - accuracy: 0.4940 - val_loss: 0.7000 - val_accuracy: 0.5172\n",
      "Epoch 16/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.7030 - accuracy: 0.4920 - val_loss: 0.6995 - val_accuracy: 0.5196\n",
      "Epoch 17/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.7024 - accuracy: 0.4964 - val_loss: 0.6990 - val_accuracy: 0.5136\n",
      "Epoch 18/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.7017 - accuracy: 0.4936 - val_loss: 0.6985 - val_accuracy: 0.5136\n",
      "Epoch 19/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.7011 - accuracy: 0.4980 - val_loss: 0.6982 - val_accuracy: 0.5080\n",
      "Epoch 20/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.7006 - accuracy: 0.4924 - val_loss: 0.6977 - val_accuracy: 0.5076\n",
      "Epoch 21/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.7001 - accuracy: 0.4928 - val_loss: 0.6974 - val_accuracy: 0.5044\n",
      "Epoch 22/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6995 - accuracy: 0.4916 - val_loss: 0.6971 - val_accuracy: 0.4996\n",
      "Epoch 23/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6992 - accuracy: 0.4928 - val_loss: 0.6967 - val_accuracy: 0.4992\n",
      "Epoch 24/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6988 - accuracy: 0.4928 - val_loss: 0.6965 - val_accuracy: 0.5028\n",
      "Epoch 25/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6984 - accuracy: 0.4916 - val_loss: 0.6962 - val_accuracy: 0.5032\n",
      "Epoch 26/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6980 - accuracy: 0.4924 - val_loss: 0.6960 - val_accuracy: 0.5044\n",
      "Epoch 27/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6978 - accuracy: 0.4936 - val_loss: 0.6962 - val_accuracy: 0.4988\n",
      "Epoch 28/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6976 - accuracy: 0.4956 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 29/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6973 - accuracy: 0.4952 - val_loss: 0.6954 - val_accuracy: 0.5068\n",
      "Epoch 30/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6969 - accuracy: 0.4968 - val_loss: 0.6954 - val_accuracy: 0.4944\n",
      "Epoch 31/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6968 - accuracy: 0.5004 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 32/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6965 - accuracy: 0.4972 - val_loss: 0.6949 - val_accuracy: 0.5024\n",
      "Epoch 33/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6962 - accuracy: 0.4944 - val_loss: 0.6947 - val_accuracy: 0.5100\n",
      "Epoch 34/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6961 - accuracy: 0.4996 - val_loss: 0.6946 - val_accuracy: 0.5008\n",
      "Epoch 35/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6959 - accuracy: 0.5012 - val_loss: 0.6944 - val_accuracy: 0.5124\n",
      "Epoch 36/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6957 - accuracy: 0.5112 - val_loss: 0.6945 - val_accuracy: 0.4916\n",
      "Epoch 37/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6955 - accuracy: 0.4976 - val_loss: 0.6942 - val_accuracy: 0.5052\n",
      "Epoch 38/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6954 - accuracy: 0.5072 - val_loss: 0.6945 - val_accuracy: 0.4940\n",
      "Epoch 39/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6955 - accuracy: 0.5064 - val_loss: 0.6942 - val_accuracy: 0.5008\n",
      "Epoch 40/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6950 - accuracy: 0.5044 - val_loss: 0.6939 - val_accuracy: 0.5092\n",
      "Epoch 41/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6951 - accuracy: 0.5084 - val_loss: 0.6941 - val_accuracy: 0.5036\n",
      "Epoch 42/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6954 - accuracy: 0.4916 - val_loss: 0.6937 - val_accuracy: 0.5060\n",
      "Epoch 43/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6951 - accuracy: 0.5052 - val_loss: 0.6936 - val_accuracy: 0.5048\n",
      "Epoch 44/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6948 - accuracy: 0.5088 - val_loss: 0.6937 - val_accuracy: 0.5060\n",
      "Epoch 45/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6948 - accuracy: 0.4992 - val_loss: 0.6937 - val_accuracy: 0.5028\n",
      "Epoch 46/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6947 - accuracy: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.5068\n",
      "Epoch 47/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6948 - accuracy: 0.5012 - val_loss: 0.6938 - val_accuracy: 0.5144\n",
      "Epoch 48/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6950 - accuracy: 0.4952 - val_loss: 0.6935 - val_accuracy: 0.5008\n",
      "Epoch 49/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6944 - accuracy: 0.5008 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 50/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6942 - accuracy: 0.5088 - val_loss: 0.6936 - val_accuracy: 0.5108\n",
      "Epoch 51/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6944 - accuracy: 0.5028 - val_loss: 0.6938 - val_accuracy: 0.5076\n",
      "Epoch 52/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6944 - accuracy: 0.5060 - val_loss: 0.6934 - val_accuracy: 0.4976\n",
      "Epoch 53/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6944 - accuracy: 0.5048 - val_loss: 0.6934 - val_accuracy: 0.4988\n",
      "Epoch 54/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6941 - accuracy: 0.5020 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 55/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6942 - accuracy: 0.4908 - val_loss: 0.6933 - val_accuracy: 0.5044\n",
      "Epoch 56/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6942 - accuracy: 0.4964 - val_loss: 0.6935 - val_accuracy: 0.5136\n",
      "Epoch 57/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6941 - accuracy: 0.5044 - val_loss: 0.6933 - val_accuracy: 0.5044\n",
      "Epoch 58/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6943 - accuracy: 0.4964 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 59/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6942 - accuracy: 0.5128 - val_loss: 0.6938 - val_accuracy: 0.5056\n",
      "Epoch 60/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6941 - accuracy: 0.5076 - val_loss: 0.6933 - val_accuracy: 0.5120\n",
      "Epoch 61/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6943 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.5004\n",
      "Epoch 62/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.5060 - val_loss: 0.6937 - val_accuracy: 0.5056\n",
      "Epoch 63/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6940 - accuracy: 0.5068 - val_loss: 0.6937 - val_accuracy: 0.5052\n",
      "Epoch 64/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6941 - accuracy: 0.5040 - val_loss: 0.6933 - val_accuracy: 0.5116\n",
      "Epoch 65/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6949 - val_accuracy: 0.4940\n",
      "Epoch 66/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6940 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.4984\n",
      "Epoch 67/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6941 - accuracy: 0.5068 - val_loss: 0.6931 - val_accuracy: 0.5072\n",
      "Epoch 68/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6941 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5092\n",
      "Epoch 69/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6939 - accuracy: 0.5040 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 70/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6937 - accuracy: 0.4928 - val_loss: 0.6939 - val_accuracy: 0.4968\n",
      "Epoch 71/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6939 - accuracy: 0.5092 - val_loss: 0.6932 - val_accuracy: 0.5076\n",
      "Epoch 72/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6940 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.5112\n",
      "Epoch 73/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6935 - accuracy: 0.5076 - val_loss: 0.6946 - val_accuracy: 0.4940\n",
      "Epoch 74/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6940 - accuracy: 0.4936 - val_loss: 0.6933 - val_accuracy: 0.5020\n",
      "Epoch 75/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6936 - accuracy: 0.5068 - val_loss: 0.6943 - val_accuracy: 0.4884\n",
      "Epoch 76/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6940 - accuracy: 0.5048 - val_loss: 0.6939 - val_accuracy: 0.5004\n",
      "Epoch 77/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6939 - accuracy: 0.5020 - val_loss: 0.6936 - val_accuracy: 0.5040\n",
      "Epoch 78/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6937 - accuracy: 0.5160 - val_loss: 0.6935 - val_accuracy: 0.5096\n",
      "Epoch 79/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6938 - accuracy: 0.4996 - val_loss: 0.6934 - val_accuracy: 0.5072\n",
      "Epoch 80/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6937 - accuracy: 0.5088 - val_loss: 0.6933 - val_accuracy: 0.5088\n",
      "Epoch 81/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6938 - accuracy: 0.5020 - val_loss: 0.6933 - val_accuracy: 0.5132\n",
      "Epoch 82/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6937 - accuracy: 0.5028 - val_loss: 0.6941 - val_accuracy: 0.5080\n",
      "Epoch 83/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6940 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.5076\n",
      "Epoch 84/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6936 - accuracy: 0.5016 - val_loss: 0.6935 - val_accuracy: 0.5036\n",
      "Epoch 85/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6939 - accuracy: 0.5028 - val_loss: 0.6943 - val_accuracy: 0.4928\n",
      "Epoch 86/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6929 - accuracy: 0.5164 - val_loss: 0.6939 - val_accuracy: 0.5100\n",
      "Epoch 87/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6936 - accuracy: 0.5024 - val_loss: 0.6936 - val_accuracy: 0.5080\n",
      "Epoch 88/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6937 - val_accuracy: 0.5068\n",
      "Epoch 89/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6938 - accuracy: 0.4976 - val_loss: 0.6943 - val_accuracy: 0.4884\n",
      "Epoch 90/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6935 - accuracy: 0.5076 - val_loss: 0.6939 - val_accuracy: 0.4992\n",
      "Epoch 91/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6935 - accuracy: 0.5032 - val_loss: 0.6953 - val_accuracy: 0.4980\n",
      "Epoch 92/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5072 - val_loss: 0.6939 - val_accuracy: 0.4980\n",
      "Epoch 93/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6950 - val_accuracy: 0.4916\n",
      "Epoch 94/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6936 - accuracy: 0.5148 - val_loss: 0.6950 - val_accuracy: 0.4960\n",
      "Epoch 95/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6930 - accuracy: 0.5180 - val_loss: 0.6937 - val_accuracy: 0.5092\n",
      "Epoch 96/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6936 - accuracy: 0.5008 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 97/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6937 - accuracy: 0.5048 - val_loss: 0.6938 - val_accuracy: 0.4916\n",
      "Epoch 98/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6936 - accuracy: 0.5128 - val_loss: 0.6935 - val_accuracy: 0.5076\n",
      "Epoch 99/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6940 - val_accuracy: 0.4912\n",
      "Epoch 100/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6940 - val_accuracy: 0.4932\n",
      "Epoch 101/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6938 - accuracy: 0.4888 - val_loss: 0.6945 - val_accuracy: 0.4820\n",
      "Epoch 102/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6935 - accuracy: 0.5104 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 103/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6929 - accuracy: 0.5104 - val_loss: 0.6937 - val_accuracy: 0.5140\n",
      "Epoch 104/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6935 - val_accuracy: 0.5068\n",
      "Epoch 105/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6939 - val_accuracy: 0.5100\n",
      "Epoch 106/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6944 - val_accuracy: 0.5092\n",
      "Epoch 107/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6942 - accuracy: 0.5072 - val_loss: 0.6937 - val_accuracy: 0.5064\n",
      "Epoch 108/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6935 - val_accuracy: 0.5056\n",
      "Epoch 109/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6934 - accuracy: 0.5124 - val_loss: 0.6940 - val_accuracy: 0.4852\n",
      "Epoch 110/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6927 - accuracy: 0.5192 - val_loss: 0.6960 - val_accuracy: 0.4904\n",
      "Epoch 111/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6929 - accuracy: 0.5184 - val_loss: 0.6945 - val_accuracy: 0.5100\n",
      "Epoch 112/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6934 - accuracy: 0.5064 - val_loss: 0.6938 - val_accuracy: 0.5012\n",
      "Epoch 113/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6939 - val_accuracy: 0.4980\n",
      "Epoch 114/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6928 - accuracy: 0.5220 - val_loss: 0.6940 - val_accuracy: 0.5048\n",
      "Epoch 115/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6937 - val_accuracy: 0.5056\n",
      "Epoch 116/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6927 - accuracy: 0.5080 - val_loss: 0.6945 - val_accuracy: 0.5108\n",
      "Epoch 117/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6935 - accuracy: 0.5092 - val_loss: 0.6940 - val_accuracy: 0.4960\n",
      "Epoch 118/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6930 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.5076\n",
      "Epoch 119/400\n",
      "2500/2500 [==============================] - 0s 98us/sample - loss: 0.6934 - accuracy: 0.5136 - val_loss: 0.6952 - val_accuracy: 0.4928\n",
      "Epoch 120/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6934 - accuracy: 0.5104 - val_loss: 0.6942 - val_accuracy: 0.4892\n",
      "Epoch 121/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6925 - accuracy: 0.5180 - val_loss: 0.6940 - val_accuracy: 0.5092\n",
      "Epoch 122/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6931 - accuracy: 0.5112 - val_loss: 0.6937 - val_accuracy: 0.5032\n",
      "Epoch 123/400\n",
      "2500/2500 [==============================] - 0s 98us/sample - loss: 0.6933 - accuracy: 0.4996 - val_loss: 0.6941 - val_accuracy: 0.4972\n",
      "Epoch 124/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6928 - accuracy: 0.5168 - val_loss: 0.6945 - val_accuracy: 0.5028\n",
      "Epoch 125/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6944 - val_accuracy: 0.4868\n",
      "Epoch 126/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6930 - accuracy: 0.5136 - val_loss: 0.6942 - val_accuracy: 0.5076\n",
      "Epoch 127/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6927 - accuracy: 0.5240 - val_loss: 0.6940 - val_accuracy: 0.5012\n",
      "Epoch 128/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6946 - val_accuracy: 0.5088\n",
      "Epoch 129/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6936 - accuracy: 0.5208 - val_loss: 0.6940 - val_accuracy: 0.5016\n",
      "Epoch 130/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6927 - accuracy: 0.5052 - val_loss: 0.6940 - val_accuracy: 0.5016\n",
      "Epoch 131/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6935 - accuracy: 0.5140 - val_loss: 0.6948 - val_accuracy: 0.5092\n",
      "Epoch 132/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6943 - val_accuracy: 0.4856\n",
      "Epoch 133/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6926 - accuracy: 0.5224 - val_loss: 0.6950 - val_accuracy: 0.4872\n",
      "Epoch 134/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6926 - accuracy: 0.5168 - val_loss: 0.6941 - val_accuracy: 0.4956\n",
      "Epoch 135/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6920 - accuracy: 0.5244 - val_loss: 0.6962 - val_accuracy: 0.5064\n",
      "Epoch 136/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6931 - accuracy: 0.5096 - val_loss: 0.6945 - val_accuracy: 0.4884\n",
      "Epoch 137/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6923 - accuracy: 0.5184 - val_loss: 0.6946 - val_accuracy: 0.4860\n",
      "Epoch 138/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6924 - accuracy: 0.5072 - val_loss: 0.6947 - val_accuracy: 0.5060\n",
      "Epoch 139/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6919 - accuracy: 0.5256 - val_loss: 0.6973 - val_accuracy: 0.4924\n",
      "Epoch 140/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6929 - accuracy: 0.5080 - val_loss: 0.6940 - val_accuracy: 0.4940\n",
      "Epoch 141/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6925 - accuracy: 0.5136 - val_loss: 0.6941 - val_accuracy: 0.4984\n",
      "Epoch 142/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6930 - accuracy: 0.5092 - val_loss: 0.6944 - val_accuracy: 0.4968\n",
      "Epoch 143/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6957 - val_accuracy: 0.4940\n",
      "Epoch 144/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6929 - accuracy: 0.5144 - val_loss: 0.6943 - val_accuracy: 0.4940\n",
      "Epoch 145/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5112 - val_loss: 0.6947 - val_accuracy: 0.4884\n",
      "Epoch 146/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6925 - accuracy: 0.5116 - val_loss: 0.6946 - val_accuracy: 0.4952\n",
      "Epoch 147/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6921 - accuracy: 0.5208 - val_loss: 0.6954 - val_accuracy: 0.4896\n",
      "Epoch 148/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6944 - val_accuracy: 0.4948\n",
      "Epoch 149/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6933 - accuracy: 0.5124 - val_loss: 0.6946 - val_accuracy: 0.5056\n",
      "Epoch 150/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6928 - accuracy: 0.5140 - val_loss: 0.6947 - val_accuracy: 0.5036\n",
      "Epoch 151/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6944 - val_accuracy: 0.4964\n",
      "Epoch 152/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6925 - accuracy: 0.5192 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 153/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6928 - accuracy: 0.5136 - val_loss: 0.6950 - val_accuracy: 0.4972\n",
      "Epoch 154/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6924 - accuracy: 0.5132 - val_loss: 0.6949 - val_accuracy: 0.4892\n",
      "Epoch 155/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6928 - accuracy: 0.5132 - val_loss: 0.6958 - val_accuracy: 0.4864\n",
      "Epoch 156/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6958 - val_accuracy: 0.4872\n",
      "Epoch 157/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6924 - accuracy: 0.5172 - val_loss: 0.6949 - val_accuracy: 0.4952\n",
      "Epoch 158/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6955 - val_accuracy: 0.5052\n",
      "Epoch 159/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6924 - accuracy: 0.5164 - val_loss: 0.6950 - val_accuracy: 0.5036\n",
      "Epoch 160/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6925 - accuracy: 0.5212 - val_loss: 0.6949 - val_accuracy: 0.5040\n",
      "Epoch 161/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6922 - accuracy: 0.5092 - val_loss: 0.6959 - val_accuracy: 0.4888\n",
      "Epoch 162/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6922 - accuracy: 0.5292 - val_loss: 0.6967 - val_accuracy: 0.4880\n",
      "Epoch 163/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6924 - accuracy: 0.5296 - val_loss: 0.6951 - val_accuracy: 0.4948\n",
      "Epoch 164/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6915 - accuracy: 0.5212 - val_loss: 0.6967 - val_accuracy: 0.4872\n",
      "Epoch 165/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6919 - accuracy: 0.5248 - val_loss: 0.6956 - val_accuracy: 0.4932\n",
      "Epoch 166/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6923 - accuracy: 0.5272 - val_loss: 0.6954 - val_accuracy: 0.4980\n",
      "Epoch 167/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6926 - accuracy: 0.5176 - val_loss: 0.6949 - val_accuracy: 0.5024\n",
      "Epoch 168/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6923 - accuracy: 0.5072 - val_loss: 0.6949 - val_accuracy: 0.4808\n",
      "Epoch 169/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6954 - val_accuracy: 0.5076\n",
      "Epoch 170/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6918 - accuracy: 0.5140 - val_loss: 0.6954 - val_accuracy: 0.4792\n",
      "Epoch 171/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6916 - accuracy: 0.5280 - val_loss: 0.6964 - val_accuracy: 0.4864\n",
      "Epoch 172/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6921 - accuracy: 0.5284 - val_loss: 0.6976 - val_accuracy: 0.4956\n",
      "Epoch 173/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6955 - val_accuracy: 0.5052\n",
      "Epoch 174/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6928 - accuracy: 0.5200 - val_loss: 0.6954 - val_accuracy: 0.4888\n",
      "Epoch 175/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6966 - val_accuracy: 0.4880\n",
      "Epoch 176/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6912 - accuracy: 0.5172 - val_loss: 0.6955 - val_accuracy: 0.5008\n",
      "Epoch 177/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6951 - val_accuracy: 0.5060\n",
      "Epoch 178/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6918 - accuracy: 0.5076 - val_loss: 0.6955 - val_accuracy: 0.4828\n",
      "Epoch 179/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6952 - val_accuracy: 0.4980\n",
      "Epoch 180/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6921 - accuracy: 0.5128 - val_loss: 0.6955 - val_accuracy: 0.5004\n",
      "Epoch 181/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6916 - accuracy: 0.5248 - val_loss: 0.6961 - val_accuracy: 0.4852\n",
      "Epoch 182/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6920 - accuracy: 0.5268 - val_loss: 0.6961 - val_accuracy: 0.5016\n",
      "Epoch 183/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6920 - accuracy: 0.5244 - val_loss: 0.6956 - val_accuracy: 0.4916\n",
      "Epoch 184/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6919 - accuracy: 0.5200 - val_loss: 0.6963 - val_accuracy: 0.4852\n",
      "Epoch 185/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6956 - val_accuracy: 0.4864\n",
      "Epoch 186/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6912 - accuracy: 0.5384 - val_loss: 0.6962 - val_accuracy: 0.5060\n",
      "Epoch 187/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6960 - val_accuracy: 0.5080\n",
      "Epoch 188/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6920 - accuracy: 0.5196 - val_loss: 0.6953 - val_accuracy: 0.5032\n",
      "Epoch 189/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6920 - accuracy: 0.5160 - val_loss: 0.6955 - val_accuracy: 0.4852\n",
      "Epoch 190/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6962 - val_accuracy: 0.4852\n",
      "Epoch 191/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6913 - accuracy: 0.5232 - val_loss: 0.6959 - val_accuracy: 0.4832\n",
      "Epoch 192/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6912 - accuracy: 0.5236 - val_loss: 0.6970 - val_accuracy: 0.4844\n",
      "Epoch 193/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6913 - accuracy: 0.5340 - val_loss: 0.6957 - val_accuracy: 0.5020\n",
      "Epoch 194/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6918 - accuracy: 0.5124 - val_loss: 0.6955 - val_accuracy: 0.4856\n",
      "Epoch 195/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6914 - accuracy: 0.5144 - val_loss: 0.6959 - val_accuracy: 0.4832\n",
      "Epoch 196/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6912 - accuracy: 0.5360 - val_loss: 0.6958 - val_accuracy: 0.4892\n",
      "Epoch 197/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6910 - accuracy: 0.5292 - val_loss: 0.6955 - val_accuracy: 0.4880\n",
      "Epoch 198/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6911 - accuracy: 0.5252 - val_loss: 0.6967 - val_accuracy: 0.5060\n",
      "Epoch 199/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6960 - val_accuracy: 0.4856\n",
      "Epoch 200/400\n",
      "2500/2500 [==============================] - 0s 97us/sample - loss: 0.6912 - accuracy: 0.5256 - val_loss: 0.6957 - val_accuracy: 0.5032\n",
      "Epoch 201/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6914 - accuracy: 0.5252 - val_loss: 0.6960 - val_accuracy: 0.5032\n",
      "Epoch 202/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6913 - accuracy: 0.5292 - val_loss: 0.6962 - val_accuracy: 0.5032\n",
      "Epoch 203/400\n",
      "2500/2500 [==============================] - 0s 94us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6967 - val_accuracy: 0.4868\n",
      "Epoch 204/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6907 - accuracy: 0.5300 - val_loss: 0.6964 - val_accuracy: 0.4828\n",
      "Epoch 205/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6912 - accuracy: 0.5296 - val_loss: 0.6965 - val_accuracy: 0.4852\n",
      "Epoch 206/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6911 - accuracy: 0.5328 - val_loss: 0.6971 - val_accuracy: 0.4844\n",
      "Epoch 207/400\n",
      "2500/2500 [==============================] - 0s 102us/sample - loss: 0.6910 - accuracy: 0.5272 - val_loss: 0.6961 - val_accuracy: 0.4872\n",
      "Epoch 208/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6912 - accuracy: 0.5276 - val_loss: 0.6967 - val_accuracy: 0.4812\n",
      "Epoch 209/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6912 - accuracy: 0.5344 - val_loss: 0.6962 - val_accuracy: 0.5080\n",
      "Epoch 210/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6912 - accuracy: 0.5320 - val_loss: 0.6963 - val_accuracy: 0.4824\n",
      "Epoch 211/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6909 - accuracy: 0.5260 - val_loss: 0.6958 - val_accuracy: 0.4992\n",
      "Epoch 212/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6909 - accuracy: 0.5324 - val_loss: 0.6968 - val_accuracy: 0.5012\n",
      "Epoch 213/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6916 - accuracy: 0.5288 - val_loss: 0.6958 - val_accuracy: 0.5020\n",
      "Epoch 214/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6909 - accuracy: 0.5320 - val_loss: 0.6970 - val_accuracy: 0.4836\n",
      "Epoch 215/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6911 - accuracy: 0.5336 - val_loss: 0.6976 - val_accuracy: 0.4856\n",
      "Epoch 216/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6915 - accuracy: 0.5272 - val_loss: 0.6971 - val_accuracy: 0.4872\n",
      "Epoch 217/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6908 - accuracy: 0.5320 - val_loss: 0.6964 - val_accuracy: 0.4892\n",
      "Epoch 218/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6906 - accuracy: 0.5320 - val_loss: 0.6958 - val_accuracy: 0.4940\n",
      "Epoch 219/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6908 - accuracy: 0.5264 - val_loss: 0.6967 - val_accuracy: 0.5052\n",
      "Epoch 220/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6916 - accuracy: 0.5252 - val_loss: 0.6962 - val_accuracy: 0.4940\n",
      "Epoch 221/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6908 - accuracy: 0.5248 - val_loss: 0.6974 - val_accuracy: 0.4896\n",
      "Epoch 222/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6909 - accuracy: 0.5356 - val_loss: 0.6966 - val_accuracy: 0.4868\n",
      "Epoch 223/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6962 - val_accuracy: 0.4916\n",
      "Epoch 224/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6922 - accuracy: 0.5360 - val_loss: 0.6961 - val_accuracy: 0.4996\n",
      "Epoch 225/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6914 - accuracy: 0.5348 - val_loss: 0.6961 - val_accuracy: 0.4944\n",
      "Epoch 226/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6970 - val_accuracy: 0.4856\n",
      "Epoch 227/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6908 - accuracy: 0.5244 - val_loss: 0.6976 - val_accuracy: 0.4916\n",
      "Epoch 228/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6905 - accuracy: 0.5252 - val_loss: 0.6980 - val_accuracy: 0.4876\n",
      "Epoch 229/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6911 - accuracy: 0.5332 - val_loss: 0.6969 - val_accuracy: 0.4972\n",
      "Epoch 230/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6909 - accuracy: 0.5344 - val_loss: 0.6966 - val_accuracy: 0.4980\n",
      "Epoch 231/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6910 - accuracy: 0.5280 - val_loss: 0.6967 - val_accuracy: 0.4988\n",
      "Epoch 232/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6915 - accuracy: 0.5228 - val_loss: 0.6970 - val_accuracy: 0.4884\n",
      "Epoch 233/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6910 - accuracy: 0.5212 - val_loss: 0.6961 - val_accuracy: 0.4988\n",
      "Epoch 234/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6908 - accuracy: 0.5352 - val_loss: 0.6963 - val_accuracy: 0.5004\n",
      "Epoch 235/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6913 - accuracy: 0.5260 - val_loss: 0.6988 - val_accuracy: 0.4876\n",
      "Epoch 236/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6965 - val_accuracy: 0.4956\n",
      "Epoch 237/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6904 - accuracy: 0.5284 - val_loss: 0.6974 - val_accuracy: 0.4928\n",
      "Epoch 238/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6911 - accuracy: 0.5316 - val_loss: 0.6967 - val_accuracy: 0.4988\n",
      "Epoch 239/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6907 - accuracy: 0.5264 - val_loss: 0.6968 - val_accuracy: 0.5028\n",
      "Epoch 240/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6910 - accuracy: 0.5156 - val_loss: 0.6963 - val_accuracy: 0.5008\n",
      "Epoch 241/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6906 - accuracy: 0.5312 - val_loss: 0.6965 - val_accuracy: 0.5008\n",
      "Epoch 242/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6899 - accuracy: 0.5416 - val_loss: 0.6985 - val_accuracy: 0.5044\n",
      "Epoch 243/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6922 - accuracy: 0.5208 - val_loss: 0.6976 - val_accuracy: 0.4956\n",
      "Epoch 244/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6911 - accuracy: 0.5336 - val_loss: 0.6966 - val_accuracy: 0.5024\n",
      "Epoch 245/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6900 - accuracy: 0.5400 - val_loss: 0.6968 - val_accuracy: 0.4988\n",
      "Epoch 246/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6907 - accuracy: 0.5368 - val_loss: 0.6967 - val_accuracy: 0.4936\n",
      "Epoch 247/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6906 - accuracy: 0.5368 - val_loss: 0.6968 - val_accuracy: 0.4960\n",
      "Epoch 248/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6902 - accuracy: 0.5304 - val_loss: 0.6967 - val_accuracy: 0.4952\n",
      "Epoch 249/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6905 - accuracy: 0.5288 - val_loss: 0.6967 - val_accuracy: 0.4980\n",
      "Epoch 250/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6898 - accuracy: 0.5380 - val_loss: 0.6991 - val_accuracy: 0.4920\n",
      "Epoch 251/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6911 - accuracy: 0.5204 - val_loss: 0.6974 - val_accuracy: 0.5052\n",
      "Epoch 252/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6904 - accuracy: 0.5292 - val_loss: 0.6974 - val_accuracy: 0.4948\n",
      "Epoch 253/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6900 - accuracy: 0.5408 - val_loss: 0.6970 - val_accuracy: 0.5040\n",
      "Epoch 254/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6894 - accuracy: 0.5468 - val_loss: 0.7001 - val_accuracy: 0.4920\n",
      "Epoch 255/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6904 - accuracy: 0.5332 - val_loss: 0.6972 - val_accuracy: 0.5012\n",
      "Epoch 256/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6972 - val_accuracy: 0.4984\n",
      "Epoch 257/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6902 - accuracy: 0.5344 - val_loss: 0.6982 - val_accuracy: 0.4876\n",
      "Epoch 258/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6906 - accuracy: 0.5340 - val_loss: 0.6970 - val_accuracy: 0.4992\n",
      "Epoch 259/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6900 - accuracy: 0.5372 - val_loss: 0.6970 - val_accuracy: 0.5024\n",
      "Epoch 260/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6897 - accuracy: 0.5492 - val_loss: 0.6978 - val_accuracy: 0.5016\n",
      "Epoch 261/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6895 - accuracy: 0.5332 - val_loss: 0.6987 - val_accuracy: 0.4924\n",
      "Epoch 262/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6903 - accuracy: 0.5280 - val_loss: 0.6976 - val_accuracy: 0.5044\n",
      "Epoch 263/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6975 - val_accuracy: 0.4988\n",
      "Epoch 264/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6897 - accuracy: 0.5368 - val_loss: 0.6978 - val_accuracy: 0.4912\n",
      "Epoch 265/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6903 - accuracy: 0.5380 - val_loss: 0.6971 - val_accuracy: 0.5016\n",
      "Epoch 266/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6901 - accuracy: 0.5336 - val_loss: 0.6969 - val_accuracy: 0.5044\n",
      "Epoch 267/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6902 - accuracy: 0.5368 - val_loss: 0.6967 - val_accuracy: 0.5032\n",
      "Epoch 268/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6897 - accuracy: 0.5308 - val_loss: 0.6970 - val_accuracy: 0.5024\n",
      "Epoch 269/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6895 - accuracy: 0.5432 - val_loss: 0.6971 - val_accuracy: 0.5020\n",
      "Epoch 270/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6905 - accuracy: 0.5324 - val_loss: 0.6977 - val_accuracy: 0.4916\n",
      "Epoch 271/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6904 - accuracy: 0.5304 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
      "Epoch 272/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6902 - accuracy: 0.5356 - val_loss: 0.6971 - val_accuracy: 0.4980\n",
      "Epoch 273/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6897 - accuracy: 0.5348 - val_loss: 0.6972 - val_accuracy: 0.5040\n",
      "Epoch 274/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6899 - accuracy: 0.5376 - val_loss: 0.6974 - val_accuracy: 0.4984\n",
      "Epoch 275/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6899 - accuracy: 0.5380 - val_loss: 0.6974 - val_accuracy: 0.5040\n",
      "Epoch 276/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6899 - accuracy: 0.5288 - val_loss: 0.6973 - val_accuracy: 0.5024\n",
      "Epoch 277/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6896 - accuracy: 0.5416 - val_loss: 0.6977 - val_accuracy: 0.5036\n",
      "Epoch 278/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6895 - accuracy: 0.5372 - val_loss: 0.6983 - val_accuracy: 0.4940\n",
      "Epoch 279/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6898 - accuracy: 0.5424 - val_loss: 0.6972 - val_accuracy: 0.5036\n",
      "Epoch 280/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6900 - accuracy: 0.5296 - val_loss: 0.6971 - val_accuracy: 0.4988\n",
      "Epoch 281/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6898 - accuracy: 0.5524 - val_loss: 0.6976 - val_accuracy: 0.5016\n",
      "Epoch 282/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6898 - accuracy: 0.5376 - val_loss: 0.6973 - val_accuracy: 0.5004\n",
      "Epoch 283/400\n",
      "2500/2500 [==============================] - 0s 93us/sample - loss: 0.6898 - accuracy: 0.5388 - val_loss: 0.6976 - val_accuracy: 0.5028\n",
      "Epoch 284/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6896 - accuracy: 0.5480 - val_loss: 0.6971 - val_accuracy: 0.5032\n",
      "Epoch 285/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6898 - accuracy: 0.5360 - val_loss: 0.6975 - val_accuracy: 0.5028\n",
      "Epoch 286/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6899 - accuracy: 0.5388 - val_loss: 0.6971 - val_accuracy: 0.5044\n",
      "Epoch 287/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6894 - accuracy: 0.5392 - val_loss: 0.6974 - val_accuracy: 0.5008\n",
      "Epoch 288/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6889 - accuracy: 0.5372 - val_loss: 0.7007 - val_accuracy: 0.4908\n",
      "Epoch 289/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6895 - accuracy: 0.5468 - val_loss: 0.6972 - val_accuracy: 0.5068\n",
      "Epoch 290/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6896 - accuracy: 0.5432 - val_loss: 0.6973 - val_accuracy: 0.5020\n",
      "Epoch 291/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6896 - accuracy: 0.5352 - val_loss: 0.6969 - val_accuracy: 0.5044\n",
      "Epoch 292/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6893 - accuracy: 0.5380 - val_loss: 0.6973 - val_accuracy: 0.5072\n",
      "Epoch 293/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6901 - accuracy: 0.5388 - val_loss: 0.6982 - val_accuracy: 0.4992\n",
      "Epoch 294/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6895 - accuracy: 0.5340 - val_loss: 0.6976 - val_accuracy: 0.5048\n",
      "Epoch 295/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6894 - accuracy: 0.5392 - val_loss: 0.6973 - val_accuracy: 0.5004\n",
      "Epoch 296/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6895 - accuracy: 0.5328 - val_loss: 0.6978 - val_accuracy: 0.5028\n",
      "Epoch 297/400\n",
      "2500/2500 [==============================] - 0s 91us/sample - loss: 0.6892 - accuracy: 0.5392 - val_loss: 0.6977 - val_accuracy: 0.5004\n",
      "Epoch 298/400\n",
      "2500/2500 [==============================] - 0s 103us/sample - loss: 0.6892 - accuracy: 0.5464 - val_loss: 0.6977 - val_accuracy: 0.5008\n",
      "Epoch 299/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6891 - accuracy: 0.5468 - val_loss: 0.6973 - val_accuracy: 0.5024\n",
      "Epoch 300/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6896 - accuracy: 0.5472 - val_loss: 0.6972 - val_accuracy: 0.5068\n",
      "Epoch 301/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6893 - accuracy: 0.5444 - val_loss: 0.6972 - val_accuracy: 0.5080\n",
      "Epoch 302/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6895 - accuracy: 0.5452 - val_loss: 0.6974 - val_accuracy: 0.5060\n",
      "Epoch 303/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6894 - accuracy: 0.5424 - val_loss: 0.6978 - val_accuracy: 0.5084\n",
      "Epoch 304/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6891 - accuracy: 0.5368 - val_loss: 0.6971 - val_accuracy: 0.5028\n",
      "Epoch 305/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6896 - accuracy: 0.5372 - val_loss: 0.6973 - val_accuracy: 0.5060\n",
      "Epoch 306/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6884 - accuracy: 0.5420 - val_loss: 0.6993 - val_accuracy: 0.5008\n",
      "Epoch 307/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6894 - accuracy: 0.5416 - val_loss: 0.6978 - val_accuracy: 0.5040\n",
      "Epoch 308/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6891 - accuracy: 0.5408 - val_loss: 0.6982 - val_accuracy: 0.4976\n",
      "Epoch 309/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6885 - accuracy: 0.5488 - val_loss: 0.6974 - val_accuracy: 0.5092\n",
      "Epoch 310/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6895 - accuracy: 0.5380 - val_loss: 0.6971 - val_accuracy: 0.5080\n",
      "Epoch 311/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6892 - accuracy: 0.5396 - val_loss: 0.6975 - val_accuracy: 0.5092\n",
      "Epoch 312/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6892 - accuracy: 0.5460 - val_loss: 0.6977 - val_accuracy: 0.5024\n",
      "Epoch 313/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6888 - accuracy: 0.5424 - val_loss: 0.6977 - val_accuracy: 0.5056\n",
      "Epoch 314/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6895 - accuracy: 0.5472 - val_loss: 0.6972 - val_accuracy: 0.5100\n",
      "Epoch 315/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6888 - accuracy: 0.5412 - val_loss: 0.6976 - val_accuracy: 0.5084\n",
      "Epoch 316/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6888 - accuracy: 0.5328 - val_loss: 0.6988 - val_accuracy: 0.4964\n",
      "Epoch 317/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6892 - accuracy: 0.5496 - val_loss: 0.6979 - val_accuracy: 0.5108\n",
      "Epoch 318/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6887 - accuracy: 0.5404 - val_loss: 0.6976 - val_accuracy: 0.5060\n",
      "Epoch 319/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6891 - accuracy: 0.5488 - val_loss: 0.6970 - val_accuracy: 0.5060\n",
      "Epoch 320/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6883 - accuracy: 0.5360 - val_loss: 0.6979 - val_accuracy: 0.5092\n",
      "Epoch 321/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6885 - accuracy: 0.5480 - val_loss: 0.6973 - val_accuracy: 0.5104\n",
      "Epoch 322/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6881 - accuracy: 0.5460 - val_loss: 0.6981 - val_accuracy: 0.5076\n",
      "Epoch 323/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6889 - accuracy: 0.5424 - val_loss: 0.6973 - val_accuracy: 0.5076\n",
      "Epoch 324/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6884 - accuracy: 0.5484 - val_loss: 0.6974 - val_accuracy: 0.5144\n",
      "Epoch 325/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6890 - accuracy: 0.5464 - val_loss: 0.6976 - val_accuracy: 0.5136\n",
      "Epoch 326/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6889 - accuracy: 0.5480 - val_loss: 0.6982 - val_accuracy: 0.5068\n",
      "Epoch 327/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6880 - accuracy: 0.5488 - val_loss: 0.6975 - val_accuracy: 0.5088\n",
      "Epoch 328/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6884 - accuracy: 0.5508 - val_loss: 0.6977 - val_accuracy: 0.5100\n",
      "Epoch 329/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6881 - accuracy: 0.5448 - val_loss: 0.6976 - val_accuracy: 0.5092\n",
      "Epoch 330/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6883 - accuracy: 0.5548 - val_loss: 0.6977 - val_accuracy: 0.5108\n",
      "Epoch 331/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6884 - accuracy: 0.5488 - val_loss: 0.6974 - val_accuracy: 0.5104\n",
      "Epoch 332/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6882 - accuracy: 0.5436 - val_loss: 0.6976 - val_accuracy: 0.5096\n",
      "Epoch 333/400\n",
      "2500/2500 [==============================] - 0s 92us/sample - loss: 0.6878 - accuracy: 0.5508 - val_loss: 0.6984 - val_accuracy: 0.5052\n",
      "Epoch 334/400\n",
      "2500/2500 [==============================] - 0s 90us/sample - loss: 0.6881 - accuracy: 0.5460 - val_loss: 0.6986 - val_accuracy: 0.5048\n",
      "Epoch 335/400\n",
      "2500/2500 [==============================] - 0s 95us/sample - loss: 0.6886 - accuracy: 0.5400 - val_loss: 0.6981 - val_accuracy: 0.5112\n",
      "Epoch 336/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6887 - accuracy: 0.5408 - val_loss: 0.6975 - val_accuracy: 0.5096\n",
      "Epoch 337/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6879 - accuracy: 0.5480 - val_loss: 0.6977 - val_accuracy: 0.5168\n",
      "Epoch 338/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6879 - accuracy: 0.5400 - val_loss: 0.6973 - val_accuracy: 0.5180\n",
      "Epoch 339/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6880 - accuracy: 0.5556 - val_loss: 0.6974 - val_accuracy: 0.5204\n",
      "Epoch 340/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6874 - accuracy: 0.5476 - val_loss: 0.7000 - val_accuracy: 0.4924\n",
      "Epoch 341/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6892 - accuracy: 0.5380 - val_loss: 0.6977 - val_accuracy: 0.5196\n",
      "Epoch 342/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6873 - accuracy: 0.5544 - val_loss: 0.6969 - val_accuracy: 0.5132\n",
      "Epoch 343/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6876 - accuracy: 0.5476 - val_loss: 0.6969 - val_accuracy: 0.5152\n",
      "Epoch 344/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6875 - accuracy: 0.5512 - val_loss: 0.6974 - val_accuracy: 0.5140\n",
      "Epoch 345/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6876 - accuracy: 0.5544 - val_loss: 0.6980 - val_accuracy: 0.5168\n",
      "Epoch 346/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6871 - accuracy: 0.5512 - val_loss: 0.6970 - val_accuracy: 0.5116\n",
      "Epoch 347/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6881 - accuracy: 0.5580 - val_loss: 0.6980 - val_accuracy: 0.5164\n",
      "Epoch 348/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6870 - accuracy: 0.5496 - val_loss: 0.6973 - val_accuracy: 0.5168\n",
      "Epoch 349/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6871 - accuracy: 0.5624 - val_loss: 0.6968 - val_accuracy: 0.5188\n",
      "Epoch 350/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6863 - accuracy: 0.5616 - val_loss: 0.7001 - val_accuracy: 0.5020\n",
      "Epoch 351/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6872 - accuracy: 0.5532 - val_loss: 0.6990 - val_accuracy: 0.5008\n",
      "Epoch 352/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6871 - accuracy: 0.5424 - val_loss: 0.6980 - val_accuracy: 0.5160\n",
      "Epoch 353/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6864 - accuracy: 0.5556 - val_loss: 0.6970 - val_accuracy: 0.5236\n",
      "Epoch 354/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6867 - accuracy: 0.5596 - val_loss: 0.6979 - val_accuracy: 0.5096\n",
      "Epoch 355/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6866 - accuracy: 0.5340 - val_loss: 0.6990 - val_accuracy: 0.5028\n",
      "Epoch 356/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6866 - accuracy: 0.5444 - val_loss: 0.6965 - val_accuracy: 0.5192\n",
      "Epoch 357/400\n",
      "2500/2500 [==============================] - 0s 89us/sample - loss: 0.6855 - accuracy: 0.5496 - val_loss: 0.6981 - val_accuracy: 0.5088\n",
      "Epoch 358/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6870 - accuracy: 0.5548 - val_loss: 0.6962 - val_accuracy: 0.5276\n",
      "Epoch 359/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6863 - accuracy: 0.5460 - val_loss: 0.6964 - val_accuracy: 0.5212\n",
      "Epoch 360/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6860 - accuracy: 0.5536 - val_loss: 0.6974 - val_accuracy: 0.5188\n",
      "Epoch 361/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6854 - accuracy: 0.5588 - val_loss: 0.6970 - val_accuracy: 0.5232\n",
      "Epoch 362/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6849 - accuracy: 0.5536 - val_loss: 0.6960 - val_accuracy: 0.5304\n",
      "Epoch 363/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6852 - accuracy: 0.5624 - val_loss: 0.6957 - val_accuracy: 0.5288\n",
      "Epoch 364/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6850 - accuracy: 0.5616 - val_loss: 0.6960 - val_accuracy: 0.5260\n",
      "Epoch 365/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6846 - accuracy: 0.5656 - val_loss: 0.6987 - val_accuracy: 0.5168\n",
      "Epoch 366/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6842 - accuracy: 0.5592 - val_loss: 0.6961 - val_accuracy: 0.5232\n",
      "Epoch 367/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6854 - accuracy: 0.5600 - val_loss: 0.6954 - val_accuracy: 0.5284\n",
      "Epoch 368/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6842 - accuracy: 0.5616 - val_loss: 0.6952 - val_accuracy: 0.5288\n",
      "Epoch 369/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6839 - accuracy: 0.5628 - val_loss: 0.6961 - val_accuracy: 0.5228\n",
      "Epoch 370/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6834 - accuracy: 0.5700 - val_loss: 0.6951 - val_accuracy: 0.5320\n",
      "Epoch 371/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6829 - accuracy: 0.5652 - val_loss: 0.6948 - val_accuracy: 0.5344\n",
      "Epoch 372/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6821 - accuracy: 0.5696 - val_loss: 0.6965 - val_accuracy: 0.5240\n",
      "Epoch 373/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6834 - accuracy: 0.5656 - val_loss: 0.6930 - val_accuracy: 0.5380\n",
      "Epoch 374/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6817 - accuracy: 0.5708 - val_loss: 0.6932 - val_accuracy: 0.5356\n",
      "Epoch 375/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6810 - accuracy: 0.5704 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
      "Epoch 376/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6811 - accuracy: 0.5708 - val_loss: 0.6921 - val_accuracy: 0.5320\n",
      "Epoch 377/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6801 - accuracy: 0.5828 - val_loss: 0.6922 - val_accuracy: 0.5404\n",
      "Epoch 378/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6793 - accuracy: 0.5700 - val_loss: 0.6916 - val_accuracy: 0.5432\n",
      "Epoch 379/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6800 - accuracy: 0.5708 - val_loss: 0.6930 - val_accuracy: 0.5528\n",
      "Epoch 380/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6786 - accuracy: 0.5740 - val_loss: 0.6916 - val_accuracy: 0.5424\n",
      "Epoch 381/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6792 - accuracy: 0.5740 - val_loss: 0.6906 - val_accuracy: 0.5408\n",
      "Epoch 382/400\n",
      "2500/2500 [==============================] - 0s 88us/sample - loss: 0.6767 - accuracy: 0.5792 - val_loss: 0.6901 - val_accuracy: 0.5452\n",
      "Epoch 383/400\n",
      "2500/2500 [==============================] - 0s 87us/sample - loss: 0.6777 - accuracy: 0.5716 - val_loss: 0.6914 - val_accuracy: 0.5492\n",
      "Epoch 384/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6754 - accuracy: 0.5880 - val_loss: 0.6885 - val_accuracy: 0.5528\n",
      "Epoch 385/400\n",
      "2500/2500 [==============================] - 0s 82us/sample - loss: 0.6752 - accuracy: 0.5820 - val_loss: 0.6919 - val_accuracy: 0.5560\n",
      "Epoch 386/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6739 - accuracy: 0.5824 - val_loss: 0.6857 - val_accuracy: 0.5628\n",
      "Epoch 387/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6721 - accuracy: 0.5816 - val_loss: 0.6851 - val_accuracy: 0.5608\n",
      "Epoch 388/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6723 - accuracy: 0.5832 - val_loss: 0.6849 - val_accuracy: 0.5648\n",
      "Epoch 389/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6716 - accuracy: 0.5856 - val_loss: 0.6849 - val_accuracy: 0.5672\n",
      "Epoch 390/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6688 - accuracy: 0.5948 - val_loss: 0.6850 - val_accuracy: 0.5664\n",
      "Epoch 391/400\n",
      "2500/2500 [==============================] - 0s 86us/sample - loss: 0.6667 - accuracy: 0.6076 - val_loss: 0.6825 - val_accuracy: 0.5740\n",
      "Epoch 392/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6676 - accuracy: 0.6000 - val_loss: 0.6826 - val_accuracy: 0.5720\n",
      "Epoch 393/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6656 - accuracy: 0.5940 - val_loss: 0.6819 - val_accuracy: 0.5772\n",
      "Epoch 394/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6641 - accuracy: 0.5952 - val_loss: 0.6788 - val_accuracy: 0.5804\n",
      "Epoch 395/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6625 - accuracy: 0.6044 - val_loss: 0.6794 - val_accuracy: 0.5844\n",
      "Epoch 396/400\n",
      "2500/2500 [==============================] - 0s 81us/sample - loss: 0.6612 - accuracy: 0.6056 - val_loss: 0.6785 - val_accuracy: 0.5772\n",
      "Epoch 397/400\n",
      "2500/2500 [==============================] - 0s 84us/sample - loss: 0.6599 - accuracy: 0.6080 - val_loss: 0.6817 - val_accuracy: 0.5804\n",
      "Epoch 398/400\n",
      "2500/2500 [==============================] - 0s 83us/sample - loss: 0.6610 - accuracy: 0.6052 - val_loss: 0.6806 - val_accuracy: 0.5760\n",
      "Epoch 399/400\n",
      "2500/2500 [==============================] - 0s 85us/sample - loss: 0.6611 - accuracy: 0.6132 - val_loss: 0.6789 - val_accuracy: 0.5736\n",
      "Epoch 400/400\n",
      "2500/2500 [==============================] - 0s 80us/sample - loss: 0.6597 - accuracy: 0.6048 - val_loss: 0.6763 - val_accuracy: 0.5872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.6048</td></tr><tr><td>loss</td><td>0.65975</td></tr><tr><td>val_accuracy</td><td>0.5872</td></tr><tr><td>val_loss</td><td>0.67632</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">woven-sweep-11</strong>: <a href=\"https://wandb.ai/kavp/tensorflow-test/runs/nbysk9ti\" target=\"_blank\">https://wandb.ai/kavp/tensorflow-test/runs/nbysk9ti</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230312_222548-nbysk9ti\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, sweep_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
